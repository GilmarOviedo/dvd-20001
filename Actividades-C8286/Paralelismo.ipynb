{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad: Procesamiento paralelo\n",
    "Las clases Process y Pool.multiprocessing.Process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soy el proceso con este id: 1\n",
      "Soy el proceso con este id: 2Soy el proceso con este id: 3Soy el proceso con este id: 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "# Codigo de Quan Nguyen\n",
    "\n",
    "\n",
    "class Process(multiprocessing.Process):\n",
    "    def __init__(self, id):\n",
    "        super(Process, self).__init__()\n",
    "        self.id = id\n",
    "\n",
    "    def run(self):\n",
    "        time.sleep(1)\n",
    "        print(\"Soy el proceso con este id: {}\".format(self.id))\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    processes = Process(1), Process(2), Process(3), Process(4)\n",
    "    [p.start()for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "# Codigo de Quan Nguyen\n",
    "\n",
    "\n",
    "class Process(multiprocessing.Process):\n",
    "    def __init__(self, id):\n",
    "        super(Process, self).__init__()\n",
    "        self.id = id\n",
    "\n",
    "    def run(self):\n",
    "        time.sleep(1)\n",
    "        print(\"Soy el proceso con este id: {}\".format(self.id))\n",
    "\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "\n",
    "def map_test():\n",
    "    pool = multiprocessing.Pool()\n",
    "\n",
    "    inputs = [0, 1, 2, 3, 4]\n",
    "    outputs = pool.map(square, inputs)\n",
    "    print(outputs)\n",
    "    outputs_async = pool.map_async(square, inputs)\n",
    "    outputs = outputs_async.get()\n",
    "    print(outputs)\n",
    "\n",
    "if __name__ =\"__main__\":\n",
    "    processes = Process(1), Process(2), Process(3), Process(4)\n",
    "    [p.start()for p in processes]   \n",
    "  \n",
    "map_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "executor = ProcessPoolExecutor(max_workers=4)\n",
    "fut = executor.submit(square, 2)\n",
    "\n",
    "result = executor.map(square, [0, 1, 2, 3, 4])\n",
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Definimos la función que queremos ejecutar de forma asíncrona.\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "# Creando el executor para manejar la ejecución concurrente\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # Enviando tareas al executor\n",
    "    fut1 = executor.submit(square, 2)\n",
    "    fut2 = executor.submit(square, 3)\n",
    "    \n",
    "    # Usando 'wait' para esperar a que ambos futures se completen\n",
    "    concurrent.futures.wait([fut1, fut2])\n",
    "    \n",
    "    # Extraemos los resultados una vez que sabemos que están completos y los almacenamos en una lista\n",
    "    results_with_wait = [fut1.result(), fut2.result()]\n",
    "    print(\"Resultados obtenidos usando wait:\", results_with_wait)\n",
    "    \n",
    "    # Usando 'as_completed' para iterar sobre los futures a medida que se completan\n",
    "    # Reenviamos las tareas porque fut1 y fut2 ya están completados y consumidos.\n",
    "    fut1 = executor.submit(square, 2)\n",
    "    fut2 = executor.submit(square, 3)\n",
    "    \n",
    "    results = concurrent.futures.as_completed([fut1, fut2])\n",
    "    results_list_as_completed = [future.result() for future in results]\n",
    "    print(\"Resultados obtenidos usando as_completed:\", results_list_as_completed)\n",
    "\n",
    "# El contexto 'with' asegura que el executor se cierre correctamente después de usarlo.\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:**  Genera futures usando la función `asyncio.run_in_executor` y manipular los resultados usando todas las herramientas y sintaxis proporcionadas por la biblioteca `asyncio` para que pueda lograr concurrencia y paralelismo al mismo tiempo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El método de Monte Carlo para estimar el valor de Pi.\n",
    "\n",
    "El primer paso al escribir un programa paralelo es desarrollar una versión en serie y verificar que funcione correctamente. En un escenario del mundo real, es recomendable dejar la paralelización como el último paso del proceso de optimización; en primer lugar, porque es necesario identificar las partes más lentas y, en segundo lugar, porque la paralelización requiere una inversión significativa de tiempo y, en el mejor de los casos, ofrece una aceleración que no supera el número de procesadores disponibles. A continuación, se presenta la implementación del programa en serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "samples = 1000000\n",
    "hits = 0\n",
    "for i in range(samples):\n",
    "    x = random.uniform(-1.0, 1.0)\n",
    "    y = random.uniform(-1.0, 1.0)\n",
    "    if x**2 + y**2 <= 1:\n",
    "        hits += 1\n",
    "pi = 4.0 * hits/samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** modifica el codigo para realizar una  funcional y eficiente la aproximación de Pi de manera serial en Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para paralelizar este código, podemos escribir una función, llamada `sample`, que corresponda a una única verificación de acierto y error. Si la muestra acierta al círculo, la función devolverá 1; de lo contrario, devolverá 0. Al ejecutar `sample` varias veces y sumar los resultados, obtendremos el número total de aciertos. \n",
    "\n",
    "Podemos ejecutar la muestra en varios procesadores con `apply_async` y obtener los resultados de la siguiente manera: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample():\n",
    "    x = random.uniform(-1.0, 1.0)\n",
    "    y = random.uniform(-1.0, 1.0)\n",
    "    if x**2 + y**2 <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "pool = multiprocessing.Pool()\n",
    "results_async = [pool.apply_async(sample) for i in range(samples)]\n",
    "hits = sum(r.get() for r in results_async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Empaqueta las dos versiones llamadas como `pi_serial` y `pi_apply_async`  y comparar la velocidad de ejecución, de la siguiente manera: \n",
    "\n",
    "- `time python -c 'import pi; pi.pi_serial()'`\n",
    "- `time python -c 'import pi; pi.pi_apply_async()'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multiple(samples_partial): \n",
    "  return sum(sample() for i in range(samples_partial)) \n",
    "\n",
    "n_tasks = 10 \n",
    "\n",
    "chunk_size = samples/n_tasks \n",
    "\n",
    "pool = multiprocessing.Pool() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Incluye este código en una función llamada `pi_apply_async_chunked` y ejecuta el código de la siguiente manera: \n",
    "\n",
    "* ` time python -c 'import pi; pi.pi_apply_async_chunked()'`\n",
    "\n",
    "¿Qué observas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código completo de respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "samples = 10000000\n",
    "\n",
    "\n",
    "def pi_serial():\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(samples):\n",
    "        x = random.uniform(-1.0, 1.0)\n",
    "        y = random.uniform(-1.0, 1.0)\n",
    "\n",
    "        if x ** 2 + y ** 2 <= 1:\n",
    "            hits += 1\n",
    "\n",
    "    pi = 4.0 * hits / samples\n",
    "    return pi\n",
    "\n",
    "\n",
    "def sample():\n",
    "    x = random.uniform(-1.0, 1.0)\n",
    "    y = random.uniform(-1.0, 1.0)\n",
    "\n",
    "    if x ** 2 + y ** 2 <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def pi_apply_async():\n",
    "    pool = multiprocessing.Pool()\n",
    "    results_async = [pool.apply_async(sample) for i in range(samples)]\n",
    "    hits = sum(r.get() for r in results_async)\n",
    "\n",
    "    pi = 4.0 * hits / samples\n",
    "    return pi\n",
    "\n",
    "\n",
    "def sample_multiple(samples_partial):\n",
    "    return sum(sample() for i in range(samples_partial))\n",
    "\n",
    "\n",
    "def pi_apply_async_chunked():\n",
    "    ntasks = 10\n",
    "    chunk_size = samples / ntasks\n",
    "    pool = multiprocessing.Pool()\n",
    "    results_async = [\n",
    "        pool.apply_async(sample_multiple, [chunk_size]) for i in range(ntasks)\n",
    "    ]\n",
    "    hits = sum(r.get() for r in results_async)\n",
    "\n",
    "    pi = 4.0 * hits / samples\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sincronización y bloqueos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "# Codigo de Quan Nguyen\n",
    "\n",
    "class Process(multiprocessing.Process):\n",
    "    def __init__(self, counter):\n",
    "        super(Process, self).__init__()\n",
    "        self.counter = counter\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(1000):\n",
    "                self.counter.value += 1\n",
    "\n",
    "\n",
    "def main():\n",
    "    counter = multiprocessing.Value(\"i\", lock=True)\n",
    "    counter.value = 0\n",
    "\n",
    "    processes = [Process(counter) for i in range(4)]\n",
    "    [p.start() for p in processes]\n",
    "    [p.join() for p in processes]\n",
    "    print(counter.value)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Encuentras algún problema en el código anterior?. Proporciona una solución para resolver algún inconveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenMP \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cython numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as cnp  # esto es necesario para las declaraciones de tipo de datos\n",
    "\n",
    "def square_serial(cnp.ndarray[cnp.float64_t, ndim=1] inp):\n",
    "    cdef int i, size = inp.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] out = np.empty(size, dtype=np.float64)\n",
    "    \n",
    "    for i in range(size):\n",
    "        out[i] = inp[i] * inp[i]\n",
    "\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_array = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float64)\n",
    "result = square_serial(inp_array)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar una versión paralela del bucle sobre los elementos de la matriz implica sustituir la llamada de `range` por `prange`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp --force\n",
    "from cython.parallel import prange\n",
    "import numpy as np\n",
    "cimport cython\n",
    "cimport numpy as cnp\n",
    "\n",
    "@cython.boundscheck(False)  # Desactivar la comprobación de límites de los arrays\n",
    "@cython.wraparound(False)   # Desactivar el envoltorio negativo\n",
    "def square_parallel(cnp.ndarray[cnp.float64_t, ndim=1] inp):\n",
    "    cdef int i, size = inp.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] out = np.empty(size, dtype=np.float64)\n",
    "    \n",
    "    # Usar prange aquí para la ejecución en paralelo\n",
    "    for i in prange(size, nogil=True):\n",
    "        out[i] = inp[i] * inp[i]\n",
    "\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_array = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float64)\n",
    "result = square_parallel(inp_array)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de `nogil` en Cython es una estrategia clave para habilitar el verdadero paralelismo de múltiples hilos en código que no necesitan interactuar con objetos de Python o cualquier cosa que requiera el Global Interpreter Lock (GIL). `nogil` literalmente significa `no GIL` y cuando se usa en un contexto (como con `prange`), permite que ese bloque de código se ejecute sin mantener el GIL, que es necesario para realizar operaciones verdaderamente paralelas en múltiples núcleos de la CPU.\n",
    "\n",
    "Para utilizar nogil de manera efectiva en Cython, sigue estos pasos:\n",
    "\n",
    "1. Asegurar que el código sea seguro sin GIL: solo código que no acceda a objetos de Python o realice operaciones que requieran el GIL puede ejecutarse de manera segura sin este. Por ejemplo, operaciones numéricas en arrays de NumPy (que no involucren la creación de nuevos objetos de Python) pueden hacerse sin el GIL.\n",
    "\n",
    "2. Usar `with nogil:` o `nogil=True`: puedes usar `with nogil:` para designar un bloque de código que se ejecutará sin el GIL. En `prange`, puedes pasar `nogil=True` como un argumento para indicar que el cuerpo del bucle se ejecutará sin el GIL.\n",
    "\n",
    "3. Compilar con soporte para multihilos: asegúrate de que tu código se compile con soporte para multihilos (usualmente OpenMP) para aprovechar el paralelismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp\n",
    "from cython.parallel import prange\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)  # Desactiva la verificación de límites para mejorar el rendimiento\n",
    "@cython.wraparound(False)   # Desactiva el envoltorio negativo\n",
    "def square_parallel_nogil(cnp.ndarray[cnp.float64_t, ndim=1] inp):\n",
    "    cdef int i, size = inp.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] out = np.empty(size, dtype=np.float64)\n",
    "    \n",
    "    # Ejecuta el bucle en paralelo y sin el GIL\n",
    "    for i in prange(size, nogil=True):\n",
    "        out[i] = inp[i] * inp[i]\n",
    "\n",
    "    return np.array(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_array = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float64)\n",
    "result = square_parallel_nogil(inp_array)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralelismo automático \n",
    "\n",
    "Ejemplos de paquetes que implementan paralelismo automático son los (ahora) familiares compiler just-in-time (JIT) [numexpr](https://github.com/pydata/numexpr) y [Numba](https://numba.pydata.org/). Se han desarrollado otros paquetes para optimizar y paralelizar automáticamente matrices y expresiones intensivas en matrices, que son cruciales en aplicaciones numéricas y de aprendizaje automático (ML) específicas. \n",
    "\n",
    "Theano es un proyecto que te permite definir una expresión matemática en matrices (más generalmente, tensores) y compilarlas en un lenguaje rápido, como C o C++. Muchas de las operaciones que implementa Theano son paralelizables y pueden ejecutarse tanto en la CPU como en la GPU. \n",
    "\n",
    "TensorFlow es otra biblioteca similar a Theano,  dirigida al uso de expresiones matemáticas con uso intensivo de matrices pero, en lugar de traducir las expresiones a código C especializado, ejecuta las operaciones en un motor C++ eficiente. \n",
    "\n",
    "Tanto Theano como TensorFlow son ideales cuando el problema en cuestión se puede expresar en una cadena de operaciones matriciales y de elementos (como redes neuronales). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo del cálculo de pi, usando Teano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import theano as th\n",
    "# Codigo de Quan Nguyen\n",
    "\n",
    "th.config.openmp_elemwise_minsize = 1000\n",
    "th.config.openmp = True\n",
    "\n",
    "x = T.vector(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "\n",
    "hit_test = x ** 2 + y ** 2 < 1\n",
    "hits = hit_test.sum()\n",
    "misses = x.shape[0]\n",
    "pi_est = 4 * hits / misses\n",
    "\n",
    "calculate_pi = th.function([x, y], pi_est)\n",
    "\n",
    "x_val = np.random.uniform(-1, 1, 30000)\n",
    "y_val = np.random.uniform(-1, 1, 30000)\n",
    "\n",
    "import timeit\n",
    "\n",
    "res = timeit.timeit(\n",
    "    \"calculate_pi(x_val, y_val)\",\n",
    "    \"from __main__ import x_val, y_val, calculate_pi\",\n",
    "    number=100000,\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** Modifica el código anterior para verificar que Theano generará un código ligeramente diferente que se beneficia menos de múltiples subprocesos, cuando se cambia el código:\n",
    "\n",
    "```\n",
    "# hits = hit_test.sum()\n",
    "hits = hit_test.astype('int32').sum()\n",
    "```\n",
    "Comprueba que si vuelves a ejecutar el bechmarking, la cantidad de subprocesos no afecta significativamente el tiempo de ejecución:\n",
    "\n",
    "```\n",
    "$ OMP_NUM_THREADS=1 python theano.py\n",
    "$ OMP_NUM_THREADS=2 python theano.py\n",
    "$ OMP_NUM_THREADS=3 python theano.py\n",
    "$ OMP_NUM_THREADS=4 python theano.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling Theano\n",
    "\n",
    "Para generar datos de creación profiling, la única modificación necesaria es agregar la opción `profile=True` a la función `th`, como se ilustra en el siguiente fragmento de código:\n",
    "\n",
    "```\n",
    "calculate_pi = th.function([x, y], pi_est,profile=True)\n",
    "```\n",
    "\n",
    "El resumen del profile se puede imprimir en la salida emitiendo el comando `summary`, de la siguiente manera:\n",
    "\n",
    "```\n",
    "calculate_pi.profile.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cuál es el resultado impreso de `calculate_pi.profile.summary()`?, ¿ qué secciones aparecen en el resultado?, ¿es consistente con el primer benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
