{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7b63b1",
   "metadata": {},
   "source": [
    "### Programación de procesos múltiples (multiprocessing)\n",
    "\n",
    "\n",
    "La programación de procesos múltiples, o multiprocessing, es una técnica que permite la ejecución simultánea de múltiples procesos independientes dentro de un sistema. A diferencia de la programación multihilo, donde múltiples hilos comparten el mismo espacio de memoria, los procesos múltiples operan en su propio espacio de direcciones, proporcionando un mayor aislamiento y robustez. Esta técnica es especialmente útil para aplicaciones que requieren un alto rendimiento y eficiencia, como el procesamiento de datos masivos, simulaciones científicas y servicios web de alta concurrencia. Este ensayo explora los conceptos fundamentales, ventajas, desafíos y aplicaciones de la programación de procesos múltiples, así como las técnicas de comunicación y sincronización entre procesos.\n",
    "\n",
    "La programación de procesos múltiples se basa en la creación y gestión de procesos independientes que pueden ejecutarse en paralelo. Un proceso es una instancia de un programa en ejecución que incluye su propio espacio de memoria, registros y pila.\n",
    "\n",
    "**Procesos y subprocesos**\n",
    "\n",
    "- Proceso: Un proceso es una entidad de ejecución que tiene su propio espacio de direcciones y recursos del sistema. Cada proceso es independiente y se ejecuta en su propio contexto.\n",
    "- Subproceso: También conocido como proceso hijo, es un proceso creado por otro proceso (el proceso padre). Los subprocesos pueden ejecutarse concurrentemente con el proceso padre.\n",
    "\n",
    "**Creación y gestión de procesos**\n",
    "\n",
    "- Creación de procesos: Los procesos se crean mediante llamadas al sistema, como fork() en Unix o CreateProcess() en Windows. Los lenguajes de programación modernos, como Python, proporcionan bibliotecas para facilitar la creación de procesos.\n",
    "- Gestión de procesos: La gestión de procesos incluye la creación, sincronización y terminación de procesos. Los sistemas operativos proporcionan herramientas y funciones para gestionar estos aspectos.\n",
    "\n",
    "**Ventajas de la programación de procesos múltiples**\n",
    "\n",
    "- Aislamiento y robustez: Cada proceso tiene su propio espacio de direcciones, lo que significa que un fallo en un proceso no afectará a otros procesos. Esto proporciona un mayor nivel de aislamiento y robustez en comparación con la programación multihilo.\n",
    "- Paralelismo real: En sistemas con múltiples núcleos de CPU, los procesos pueden ejecutarse en paralelo, aprovechando al máximo el hardware disponible para mejorar el rendimiento.\n",
    "- Escalabilidad: La programación de procesos múltiples permite escalar aplicaciones distribuyendo la carga de trabajo entre múltiples procesos, lo que es útil en sistemas de computación distribuida y clústeres.\n",
    "\n",
    "**Desafíos de la programación de procesos múltiples**\n",
    "\n",
    "- Sobrecarga de comunicación: La comunicación entre procesos (IPC, por sus siglas en inglés) puede ser más costosa en términos de rendimiento que la comunicación entre hilos, debido al aislamiento de memoria.\n",
    "- Sincronización y consistencia: La sincronización de procesos para acceder a recursos compartidos es compleja y puede introducir latencias y cuellos de botella si no se maneja adecuadamente.\n",
    "- Gestión de recursos: La creación y gestión de procesos implica una mayor sobrecarga en términos de memoria y recursos del sistema, lo que puede limitar el número de procesos que pueden ejecutarse simultáneamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c2b1c1",
   "metadata": {},
   "source": [
    "### Técnicas de comunicación y sincronización entre procesos\n",
    "\n",
    "La programación de procesos múltiples implica la creación y gestión de procesos independientes que pueden ejecutarse en paralelo. Sin embargo, para que estos procesos colaboren de manera efectiva, es crucial implementar técnicas de comunicación y sincronización. Estas técnicas permiten a los procesos compartir datos y coordinar sus acciones, garantizando la coherencia y evitando conflictos. A continuación, se describen en detalle varias técnicas fundamentales para la comunicación y sincronización entre procesos.\n",
    "\n",
    "**Comunicación entre procesos (IPC)**\n",
    "\n",
    "- Tuberías (Pipes)_ Las tuberías son una técnica de comunicación unidireccional que permite transmitir datos de un proceso a otro a través de una conexión de flujo. En sistemas Unix, se crean utilizando la llamada al sistema pipe(). Las tuberías pueden ser anónimas, utilizadas entre procesos que tienen una relación padre-hijo, o con nombre, utilizadas entre procesos independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33038c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <unistd.h>\n",
    "\n",
    "int main() {\n",
    "    int fd[2];\n",
    "    pipe(fd);\n",
    "    pid_t pid = fork();\n",
    "\n",
    "    if (pid == 0) {\n",
    "        // Proceso hijo\n",
    "        close(fd[0]);\n",
    "        char message[] = \"Hello from child\";\n",
    "        write(fd[1], message, sizeof(message));\n",
    "        close(fd[1]);\n",
    "    } else {\n",
    "        // Proceso padre\n",
    "        close(fd[1]);\n",
    "        char buffer[100];\n",
    "        read(fd[0], buffer, sizeof(buffer));\n",
    "        printf(\"%s\\n\", buffer);\n",
    "        close(fd[0]);\n",
    "    }\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9acda6",
   "metadata": {},
   "source": [
    "* Colas de Mensajes_ Las colas de mensajes permiten la comunicación asíncrona entre procesos mediante el envío y recepción de mensajes a través de una estructura de datos compartida. Los mensajes se almacenan en una cola hasta que el proceso receptor los consume. Esta técnica es útil para sistemas distribuidos y aplicaciones que requieren una alta concurrencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker(queue):\n",
    "    queue.put(\"Hello from worker\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue = multiprocessing.Queue()\n",
    "    process = multiprocessing.Process(target=worker, args=(queue,))\n",
    "    process.start()\n",
    "    print(queue.get())\n",
    "    process.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35594b3b",
   "metadata": {},
   "source": [
    "* Memoria compartida: La memoria compartida permite que múltiples procesos accedan a una región de memoria común, facilitando el intercambio de datos de manera eficiente. Sin embargo, este método requiere mecanismos de sincronización para evitar condiciones de carrera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd13725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value\n",
    "\n",
    "def worker(shared_value):\n",
    "    shared_value.value += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    shared_value = Value('i', 0)\n",
    "    processes = [Process(target=worker, args=(shared_value,)) for _ in range(5)]\n",
    "\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(shared_value.value)  # Output: 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26edccf",
   "metadata": {},
   "source": [
    "* Sockets: Los sockets permiten la comunicación entre procesos que pueden estar en diferentes máquinas, utilizando protocolos de red como TCP/IP. Los sockets son extremadamente flexibles y se utilizan en una amplia variedad de aplicaciones, desde servidores web hasta sistemas de mensajería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71060522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "def server():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind(('localhost', 12345))\n",
    "    s.listen(1)\n",
    "    conn, addr = s.accept()\n",
    "    print('Connected by', addr)\n",
    "    data = conn.recv(1024)\n",
    "    print('Received', data)\n",
    "    conn.close()\n",
    "\n",
    "def client():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.connect(('localhost', 12345))\n",
    "    s.sendall(b'Hello, world')\n",
    "    s.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing import Process\n",
    "    p1 = Process(target=server)\n",
    "    p2 = Process(target=client)\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42fbaa",
   "metadata": {},
   "source": [
    "**Sincronización entre Procesos**\n",
    "\n",
    "* Semáforos: Los semáforos son variables que se utilizan para controlar el acceso a recursos compartidos y sincronizar la ejecución de procesos. Pueden ser binarios (mutex) o contadores, y son esenciales para evitar condiciones de carrera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing.Semaphore\n",
    "from multiprocessing import Process, Semaphore\n",
    "\n",
    "def worker(sem, n):\n",
    "    sem.acquire()\n",
    "    print(f'Worker {n} is in critical section')\n",
    "    sem.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sem = Semaphore(1)\n",
    "    processes = [Process(target=worker, args=(sem, i)) for i in range(5)]\n",
    "\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdf03e",
   "metadata": {},
   "source": [
    "* Mutexes: Un mutex (mutual exclusion) es un tipo de semáforo binario utilizado específicamente para asegurar que solo un proceso pueda acceder a un recurso compartido a la vez. Los mutexes son esenciales para evitar condiciones de carrera en entornos de programación concurrente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threading.Lock\n",
    "import threading\n",
    "\n",
    "class SharedResource:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.value += 1\n",
    "\n",
    "def worker(resource):\n",
    "    for _ in range(1000):\n",
    "        resource.increment()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resource = SharedResource()\n",
    "    threads = [threading.Thread(target=worker, args=(resource,)) for _ in range(5)]\n",
    "\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    print(resource.value)  # Output: 5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107e3f6",
   "metadata": {},
   "source": [
    "* Condiciones (conditions): Las condiciones son mecanismos de sincronización que permiten que los procesos esperen hasta que se cumpla una condición específica. Son útiles para coordinar la ejecución de procesos que dependen de ciertos eventos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b097a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threading.Condition\n",
    "import threading\n",
    "\n",
    "class SharedResource:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self.condition = threading.Condition()\n",
    "\n",
    "    def wait_for_increment(self):\n",
    "        with self.condition:\n",
    "            self.condition.wait_for(lambda: self.value > 0)\n",
    "            print('Value incremented:', self.value)\n",
    "\n",
    "    def increment(self):\n",
    "        with self.condition:\n",
    "            self.value += 1\n",
    "            self.condition.notify_all()\n",
    "\n",
    "def worker(resource):\n",
    "    resource.increment()\n",
    "\n",
    "def waiter(resource):\n",
    "    resource.wait_for_increment()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resource = SharedResource()\n",
    "    t1 = threading.Thread(target=worker, args=(resource,))\n",
    "    t2 = threading.Thread(target=waiter, args=(resource,))\n",
    "\n",
    "    t2.start()\n",
    "    t1.start()\n",
    "    t1.join()\n",
    "    t2.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1dcaf7",
   "metadata": {},
   "source": [
    "* Barreras: Las barreras son mecanismos de sincronización que permiten a un conjunto de procesos o hilos esperar hasta que todos ellos hayan alcanzado un punto común de ejecución. Son útiles en algoritmos paralelos donde múltiples tareas deben sincronizarse en ciertos puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6286b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threading.Barrier\n",
    "import threading\n",
    "\n",
    "def worker(barrier, n):\n",
    "    print(f'Worker {n} before barrier')\n",
    "    barrier.wait()\n",
    "    print(f'Worker {n} after barrier')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    barrier = threading.Barrier(3)\n",
    "    threads = [threading.Thread(target=worker, args=(barrier, i)) for i in range(3)]\n",
    "\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdaba5",
   "metadata": {},
   "source": [
    "### Problemas clásicos en la programación de procesos múltiples\n",
    "\n",
    "La programación de procesos múltiples es un área fundamental en la informática, especialmente en el contexto de sistemas operativos y la programación concurrente. Esta área aborda la ejecución simultánea de múltiples procesos o hilos que pueden cooperar y competir por recursos compartidos. Sin embargo, la programación concurrente introduce varios problemas complejos que requieren técnicas sofisticadas para resolverlos. A continuación, se describen algunos de los problemas clásicos en la programación de procesos múltiples.\n",
    "\n",
    "1 . Condición de carrera (race condition)\n",
    "\n",
    "Una condición de carrera ocurre cuando dos o más procesos acceden a recursos compartidos simultáneamente, y el resultado del programa depende del orden en el que los procesos se ejecutan. Esto puede llevar a resultados inconsistentes y errores difíciles de reproducir y depurar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    t = threading.Thread(target=increment)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(counter)  #La salida debería ser 500000, pero sin bloqueo podría ser menor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafc9da",
   "metadata": {},
   "source": [
    "En este ejemplo, sin el uso de lock, múltiples hilos pueden incrementar counter al mismo tiempo, lo que resulta en una condición de carrera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c7ce8c",
   "metadata": {},
   "source": [
    "2 . Sección crítica (critical section)\n",
    "Una sección crítica es una parte del código que debe ser ejecutada por solo un proceso o hilo a la vez para evitar condiciones de carrera. El acceso a la sección crítica debe ser controlado mediante mecanismos de sincronización como mutexes o semáforos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d68e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class SharedResource:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.value += 1\n",
    "\n",
    "resource = SharedResource()\n",
    "\n",
    "def worker():\n",
    "    for _ in range(100000):\n",
    "        resource.increment()\n",
    "\n",
    "threads = [threading.Thread(target=worker) for _ in range(5)]\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(resource.value)  # salida correcta: 500000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7a261",
   "metadata": {},
   "source": [
    "3 . Problema de los productores y consumidores (producer-consumer problem)\n",
    "\n",
    "El problema de los productores y consumidores involucra dos tipos de procesos: productores que generan datos y consumidores que procesan esos datos. Un búfer finito se utiliza para almacenar datos temporales. El desafío es asegurar que los productores no llenen el búfer cuando esté lleno y que los consumidores no intenten extraer datos cuando el búfer esté vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeddd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "buffer = queue.Queue(maxsize=10)\n",
    "\n",
    "def producer():\n",
    "    for i in range(100):\n",
    "        buffer.put(i)\n",
    "        print(f'Produced {i}')\n",
    "\n",
    "def consumer():\n",
    "    for i in range(100):\n",
    "        item = buffer.get()\n",
    "        print(f'Consumed {item}')\n",
    "        buffer.task_done()\n",
    "\n",
    "producer_thread = threading.Thread(target=producer)\n",
    "consumer_thread = threading.Thread(target=consumer)\n",
    "\n",
    "producer_thread.start()\n",
    "consumer_thread.start()\n",
    "\n",
    "producer_thread.join()\n",
    "consumer_thread.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb92ab",
   "metadata": {},
   "source": [
    "4 . Problema de la cena de los filósofos (dining philosophers problem)\n",
    "\n",
    "El problema de la cena de los filósofos es un ejemplo clásico de sincronización en el que cinco filósofos se sientan alrededor de una mesa circular con un tenedor entre cada par de filósofos. Cada filósofo necesita ambos tenedores para comer, lo que puede conducir a un bloqueo mutuo si todos los filósofos intentan tomar el tenedor de su izquierda al mismo tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cbab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "class Philosopher(threading.Thread):\n",
    "    def __init__(self, name, left_fork, right_fork):\n",
    "        threading.Thread.__init__(self, name=name)\n",
    "        self.left_fork = left_fork\n",
    "        self.right_fork = right_fork\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "            self.dine()\n",
    "\n",
    "    def dine(self):\n",
    "        fork1, fork2 = self.left_fork, self.right_fork\n",
    "        while True:\n",
    "            fork1.acquire(True)\n",
    "            locked = fork2.acquire(False)\n",
    "            if locked: break\n",
    "            fork1.release()\n",
    "            fork1, fork2 = fork2, fork1\n",
    "        self.eating()\n",
    "        fork2.release()\n",
    "        fork1.release()\n",
    "\n",
    "    def eating(self):\n",
    "        print(f'{self.name} is eating.')\n",
    "        time.sleep(1)\n",
    "\n",
    "forks = [threading.Lock() for n in range(5)]\n",
    "names = ['Philosopher1', 'Philosopher2', 'Philosopher3', 'Philosopher4', 'Philosopher5']\n",
    "\n",
    "philosophers = [Philosopher(names[i], forks[i], forks[(i+1)%5]) for i in range(5)]\n",
    "\n",
    "for p in philosophers:\n",
    "    p.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c4061",
   "metadata": {},
   "source": [
    "5 . Problema de los Lectores y Escritores (Readers-Writers Problem)\n",
    "\n",
    "El problema de los lectores y escritores se centra en la necesidad de sincronizar el acceso a un recurso compartido entre múltiples procesos de lectura y escritura. Los lectores pueden acceder al recurso simultáneamente, pero los escritores requieren acceso exclusivo. El desafío es diseñar un sistema que minimice la espera y evite condiciones de carrera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class ReadersWriters:\n",
    "    def __init__(self):\n",
    "        self.read_count = 0\n",
    "        self.read_lock = threading.Lock()\n",
    "        self.resource_lock = threading.Lock()\n",
    "\n",
    "    def reader(self):\n",
    "        with self.read_lock:\n",
    "            self.read_count += 1\n",
    "            if self.read_count == 1:\n",
    "                self.resource_lock.acquire()\n",
    "        print('Reading')\n",
    "        with self.read_lock:\n",
    "            self.read_count -= 1\n",
    "            if self.read_count == 0:\n",
    "                self.resource_lock.release()\n",
    "\n",
    "    def writer(self):\n",
    "        with self.resource_lock:\n",
    "            print('Writing')\n",
    "\n",
    "rw = ReadersWriters()\n",
    "threads = []\n",
    "\n",
    "for i in range(3):\n",
    "    t = threading.Thread(target=rw.reader)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=rw.writer)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a6166",
   "metadata": {},
   "source": [
    "6 . Bloqueo mutuo (deadlock)\n",
    "\n",
    "El bloqueo mutuo ocurre cuando dos o más procesos están bloqueados permanentemente esperando por recursos que están siendo retenidos por otros procesos en el conjunto de bloqueo. Para resolver este problema, es necesario implementar técnicas de prevención, detección y recuperación de bloqueos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6afaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "lock1 = threading.Lock()\n",
    "lock2 = threading.Lock()\n",
    "\n",
    "def task1():\n",
    "    while True:\n",
    "        with lock1:\n",
    "            time.sleep(0.1)\n",
    "            with lock2:\n",
    "                print(\"Task 1 completed\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def task2():\n",
    "    while True:\n",
    "        with lock2:\n",
    "            time.sleep(0.1)\n",
    "            with lock1:\n",
    "                print(\"Task 2 completed\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "t1 = threading.Thread(target=task1)\n",
    "t2 = threading.Thread(target=task2)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78990440",
   "metadata": {},
   "source": [
    "7 . Inanición (Starvation)\n",
    "La inanición ocurre cuando un proceso no puede acceder a los recursos necesarios para continuar su ejecución debido a la competencia con otros procesos. Esto suele ser resultado de una política de planificación injusta.\n",
    "\n",
    "8 . Inversión de Prioridad (priority inversion)\n",
    "La inversión de prioridad sucede cuando un proceso de alta prioridad espera por un recurso retenido por un proceso de baja prioridad, mientras que un proceso de prioridad media sigue ejecutándose. Esta situación puede resolverse utilizando técnicas como la herencia de prioridad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d363e89",
   "metadata": {},
   "source": [
    "### Aplicaciones de la programación de procesos múltiples\n",
    "\n",
    "* Procesamiento de datos masivos: La programación de procesos múltiples se utiliza ampliamente en aplicaciones de procesamiento de datos masivos, como Hadoop y Apache Spark, que dividen grandes volúmenes de datos en fragmentos más pequeños que se procesan en paralelo.\n",
    "\n",
    "* Simulaciones científicas: Las simulaciones científicas que requieren un alto poder de cómputo, como las simulaciones de dinámica molecular y clima, utilizan múltiples procesos para distribuir la carga de trabajo y acelerar el procesamiento.\n",
    "\n",
    "* Servidores web de alta concurrencia: Los servidores web como Apache y Nginx utilizan múltiples procesos para manejar miles de solicitudes de clientes simultáneamente, mejorando la capacidad de respuesta y el rendimiento del servidor.\n",
    "\n",
    "* Sistemas operativos: Los sistemas operativos modernos utilizan la programación de procesos múltiples para gestionar la ejecución de aplicaciones y servicios de manera eficiente, permitiendo la multitarea y la gestión de recursos del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28248d9e",
   "metadata": {},
   "source": [
    "#### Beneficios de la programación de procesos múltiples\n",
    "\n",
    "* Robustez y aislamiento: Cada proceso opera en su propio espacio de memoria, lo que proporciona un mayor nivel de robustez y aislamiento frente a fallos y errores.\n",
    "\n",
    "* Paralelismo en sistemas multinúcleo: Los procesos pueden ejecutarse en paralelo en sistemas con múltiples núcleos de CPU, aprovechando al máximo el hardware disponible.\n",
    "\n",
    "* Escalabilidad en sistemas distribuidos: La programación de procesos múltiples permite distribuir la carga de trabajo entre múltiples nodos en un clúster, mejorando la escalabilidad y el rendimiento de las aplicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61788a89",
   "metadata": {},
   "source": [
    "#### Herramientas y técnicas avanzadas\n",
    "\n",
    "* Bibliotecas de alto nivel: Bibliotecas como MPI (Message Passing Interface) facilitan la comunicación y coordinación entre procesos en aplicaciones de computación paralela y distribuida.\n",
    "* Lenguajes de programación concurrente: Algunos lenguajes, como Erlang y Go, están diseñados específicamente para la programación concurrente, simplificando la creación y gestión de procesos.\n",
    "* Sistemas de gestión de colas de trabajo: Sistemas como Celery en Python permiten gestionar y distribuir tareas entre múltiples procesos de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6bcc9",
   "metadata": {},
   "source": [
    "### Patrones de diseño para la programación de procesos múltiples\n",
    "\n",
    "\n",
    "Uno de los patrones de diseño más significativos y ampliamente utilizados en este contexto es el patrón MapReduce. Este patrón es esencial para el procesamiento distribuido de grandes volúmenes de datos y ha sido popularizado principalmente por su implementación en sistemas de computación en la nube y big data, como Hadoop.\n",
    "\n",
    "El patrón MapReduce fue introducido por Google en un artículo de investigación en 2004. Está diseñado para procesar y generar grandes conjuntos de datos de manera paralela, distribuida y escalable. El nombre MapReduce proviene de dos funciones principales que se utilizan en este patrón: Map y Reduce.\n",
    "\n",
    "* Map: Esta función toma una colección de datos y los transforma en pares clave-valor.\n",
    "* Reduce: Esta función toma los pares clave-valor generados por la fase de Map y los agrega o reduce a un conjunto más pequeño de resultados.\n",
    "\n",
    "El proceso MapReduce se puede dividir en varias etapas clave:\n",
    "\n",
    "- Input splitting: Los datos de entrada se dividen en fragmentos manejables llamados splits. Cada split se asigna a un mapeador para su procesamiento.\n",
    "- Mapping: Los mapeadores (funciones Map) procesan cada split y generan pares clave-valor intermedios.\n",
    "- Shuffling and sorting: Los pares clave-valor intermedios se agrupan y ordenan por clave. Este proceso asegura que todos los valores asociados con una clave específica se envíen al mismo reductor.\n",
    "- Reducing: Los reductores (funciones Reduce) reciben los pares clave-valor ordenados y los procesan para generar los resultados finales.\n",
    "- Output: Los resultados finales se almacenan en un sistema de almacenamiento distribuido o se entregan directamente a la aplicación solicitante.\n",
    "\n",
    "Para ilustrar cómo funciona MapReduce, consideremos una implementación básica en Python. Supongamos que queremos contar el número de apariciones de cada palabra en un gran conjunto de documentos.\n",
    "\n",
    "1 . Definición de la función map:\n",
    "\n",
    "La función map tomará una línea de texto y emitirá pares clave-valor donde la clave es la palabra y el valor es 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ce2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(line):\n",
    "    words = line.split()\n",
    "    return [(word, 1) for word in words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0419095",
   "metadata": {},
   "source": [
    "2 . Definición de la función reduce:\n",
    "\n",
    "La función reduce tomará una clave y una lista de valores, y sumará los valores para contar el número total de apariciones de cada palabra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73696bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(word, counts):\n",
    "    return (word, sum(counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b929d99",
   "metadata": {},
   "source": [
    "3 . Ejecución del proceso MapReduce:\n",
    "\n",
    "El siguiente código simula el flujo completo de un trabajo MapReduce utilizando las funciones definidas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5dffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Datos de ejemplo\n",
    "documents = [\n",
    "    \"hello world\",\n",
    "    \"hello\",\n",
    "    \"hello mapreduce world\",\n",
    "    \"mapreduce in python\",\n",
    "    \"hello mapreduce\"\n",
    "]\n",
    "\n",
    "# Fase de Mapping\n",
    "mapped = []\n",
    "for doc in documents:\n",
    "    mapped.extend(map(doc))\n",
    "\n",
    "# Fase de Shuffling and Sorting\n",
    "shuffled = defaultdict(list)\n",
    "for word, count in mapped:\n",
    "    shuffled[word].append(count)\n",
    "\n",
    "# Fase de Reducing\n",
    "reduced = []\n",
    "for word, counts in shuffled.items():\n",
    "    reduced.append(reduce(word, counts))\n",
    "\n",
    "# Resultados finales\n",
    "for word, count in reduced:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9aa7c",
   "metadata": {},
   "source": [
    "**Optimización y escalabilidad**\n",
    "\n",
    "El verdadero poder del patrón MapReduce se revela cuando se trata de optimizar y escalar el procesamiento de datos a través de múltiples nodos en un clúster. A continuación, se describen algunas técnicas clave para mejorar el rendimiento y la escalabilidad de MapReduce.\n",
    "\n",
    "1. Particionamiento y balanceo de carga: Es fundamental dividir los datos de manera que todos los mapeadores y reductores tengan una carga de trabajo equilibrada. El particionamiento se puede lograr utilizando funciones de hash para distribuir uniformemente los datos entre los nodos.\n",
    "\n",
    "2. Compresión de datos: La compresión de datos de entrada y salida puede reducir significativamente el tiempo de E/S (entrada/salida) y el uso del ancho de banda de la red. Herramientas como Hadoop soportan múltiples formatos de compresión, como gzip y bzip2.\n",
    "\n",
    "3. Caché en memoria: El uso de caché en memoria para almacenar datos intermedios puede reducir el tiempo de acceso y mejorar el rendimiento general. Apache Spark, por ejemplo, es una alternativa a Hadoop MapReduce que utiliza intensivamente el caché en memoria.\n",
    "\n",
    "4. Tolerancia a fallos: El manejo de fallos es crucial en sistemas distribuidos. Los frameworks de MapReduce, como Hadoop, están diseñados para reintentar automáticamente las tareas fallidas y replicar datos en múltiples nodos para garantizar la disponibilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175a67f",
   "metadata": {},
   "source": [
    "**Casos de uso y aplicaciones de MapReduce**\n",
    "\n",
    "El patrón MapReduce se ha aplicado exitosamente en una amplia variedad de dominios y aplicaciones. Algunos ejemplos incluyen:\n",
    "\n",
    "1. Indexación de motores de búsqueda: Google utiliza MapReduce para indexar la web, procesando enormes cantidades de datos para construir índices de búsqueda eficientes.\n",
    "\n",
    "2. Análisis de datos en redes sociales: Las plataformas de redes sociales utilizan MapReduce para analizar patrones de uso, tendencias y conexiones entre usuarios a gran escala.\n",
    "\n",
    "3. Procesamiento de datos científicos: Instituciones científicas y de investigación utilizan MapReduce para analizar grandes conjuntos de datos, como simulaciones climáticas, secuencias genómicas y estudios astronómicos.\n",
    "\n",
    "4. Logística y comercio electrónico: Las empresas de logística y comercio electrónico utilizan MapReduce para optimizar rutas de entrega, gestionar inventarios y analizar comportamientos de compra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bcec2c",
   "metadata": {},
   "source": [
    "**MapReduce en la nube**\n",
    "\n",
    "Con la creciente adopción de la computación en la nube, MapReduce se ha convertido en una herramienta esencial para el procesamiento de datos a gran escala. Servicios en la nube como Amazon Elastic MapReduce (EMR) y Google Cloud Dataflow ofrecen implementaciones gestionadas de MapReduce, permitiendo a las organizaciones escalar rápidamente sus operaciones de datos sin preocuparse por la infraestructura subyacente. Aquí las ventajas:\n",
    "\n",
    "\n",
    "- Elasticidad: La capacidad de escalar automáticamente los recursos según la carga de trabajo permite un procesamiento eficiente y rentable.\n",
    "- Gestión simplificada: Los proveedores de la nube gestionan la infraestructura, liberando a los usuarios de la necesidad de administrar servidores y redes.\n",
    "- Accesibilidad global: Los datos y las tareas de procesamiento pueden distribuirse globalmente, mejorando la latencia y la disponibilidad.\n",
    "\n",
    "A pesar de sus numerosas ventajas, MapReduce no es adecuado para todas las tareas. Algunos desafíos y limitaciones incluyen:\n",
    "\n",
    "* Latencia: Para ciertas aplicaciones en tiempo real, la latencia de MapReduce puede ser demasiado alta.\n",
    "* Complejidad del desarrollo: Escribir trabajos MapReduce eficientes puede ser complejo y requiere un profundo conocimiento de los datos y el sistema.\n",
    "* Inflexibilidad: MapReduce sigue un modelo de programación rígido que puede no ser adecuado para todas las tareas de procesamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5af620",
   "metadata": {},
   "source": [
    "Además de las implementaciones tradicionales de MapReduce, han surgido varias alternativas y extensiones que abordan algunas de sus limitaciones:\n",
    "\n",
    "* Apache Spark: Ofrece una alternativa más rápida y flexible a Hadoop MapReduce, utilizando un modelo de procesamiento en memoria.\n",
    "* Apache Flink: Proporciona capacidades avanzadas de procesamiento en tiempo real y análisis de datos en flujo.\n",
    "* Google Cloud Dataflow: Extiende el modelo MapReduce con capacidades de procesamiento en flujo y por lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb8813c",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "\n",
    "* Explica qué es una condición de carrera y proporcione un ejemplo de un escenario en el que pueda ocurrir.\n",
    "* ¿Cómo se pueden prevenir las condiciones de carrera en un sistema multihilo? Describa al menos dos técnicas.\n",
    "* ¿Qué es una sección crítica y por qué es importante en la programación concurrente?\n",
    "* Describe cómo se puede usar un mutex para proteger una sección crítica. Incluya un pseudocódigo o fragmento de código que ilustre su uso.\n",
    "* Explica el problema productor-consumidor y su importancia en la programación concurrente.\n",
    "* ¿Cómo se puede implementar una solución al problema productor-consumidor utilizando colas y semáforos? Describe los pasos principales y proporcione un pseudocódigo.\n",
    "* Explica el problema de los filósofos cenando y los desafíos que presenta en términos de sincronización.\n",
    "* Proporciona una solución al problema utilizando mutexes o semáforos. Incluye un pseudocódigo detallado.\n",
    "* ¿Cuál es el problema de los lectores y escritores y por qué es relevante en la gestión de recursos compartidos?\n",
    "* Describe una solución al problema de los lectores y escritores que permita múltiples lectores o un único escritor acceder al recurso compartido. Usa pseudocódigo para ilustrar su respuesta.\n",
    "* Define bloqueo mutuo y describa las cuatro condiciones necesarias para que ocurra un deadlock.\n",
    "* ¿Cuáles son algunas de las estrategias para prevenir o resolver el bloqueo mutuo en sistemas concurrentes?Proporciona ejemplos concretos.\n",
    "* ¿Qué es la inanición en el contexto de la programación concurrente? Describe un escenario en el que pueda ocurrir.\n",
    "* Explica la inversión de prioridad y cómo puede afectar el rendimiento del sistema. ¿Qué técnicas se pueden utilizar para mitigar este problema?\n",
    "* Describe el patrón de diseño maestro-esclavo y su aplicación en sistemas distribuidos.\n",
    "* Proporciona un ejemplo de cómo se puede implementar el patrón maestro-esclavo para procesar un gran conjunto de datos. Incluye un pseudocódigo detallado que ilustre la comunicación entre el maestro y los esclavos.\n",
    "* Explica el patrón de diseño MapReduce y sus componentes principales: map, shuffle y reduce.\n",
    "* Describe un caso de uso en el que el patrón MapReduce sea ideal. Proporciona un ejemplo detallado y un pseudocódigo que ilustre cómo se puede implementar MapReduce para resolver este problema.\n",
    "* Compara y contraste los patrones de diseño maestro-esclavo y MapReduce. ¿En qué escenarios uno es más adecuado que el otro?\n",
    "* Describe cómo se puede combinar el patrón maestro-esclavo con MapReduce en una aplicación de procesamiento de datos distribuido. Proporciona un diagrama de flujo y un pseudocódigo para ilustrar su respuesta.\n",
    "* ¿Cuáles son algunas de las técnicas para optimizar el rendimiento de un trabajo MapReduce? Describe al menos tres técnicas y cómo cada una mejora el rendimiento.\n",
    "* Explica cómo la compresión de datos y el uso de caché en memoria pueden influir en el rendimiento de un sistema MapReduce. Proporcione ejemplos específicos.\n",
    "* ¿Cuáles son las ventajas y desventajas de utilizar un servicio gestionado de MapReduce en la nube, como Amazon EMR o Google Cloud Dataflow?\n",
    "* Describe un escenario de uso en el que implementar MapReduce en la nube sería beneficioso. Incluye una explicación detallada de los pasos involucrados en la configuración y ejecución del trabajo.\n",
    "* Diseñe un algoritmo MapReduce para contar las apariciones de palabras en un conjunto masivo de documentos almacenados en HDFS (Hadoop Distributed File System). Proporciona un pseudocódigo detallado que incluya las fases de map, shuffle y reduce.\n",
    "* Describe cómo puede utilizar los resultados del ejercicio anterior para realizar análisis adicionales, como la identificación de las palabras más frecuentes en el conjunto de documentos. Incluye un pseudocódigo para el análisis adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303dce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce4e66",
   "metadata": {},
   "source": [
    "1 .  Demuestra una condición de carrera y resolverla utilizando un Lock.\n",
    "\n",
    "- Parte A: Escribe un programa que incremente un contador global desde múltiples hilos sin utilizar ningún mecanismo de sincronización. Observa los resultados.\n",
    "\n",
    "- Parte B: Modifica el programa para utilizar un Lock y evitar la condición de carrera. Compara los resultados con la Parte A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        counter += 1\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    t = threading.Thread(target=increment)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Counter without lock:\", counter)\n",
    "\n",
    "# Parte B: Usando Lock\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment_with_lock():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    t = threading.Thread(target=increment_with_lock)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Counter with lock:\", counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe11947",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382540e6",
   "metadata": {},
   "source": [
    "2 . Implementa una sección crítica utilizando Lock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class SharedResource:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.value += 1\n",
    "\n",
    "resource = SharedResource()\n",
    "\n",
    "def worker():\n",
    "    for _ in range(100000):\n",
    "        resource.increment()\n",
    "\n",
    "threads = [threading.Thread(target=worker) for _ in range(5)]\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Final value:\", resource.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af43344",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbcab4",
   "metadata": {},
   "source": [
    "3 .  Implementa el problema productor-consumidor utilizando queue y Thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ad7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "buffer = queue.Queue(maxsize=10)\n",
    "\n",
    "def producer():\n",
    "    for i in range(20):\n",
    "        buffer.put(i)\n",
    "        print(f'Produced {i}')\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def consumer():\n",
    "    for i in range(20):\n",
    "        item = buffer.get()\n",
    "        print(f'Consumed {item}')\n",
    "        buffer.task_done()\n",
    "        time.sleep(0.2)\n",
    "\n",
    "producer_thread = threading.Thread(target=producer)\n",
    "consumer_thread = threading.Thread(target=consumer)\n",
    "\n",
    "producer_thread.start()\n",
    "consumer_thread.start()\n",
    "\n",
    "producer_thread.join()\n",
    "consumer_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b816b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995dcf51",
   "metadata": {},
   "source": [
    "4 . Implementa el problema de los filósofos cenando utilizando Lock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "class Philosopher(threading.Thread):\n",
    "    def __init__(self, name, left_fork, right_fork):\n",
    "        threading.Thread.__init__(self, name=name)\n",
    "        self.left_fork = left_fork\n",
    "        self.right_fork = right_fork\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "            self.dine()\n",
    "\n",
    "    def dine(self):\n",
    "        fork1, fork2 = self.left_fork, self.right_fork\n",
    "        while True:\n",
    "            fork1.acquire(True)\n",
    "            locked = fork2.acquire(False)\n",
    "            if locked: break\n",
    "            fork1.release()\n",
    "            fork1, fork2 = fork2, fork1\n",
    "        self.eating()\n",
    "        fork2.release()\n",
    "        fork1.release()\n",
    "\n",
    "    def eating(self):\n",
    "        print(f'{self.name} is eating.')\n",
    "        time.sleep(1)\n",
    "\n",
    "forks = [threading.Lock() for n in range(5)]\n",
    "names = ['Philosopher1', 'Philosopher2', 'Philosopher3', 'Philosopher4', 'Philosopher5']\n",
    "\n",
    "philosophers = [Philosopher(names[i], forks[i], forks[(i+1)%5]) for i in range(5)]\n",
    "\n",
    "for p in philosophers:\n",
    "    p.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39644203",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93effa6c",
   "metadata": {},
   "source": [
    "5 . Implementa el problema de los lectores y escritores utilizando Lock y Condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a78dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class ReadersWriters:\n",
    "    def __init__(self):\n",
    "        self.read_count = 0\n",
    "        self.read_lock = threading.Lock()\n",
    "        self.resource_lock = threading.Lock()\n",
    "\n",
    "    def reader(self):\n",
    "        with self.read_lock:\n",
    "            self.read_count += 1\n",
    "            if self.read_count == 1:\n",
    "                self.resource_lock.acquire()\n",
    "        print('Reading')\n",
    "        time.sleep(1)\n",
    "        with self.read_lock:\n",
    "            self.read_count -= 1\n",
    "            if self.read_count == 0:\n",
    "                self.resource_lock.release()\n",
    "\n",
    "    def writer(self):\n",
    "        with self.resource_lock:\n",
    "            print('Writing')\n",
    "            time.sleep(2)\n",
    "\n",
    "rw = ReadersWriters()\n",
    "threads = []\n",
    "\n",
    "for i in range(3):\n",
    "    t = threading.Thread(target=rw.reader)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=rw.writer)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236cf0e2",
   "metadata": {},
   "source": [
    "6 . Demuestra un escenario de deadlock y resolverlo utilizando try y finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8754bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "lock1 = threading.Lock()\n",
    "lock2 = threading.Lock()\n",
    "\n",
    "def task1():\n",
    "    while True:\n",
    "        with lock1:\n",
    "            time.sleep(0.1)\n",
    "            with lock2:\n",
    "                print(\"Task 1 completed\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def task2():\n",
    "    while True:\n",
    "        with lock2:\n",
    "            time.sleep(0.1)\n",
    "            with lock1:\n",
    "                print(\"Task 2 completed\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "t1 = threading.Thread(target=task1)\n",
    "t2 = threading.Thread(target=task2)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d47f7b5",
   "metadata": {},
   "source": [
    "7 . Demuestra la inanición e inversión de prioridad y resolverla utilizando la herencia de prioridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def low_priority_task():\n",
    "    while True:\n",
    "        with lock:\n",
    "            print(\"Low priority task\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def high_priority_task():\n",
    "    while True:\n",
    "        with lock:\n",
    "            print(\"High priority task\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "low_thread = threading.Thread(target=low_priority_task)\n",
    "high_thread = threading.Thread(target=high_priority_task)\n",
    "\n",
    "low_thread.start()\n",
    "high_thread.start()\n",
    "\n",
    "low_thread.join()\n",
    "high_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ceb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a506c",
   "metadata": {},
   "source": [
    "8 . Implementa el patrón maestro-esclavo para procesar un conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8906505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "def worker(task_queue, result_queue):\n",
    "    while True:\n",
    "        task = task_queue.get()\n",
    "        if task is None:\n",
    "            break\n",
    "        result = task * task\n",
    "        result_queue.put(result)\n",
    "        task_queue.task_done()\n",
    "\n",
    "task_queue = queue.Queue()\n",
    "result_queue = queue.Queue()\n",
    "\n",
    "num_workers = 4\n",
    "workers = []\n",
    "for _ in range(num_workers):\n",
    "    t = threading.Thread(target=worker, args=(task_queue, result_queue))\n",
    "    t.start()\n",
    "    workers.append(t)\n",
    "\n",
    "# Agregar tareas a la cola\n",
    "for i in range(20):\n",
    "    task_queue.put(i)\n",
    "\n",
    "# esperar por todas las tareas a ser procesadas\n",
    "task_queue.join()\n",
    "\n",
    "# parar los trabajadores\n",
    "for _ in range(num_workers):\n",
    "    task_queue.put(None)\n",
    "\n",
    "for t in workers:\n",
    "    t.join()\n",
    "\n",
    "# imprimir resultados\n",
    "while not result_queue.empty():\n",
    "    print(result_queue.get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41292aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cfc6b0",
   "metadata": {},
   "source": [
    "9 .  Implementa el patrón MapReduce para contar las apariciones de palabras en un conjunto de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348db237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import threading\n",
    "\n",
    "documents = [\n",
    "    \"hello world\",\n",
    "    \"hello\",\n",
    "    \"hello mapreduce world\",\n",
    "    \"mapreduce in python\",\n",
    "    \"hello mapreduce\"\n",
    "]\n",
    "\n",
    "def map_function(doc):\n",
    "    words = doc.split()\n",
    "    return [(word, 1) for word in words]\n",
    "\n",
    "def reduce_function(word, counts):\n",
    "    return (word, sum(counts))\n",
    "\n",
    "mapped = []\n",
    "for doc in documents:\n",
    "    mapped.extend(map_function(doc))\n",
    "\n",
    "shuffled = defaultdict(list)\n",
    "for word, count in mapped:\n",
    "    shuffled[word].append(count)\n",
    "\n",
    "reduced = []\n",
    "for word, counts in shuffled.items():\n",
    "    reduced.append(reduce_function(word, counts))\n",
    "\n",
    "for word, count in reduced:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
