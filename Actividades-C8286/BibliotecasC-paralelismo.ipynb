{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88148393",
   "metadata": {},
   "source": [
    "### Bibliotecas de programación paralela en C "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03293c54",
   "metadata": {},
   "source": [
    "\n",
    "### Pthreads\n",
    "\n",
    "POSIX Threads, comúnmente conocidos como Pthreads, son un estándar de la biblioteca de hilos definido por POSIX (Portable Operating System Interface) que proporciona una API para crear y gestionar hilos a nivel de usuario. Pthreads permite a los desarrolladores escribir programas concurrentes y paralelos, mejorando el rendimiento de las aplicaciones al aprovechar los sistemas de multiprocesador y los núcleos múltiples en CPUs modernas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29956b3",
   "metadata": {},
   "source": [
    "### API de Pthreads\n",
    "\n",
    "Pthreads proporciona varias funciones para gestionar hilos, algunas de las más importantes incluyen:\n",
    "\n",
    "**pthread_create:**\n",
    "\n",
    "Prototipo:`int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg);`\n",
    "\n",
    "Descripción: Crea un nuevo hilo que ejecuta la función especificada por start_routine.\n",
    "\n",
    "**pthread_join:**\n",
    "\n",
    "Prototipo: `int pthread_join(pthread_t thread, void **retval);`\n",
    "Descripción: Espera a que el hilo especificado termine y, opcionalmente, obtiene el valor devuelto por el hilo.\n",
    "\n",
    "**pthread_exit:**\n",
    "\n",
    "Prototipo: `void pthread_exit(void *retval);`\n",
    "Descripción: Termina la ejecución del hilo que llama a esta función y devuelve un valor opcional.\n",
    "\n",
    "**pthread_mutex_lock** y **pthread_mutex_unlock:**\n",
    "\n",
    "Descripción: Estas funciones se utilizan para bloquear y desbloquear un mutex, respectivamente, para asegurar la exclusión mutua en secciones críticas del código.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// mutexes \n",
    "pthread_mutex_t lock;\n",
    "pthread_mutex_init(&lock, NULL);\n",
    "\n",
    "pthread_mutex_lock(&lock);\n",
    "// Sección crítica\n",
    "pthread_mutex_unlock(&lock);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cefc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "// variables de condicion\n",
    "pthread_cond_t cond;\n",
    "pthread_mutex_t lock;\n",
    "\n",
    "pthread_mutex_lock(&lock);\n",
    "pthread_cond_wait(&cond, &lock);\n",
    "// Espera hasta que otra señal condicional despierte el hilo.\n",
    "pthread_mutex_unlock(&lock);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2595293",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Barrier\n",
    "\n",
    "pthread_barrier_t barrier;\n",
    "pthread_barrier_init(&barrier, NULL, N); // N es el número de hilos\n",
    "\n",
    "pthread_barrier_wait(&barrier);\n",
    "// Todos los hilos deben alcanzar este punto antes de continuar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c892abb",
   "metadata": {},
   "source": [
    "#### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "void* print_message(void* ptr) {\n",
    "    char* message = (char*) ptr;\n",
    "    printf(\"%s \\n\", message);\n",
    "    return NULL;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    pthread_t thread1, thread2;\n",
    "    const char* message1 = \"Hello from Thread 1\";\n",
    "    const char* message2 = \"Hello from Thread 2\";\n",
    "\n",
    "    pthread_create(&thread1, NULL, print_message, (void*) message1);\n",
    "    pthread_create(&thread2, NULL, print_message, (void*) message2);\n",
    "\n",
    "    pthread_join(thread1, NULL);\n",
    "    pthread_join(thread2, NULL);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22efa56",
   "metadata": {},
   "source": [
    "Para compilar y ejecutar: \n",
    "\n",
    "gcc -o pthreads_example pthreads_example.c -lpthread\n",
    "\n",
    "./pthreads_example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c92982",
   "metadata": {},
   "source": [
    "**Consideraciones y buenas prácticas**\n",
    "\n",
    "- Evitación de Deadlocks: Los deadlocks ocurren cuando dos o más hilos se bloquean mutuamente esperando recursos que los otros tienen. Para evitarlo, siempre adquiere los bloqueos en el mismo orden y usa técnicas como el tiempo de espera para detectar y manejar deadlocks.\n",
    "- Diseño de programas escalables: Diseña tus programas para que puedan escalar con el número de núcleos disponibles, evitando la sobrecarga excesiva de creación y destrucción de hilos.\n",
    "- Uso adecuado de sincronización: Utiliza las primitivas de sincronización adecuadas según el caso, y evita la sincronización excesiva que puede llevar a una degradación del rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550e863",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "* Explica la diferencia entre hilos (threads) y procesos.\n",
    "* ¿Qué es una condición de carrera? Proporciona un ejemplo.\n",
    "* ¿Cómo se pueden utilizar mutexes para prevenir condiciones de carrera en un programa multihilo?\n",
    "* Implementa un programa en C utilizando Pthreads que sume los elementos de un arreglo grande dividiéndolo en segmentos, donde cada segmento es sumado por un hilo diferente.\n",
    "    \n",
    "    Instrucciones:\n",
    "    * Divide el arreglo en partes iguales para cada hilo.\n",
    "    * Cada hilo debe sumar su segmento del arreglo.\n",
    "    * Los resultados parciales deben combinarse al final para obtener la suma total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8148e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92152e78",
   "metadata": {},
   "source": [
    "### OpenMP: Programación Paralela con Open Multi-Processing\n",
    "\n",
    "OpenMP, acrónimo de Open Multi-Processing, es una API (Application Programming Interface) diseñada para facilitar la programación paralela en aplicaciones de alto rendimiento. OpenMP permite a los desarrolladores escribir programas que pueden ejecutarse en sistemas multiprocesador y multinúcleo, aprovechando la capacidad de procesamiento paralelo. Introducido en 1997, OpenMP es ampliamente utilizado en la industria y en la investigación científica para acelerar el rendimiento de las aplicaciones.\n",
    "\n",
    "OpenMP facilita  el paralismo de datos con directivas que permiten distribuir bucles entre varios hilos y soporta el paralelismo de tareas mediante la creación de secciones paralelas.\n",
    "\n",
    "OpenMP sigue el modelo de memoria compartida, donde todos los hilos tienen acceso al mismo espacio de memoria. Esto permite una comunicación eficiente entre los hilos pero también requiere una sincronización adecuada para evitar condiciones de carrera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec718c",
   "metadata": {},
   "source": [
    "### API de OpenMP\n",
    "\n",
    "OpenMP proporciona un conjunto de directivas, rutinas de biblioteca y variables de entorno para la programación paralela. Las directivas de OpenMP se utilizan para especificar regiones de código que deben ejecutarse en paralelo.\n",
    "\n",
    "**Directiva #pragma omp parallel:**\n",
    "\n",
    "Esta directiva crea un equipo de hilos que ejecutan el bloque de código asociado en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        int id = omp_get_thread_num();\n",
    "        printf(\"Hello from thread %d\\n\", id);\n",
    "    }\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a609f",
   "metadata": {},
   "source": [
    "**Directiva #pragma omp for:**\n",
    "\n",
    "Se utiliza para paralelizar bucles for. Los iteradores del bucle se dividen entre los hilos disponibles.\n",
    "Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int i, n = 10;\n",
    "    int a[n];\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (i = 0; i < n; i++) {\n",
    "        a[i] = i * i;\n",
    "        printf(\"Thread %d computes a[%d] = %d\\n\", omp_get_thread_num(), i, a[i]);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db68d9",
   "metadata": {},
   "source": [
    "**Directiva #pragma omp sections:**\n",
    "\n",
    "Permite dividir el trabajo en secciones independientes que se ejecutan en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel sections\n",
    "    {\n",
    "        #pragma omp section\n",
    "        {\n",
    "            printf(\"Section 1 executed by thread %d\\n\", omp_get_thread_num());\n",
    "        }\n",
    "        #pragma omp section\n",
    "        {\n",
    "            printf(\"Section 2 executed by thread %d\\n\", omp_get_thread_num());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bcfbc",
   "metadata": {},
   "source": [
    "**Variables privadas y compartidas:**\n",
    "\n",
    "- Privadas: Cada hilo tiene su propia copia de la variable.\n",
    "- Compartidas: Todas las variables globales y estáticas son compartidas por defecto entre los hilos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "int x;\n",
    "#pragma omp parallel private(x)\n",
    "{\n",
    "    x = omp_get_thread_num();\n",
    "    printf(\"Thread %d has private x = %d\\n\", omp_get_thread_num(), x);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d107fee",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// openmp_example.c\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        int id = omp_get_thread_num();\n",
    "        printf(\"Hello from thread %d\\n\", id);\n",
    "    }\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a1e79",
   "metadata": {},
   "source": [
    "Para compilar y ejecutar:\n",
    "\n",
    "gcc -o openmp_example openmp_example.c -fopenmp\n",
    "\n",
    "./openmp_example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7214a5f",
   "metadata": {},
   "source": [
    "#### Sincronización en OpenMP\n",
    "\n",
    "La sincronización es crucial para evitar conflictos y asegurar la coherencia de los datos en programas paralelos. OpenMP proporciona varios mecanismos de sincronización:\n",
    "\n",
    "**Directiva #pragma omp critical:**\n",
    "\n",
    "Define una sección crítica del código que solo puede ser ejecutada por un hilo a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int sum = 0;\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        #pragma omp critical\n",
    "        sum += i;\n",
    "    }\n",
    "    printf(\"Sum = %d\\n\", sum);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a097f",
   "metadata": {},
   "source": [
    "**Directiva #pragma omp barrier:**\n",
    "\n",
    "Hace que todos los hilos esperen en este punto hasta que todos los hilos del equipo hayan llegado a la barrera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978010b1",
   "metadata": {},
   "source": [
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        int id = omp_get_thread_num();\n",
    "        printf(\"Before barrier - Thread %d\\n\", id);\n",
    "        #pragma omp barrier\n",
    "        printf(\"After barrier - Thread %d\\n\", id);\n",
    "    }\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a934b10",
   "metadata": {},
   "source": [
    "**Directiva #pragma omp atomic:**\n",
    "\n",
    "Garantiza que una operación de actualización de memoria se realice de forma atómica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8462b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int count = 0;\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < 1000; i++) {\n",
    "        #pragma omp atomic\n",
    "        count++;\n",
    "    }\n",
    "    printf(\"Count = %d\\n\", count);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98e57f",
   "metadata": {},
   "source": [
    "**Consideraciones y buenas prácticas**\n",
    "\n",
    "- Balanceo de Carga: Es importante asegurar que el trabajo se distribuya equitativamente entre los hilos para evitar el sobrecarga de algunos hilos mientras otros están inactivos.\n",
    "- Minimización de sincronización: Aunque la sincronización es necesaria, debe ser minimizada para reducir el overhead y mejorar la eficiencia.\n",
    "- Debugging: La depuración de programas paralelos puede ser más compleja que en programas secuenciales. Herramientas especializadas y técnicas de logging pueden ser útiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621944c",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "- Describe cómo funciona la directiva #pragma omp parallel y su uso en un programa.\n",
    "- ¿Qué es la directiva #pragma omp for y cómo se utiliza para paralelizar bucles?\n",
    "- Explica la diferencia entre las variables privadas y compartidas en el contexto de OpenMP\n",
    "- Escribe un programa en C que realice la multiplicación de dos matrices utilizando OpenMP para paralelizar el cálculo.\n",
    "\n",
    "    Instrucciones:\n",
    "    * Inicializa dos matrices de tamaño NxN con valores aleatorios.\n",
    "    * Utiliza #pragma omp parallel for para paralelizar el bucle de multiplicación de matrices.\n",
    "    * Asegúrate de manejar correctamente las variables compartidas y privadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10deac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6750e",
   "metadata": {},
   "source": [
    "### MPI: Interfaz de paso de mensajes (Message Passing Interface)\n",
    "\n",
    "\n",
    "MPI, acrónimo de Message Passing Interface, es un estándar para la programación paralela que permite la comunicación y coordinación entre procesos que se ejecutan en un entorno distribuido. MPI es ampliamente utilizado en aplicaciones de computación de alto rendimiento (HPC), tales como simulaciones científicas, análisis de grandes datos y procesamiento de imágenes. Introducido en 1994, MPI proporciona una plataforma robusta y flexible para desarrollar aplicaciones que pueden escalar desde unas pocas máquinas hasta miles de nodos en supercomputadoras.\n",
    "\n",
    "MPI se basa en el modelo de memoria distribuida.\n",
    "\n",
    "En MPI, los programas están compuestos por múltiples procesos independientes que pueden ejecutarse en diferentes nodos de una red.\n",
    "La comunicación entre procesos se realiza mediante el envío y recepción de mensajes. MPI proporciona una variedad de funciones para la comunicación punto a punto y colectiva.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2ed5d",
   "metadata": {},
   "source": [
    "**API de MPI**\n",
    "\n",
    "MPI define una serie de funciones que permiten la inicialización, comunicación y finalización de programas paralelos. Algunas de las funciones más importantes incluyen:\n",
    "\n",
    "MPI_Init y MPI_Finalize:\n",
    "\n",
    "Prototipos: `int MPI_Init(int *argc, char ***argv);` y `int MPI_Finalize(void);`\n",
    "\n",
    "Descripción: `MPI_Init` inicializa el entorno MPI, y `MPI_Finalize` lo finaliza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    printf(\"Hello, MPI World!\\n\");\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0a42e",
   "metadata": {},
   "source": [
    "MPI_Comm_size y MPI_Comm_rank:\n",
    "\n",
    "Prototipos: `int MPI_Comm_size(MPI_Comm comm, int *size);` y `int MPI_Comm_rank(MPI_Comm comm, int *rank);`\n",
    "\n",
    "Descripción: MPI_Comm_size obtiene el número de procesos en el comunicador, y MPI_Comm_rank obtiene el identificador (rango) del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int world_size, world_rank;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "\n",
    "    printf(\"Hello from process %d of %d\\n\", world_rank, world_size);\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e530f8e",
   "metadata": {},
   "source": [
    "MPI_Send y MPI_Recv:\n",
    "\n",
    "Prototipos: `int MPI_Send(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm);` y `int MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status);`\n",
    "\n",
    "Descripción: MPI_Send envía un mensaje a un proceso destino, y MPI_Recv recibe un mensaje de un proceso fuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383748d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int world_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "\n",
    "    if (world_rank == 0) {\n",
    "        int number = 42;\n",
    "        MPI_Send(&number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
    "    } else if (world_rank == 1) {\n",
    "        int number;\n",
    "        MPI_Recv(&number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Process 1 received number %d from process 0\\n\", number);\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33c874",
   "metadata": {},
   "source": [
    "MPI_Bcast:\n",
    "\n",
    "Prototipo: `int MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm);`\n",
    "\n",
    "Descripción: Difunde un mensaje desde el proceso raíz a todos los demás procesos en el comunicador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53644be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int world_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "\n",
    "    int data = 0;\n",
    "    if (world_rank == 0) {\n",
    "        data = 100;\n",
    "    }\n",
    "\n",
    "    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    printf(\"Process %d received data %d\\n\", world_rank, data);\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c06fe",
   "metadata": {},
   "source": [
    "MPI_Reduce:\n",
    "\n",
    "Prototipo: `int MPI_Reduce(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm);`\n",
    "\n",
    "Descripción: Realiza una operación de reducción (como suma, máximo, etc.) sobre los datos distribuidos y recoge el resultado en el proceso raíz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f620da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int world_rank, world_size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "\n",
    "    int local_data = world_rank;\n",
    "    int global_sum;\n",
    "\n",
    "    MPI_Reduce(&local_data, &global_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    if (world_rank == 0) {\n",
    "        printf(\"Sum of all ranks is %d\\n\", global_sum);\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f39a6",
   "metadata": {},
   "source": [
    "MPI proporciona varias funciones para sincronizar procesos y garantizar la coherencia de los datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a4ba1",
   "metadata": {},
   "source": [
    "MPI_Barrier:\n",
    "\n",
    "Prototipo: `int MPI_Barrier(MPI_Comm comm);`\n",
    "\n",
    "Descripción: Bloquea hasta que todos los procesos en el comunicador han llegado a este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea03f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    MPI_Barrier(MPI_COMM_WORLD);\n",
    "\n",
    "    printf(\"All processes reached the barrier.\\n\");\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e77a0",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// mpi_example.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int world_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "\n",
    "    int world_size;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "\n",
    "    printf(\"Hello from rank %d out of %d processors\\n\", world_rank, world_size);\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4936521",
   "metadata": {},
   "source": [
    "Para compilar y ejecutar:\n",
    "\n",
    "mpicc -o mpi_example mpi_example.c\n",
    "\n",
    "mpirun -np 4 ./mpi_example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b7638",
   "metadata": {},
   "source": [
    "**Ejemplo práctico de MPI**\n",
    "\n",
    "Un ejemplo sencillo que ilustra el uso de MPI para calcular la suma de elementos en un arreglo distribuido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544eadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int world_size, world_rank;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "\n",
    "    int n = 100;\n",
    "    int *data = NULL;\n",
    "    int local_n = n / world_size;\n",
    "    int *local_data = (int*)malloc(local_n * sizeof(int));\n",
    "\n",
    "    if (world_rank == 0) {\n",
    "        data = (int*)malloc(n * sizeof(int));\n",
    "        for (int i = 0; i < n; i++) {\n",
    "            data[i] = i + 1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    MPI_Scatter(data, local_n, MPI_INT, local_data, local_n, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    int local_sum = 0;\n",
    "    for (int i = 0; i < local_n; i++) {\n",
    "        local_sum += local_data[i];\n",
    "    }\n",
    "\n",
    "    int global_sum;\n",
    "    MPI_Reduce(&local_sum, &global_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    if (world_rank == 0) {\n",
    "        printf(\"Total sum = %d\\n\", global_sum);\n",
    "        free(data);\n",
    "    }\n",
    "\n",
    "    free(local_data);\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d6db0",
   "metadata": {},
   "source": [
    "**Consideraciones y buenas prácticas**\n",
    "\n",
    "- Escalabilidad: Diseña tu programa para escalar eficientemente a medida que aumentas el número de procesos.\n",
    "- Evitación de deadlocks: Asegúrate de que las operaciones de comunicación no provoquen bloqueos.\n",
    "- Optimización de comunicación: Minimiza la comunicación innecesaria entre procesos para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca586afd",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "- Explica el modelo de comunicación de MPI y cómo difiere de la comunicación basada en hilos.\n",
    "- Describe las funciones básicas de MPI para enviar y recibir mensajes (MPI_Send y MPI_Recv).\n",
    "- ¿Qué es MPI_Barrier y cuándo se debe utilizar?\n",
    "- Implementa un programa en C utilizando MPI donde el proceso de rank 0 envíe un mensaje a todos los demás procesos utilizando MPI_Bcast.\n",
    "\n",
    "    Instrucciones:\n",
    "    * Inicializa MPI y determina el rank del proceso.\n",
    "    * Si el proceso tiene rank 0, inicializa un mensaje y utiliza MPI_Bcast para enviarlo a todos los demás procesos.\n",
    "    * Los otros procesos deben recibir el mensaje y mostrarlo en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C",
   "language": "c",
   "name": "c"
  },
  "language_info": {
   "file_extension": ".c",
   "mimetype": "text/plain",
   "name": "c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
