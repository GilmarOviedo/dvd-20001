{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b98b262-f666-422f-bacb-9a110c93f835",
   "metadata": {},
   "source": [
    "### Algoritmos paralelos\n",
    "\n",
    "Los algoritmos paralelos son una categoría de algoritmos diseñados para aprovechar las capacidades de procesamiento paralelo de las computadoras modernas, permitiendo la ejecución simultánea de múltiples tareas. A medida que los procesadores multinúcleo y los sistemas de computación distribuida se han vuelto más comunes, el desarrollo y la implementación de algoritmos paralelos se ha vuelto esencial para mejorar el rendimiento y la eficiencia de muchas aplicaciones. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e69de4-31c1-4c91-b4d3-a6f8b00797ea",
   "metadata": {},
   "source": [
    "### Conceptos fundamentales\n",
    "\n",
    "El campo de los algoritmos paralelos es esencial para el avance de machine learning (ML) y deep learning (DL). La capacidad de procesar grandes volúmenes de datos y ejecutar complejas operaciones matemáticas de manera eficiente es crucial para el desarrollo y la implementación de modelos de aprendizaje automático y profundo.\n",
    "\n",
    "\n",
    "**Descomposición de datos**\n",
    "\n",
    "En ML y DL, la descomposición de datos es una técnica fundamental. Consiste en dividir grandes conjuntos de datos en fragmentos más pequeños que pueden ser procesados simultáneamente por múltiples unidades de procesamiento. Esta técnica es particularmente útil en la fase de entrenamiento de modelos de DL, donde los datos de entrenamiento pueden ser distribuidos entre diferentes GPUs o nodos de un clúster de computación.\n",
    "\n",
    "**Descomposición de tareas**\n",
    "\n",
    "La descomposición de tareas implica dividir un algoritmo en partes más pequeñas, cada una de las cuales puede ejecutarse en paralelo. En DL, esto puede aplicarse a la arquitectura del modelo, donde diferentes capas de una red neuronal profunda pueden ser computadas simultáneamente, o en algoritmos de optimización donde múltiples instancias de una función objetivo pueden evaluarse en paralelo.\n",
    "\n",
    "**Granularidad y overhead**\n",
    "\n",
    "La granularidad se refiere al tamaño de las tareas individuales en las que se divide un problema. En el contexto de ML y DL, una granularidad adecuada puede influir significativamente en el rendimiento del algoritmo paralelo.\n",
    "\n",
    "- Granularidad fina: Implica dividir el problema en tareas muy pequeñas. Aunque esto puede aprovechar mejor la paralelización, el overhead de comunicación entre tareas puede ser alto, lo que reduce la eficiencia general.\n",
    "- Granularidad gruesa: Divide el problema en tareas más grandes, reduciendo el overhead de comunicación. Esto es común en sistemas donde las tareas individuales son relativamente independientes y no requieren comunicación frecuente.\n",
    "\n",
    "**Sincronización y comunicación**\n",
    "\n",
    "- Sincronización: La sincronización asegura que las tareas paralelas se coordinen adecuadamente, especialmente cuando comparten recursos. En ML y DL, esto es crucial para operaciones como la actualización de parámetros del modelo en algoritmos de entrenamiento distribuidos.\n",
    "- Locks y semáforos: Se utilizan para controlar el acceso a recursos compartidos, garantizando que no se produzcan condiciones de carrera.\n",
    "- Barreras: Aseguran que todas las tareas lleguen a un cierto punto antes de continuar, lo que es esencial en el entrenamiento sincronizado de redes neuronales distribuidas.\n",
    "\n",
    "**Comunicación**\n",
    "\n",
    "La comunicación eficiente entre tareas es esencial para el rendimiento de algoritmos paralelos en ML y DL. Existen dos modelos principales:\n",
    "\n",
    "- Memoria compartida: Las tareas acceden a un espacio de memoria común. Este modelo es eficiente pero puede ser problemático debido a las condiciones de carrera.\n",
    "- Pasaje de mensajes: Las tareas se comunican enviando y recibiendo mensajes. Este modelo es más adecuado para sistemas distribuidos, como el entrenamiento de modelos en clústeres de computación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec8aa5-e7fd-4a44-ae9f-23f1848cf881",
   "metadata": {},
   "source": [
    "### Técnicas de paralelización en machine learning y deep learning\n",
    "\n",
    "**Paralelización de datos**\n",
    "\n",
    "La paralelización de datos es ampliamente utilizada en DL, donde los datos de entrenamiento se dividen entre múltiples GPUs o nodos. Cada unidad de procesamiento entrena una copia del modelo en su subconjunto de datos y luego combina los gradientes calculados para actualizar los parámetros del modelo global.\n",
    "\n",
    "**Paralelización de modelos**\n",
    "\n",
    "En redes neuronales muy grandes, la paralelización de modelos divide el modelo en diferentes partes que se distribuyen entre varias GPUs. Por ejemplo, diferentes capas de una red pueden ser asignadas a diferentes GPUs, permitiendo que cada GPU procese su parte del modelo en paralelo.\n",
    "\n",
    "**Pipeline de datos**\n",
    "\n",
    "El pipeline de datos es una técnica donde las operaciones de preprocesamiento y entrenamiento se solapan. Mientras una parte de los datos está siendo procesada, otra parte está siendo utilizada para entrenar el modelo. Esto maximiza el uso de recursos y reduce el tiempo de inactividad.\n",
    "\n",
    "**Entrenamiento distribuido**\n",
    "\n",
    "El entrenamiento distribuido es una técnica donde múltiples nodos colaboran para entrenar un modelo. Existen dos enfoques principales:\n",
    "\n",
    "- Entrenamiento sincronizado: Todos los nodos deben completar su cálculo antes de que los parámetros del modelo sean actualizados.\n",
    "- Entrenamiento asincronizado: Los nodos actualizan los parámetros del modelo de manera independiente, lo que puede conducir a una convergencia más rápida pero también introduce desafíos de coherencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8405aa6f-676f-40c9-a922-cd131af18e3a",
   "metadata": {},
   "source": [
    "### Algoritmos paralelos en machine learning y deep learning\n",
    "\n",
    "**Paralelización de datos (data parallelism)**\n",
    "\n",
    "La paralelización de datos es una técnica ampliamente utilizada en ML y DL, donde los datos se dividen en fragmentos y se procesan simultáneamente en múltiples unidades de procesamiento. Esta técnica es especialmente efectiva en el entrenamiento de modelos de DL, donde grandes conjuntos de datos se distribuyen entre varias GPUs o nodos de un clúster.\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "- Entrenamiento de redes neuronales: Los datos de entrenamiento se dividen entre varias GPUs, cada una de las cuales calcula los gradientes para su subconjunto de datos. Luego, los gradientes se combinan para actualizar los parámetros del modelo global.\n",
    "- Gradient Boosting Machines (GBM): En GBM, los árboles se construyen secuencialmente, pero los cálculos de gradientes y actualizaciones pueden paralelizarse.\n",
    "\n",
    "**Paralelización de modelos (model parallelism)**\n",
    "En redes neuronales muy grandes, la paralelización de modelos divide el modelo entre múltiples GPUs. Cada GPU se encarga de una parte del modelo, lo que permite manejar arquitecturas que de otro modo no cabrían en la memoria de una sola GPU.\n",
    "\n",
    "Ejemplos:\n",
    "- Redes neuronales convolucionales (CNNs): Las diferentes capas de una CNN pueden ser asignadas a distintas GPUs para procesarse en paralelo.\n",
    "- Redes neuronales recursivas (RNNs): Las secuencias de datos largas se pueden dividir entre múltiples GPUs, donde cada GPU procesa una subsecuencia.\n",
    "\n",
    "**Pipeline parallelism**\n",
    "\n",
    "El pipeline parallelism divide las operaciones de preprocesamiento y entrenamiento en una serie de etapas secuenciales, donde cada etapa se ejecuta en paralelo. Esto maximiza la utilización de recursos y minimiza el tiempo de inactividad.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Transformers: En modelos como BERT, diferentes capas de autoatención pueden procesarse en paralelo usando pipeline parallelism, mejorando la eficiencia del entrenamiento.\n",
    "\n",
    "**Algoritmos de optimización paralelos**\n",
    "\n",
    "Los algoritmos de optimización paralelos son esenciales para acelerar el entrenamiento de modelos complejos en ML y DL. Métodos como el descenso de gradiente estocástico (SGD) se pueden paralelizar fácilmente.\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "- SGD paralelo: Los datos se dividen entre varios nodos, cada uno calculando los gradientes de forma independiente. Luego, los gradientes se agregan para actualizar los parámetros del modelo global.\n",
    "- Métodos de Monte Carlo: Los métodos de Monte Carlo se pueden paralelizar evaluando múltiples muestras simultáneamente, útil en optimización estocástica y aprendizaje por refuerzo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec0d6f-dc61-4cef-b97a-c8d5be5ca5a7",
   "metadata": {},
   "source": [
    "### Algoritmos paralelos en sistemas distribuidos\n",
    "\n",
    "**MapReduce**\n",
    "\n",
    "MapReduce es un modelo de programación que permite el procesamiento y la generación de grandes conjuntos de datos mediante un modelo de pares clave-valor. Este modelo distribuye el trabajo en dos fases principales: Map y Reduce, facilitando la paralelización de tareas de procesamiento de datos en un clúster.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Procesamiento de Logs: Los logs se dividen en fragmentos y se distribuyen entre varios nodos para el procesamiento paralelo. Los resultados parciales se combinan en la fase de reducción para generar la salida final.\n",
    "\n",
    "**Clustering (cluster computing)**\n",
    "\n",
    "La computación en grupos utiliza múltiples nodos de un clúster para ejecutar tareas paralelas. Frameworks como Apache Hadoop y Apache Spark permiten la ejecución eficiente de tareas distribuidas.\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "- Análisis de grandes datos (big data analytics): Herramientas como Spark permiten procesar y analizar grandes volúmenes de datos en paralelo, utilizando operaciones como transformaciones y acciones distribuidas.\n",
    "\n",
    "**Programación de pasaje de mensajes (Message Passing Interface, MPI)**\n",
    "\n",
    "MPI es un estándar para la programación paralela que permite a los desarrolladores escribir programas que pueden ejecutarse en sistemas distribuidos, facilitando la comunicación entre nodos mediante el paso de mensajes.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Simulaciones científicas: Las simulaciones que requieren grandes cantidades de cálculo pueden distribuirse entre múltiples nodos utilizando MPI para comunicarse y sincronizarse.\n",
    "\n",
    "**Algoritmos distribuidos**\n",
    "\n",
    "Los algoritmos distribuidos están diseñados para sistemas donde los componentes son nodos autónomos que interactúan mediante comunicación de red. Estos algoritmos se utilizan para resolver problemas donde la información y el control están distribuidos.\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "- Algoritmos de Consenso: En sistemas distribuidos, los algoritmos de consenso como Paxos y Raft aseguran que todos los nodos acuerden un valor único, crucial para la consistencia de los datos.\n",
    "- Algoritmos de elección de líder: Estos algoritmos determinan un líder entre un grupo de nodos, utilizado en sistemas distribuidos para coordinar actividades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e93f47-1c87-4c92-bc4c-23434da648e0",
   "metadata": {},
   "source": [
    "### Algoritmos paralelos en la nube\n",
    "\n",
    "**Funciones como servicio (function as a service, FaaS)**\n",
    "\n",
    "FaaS permite ejecutar fragmentos de código en respuesta a eventos sin la necesidad de gestionar servidores. Las plataformas en la nube como AWS Lambda, Google Cloud Functions y Azure Functions facilitan la paralelización y el escalado automático de tareas.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Procesamiento de imágenes: Las imágenes subidas a un almacenamiento en la nube pueden desencadenar funciones Lambda que procesan las imágenes en paralelo, aplicando filtros o análisis.\n",
    "- \n",
    "**Infraestructura como servicio (IaaS)**\n",
    "  \n",
    "IaaS proporciona recursos de computación virtualizados que pueden ser escalados según las necesidades del usuario. Esto permite la ejecución paralela de algoritmos de ML y DL en instancias de máquinas virtuales.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Entrenamiento de modelos en EC2: Utilizando instancias EC2 con múltiples GPUs, los modelos de DL pueden ser entrenados en paralelo, reduciendo significativamente el tiempo de entrenamiento.\n",
    "\n",
    "**Kubernetes y contenedores**\n",
    "\n",
    "Kubernetes es una plataforma de orquestación de contenedores que permite gestionar y escalar aplicaciones en contenedores. Los contenedores proporcionan un entorno aislado y consistente para la ejecución de aplicaciones, facilitando la paralelización y el despliegue en la nube.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Microservicios: Los microservicios que componen una aplicación se despliegan en contenedores, y Kubernetes gestiona la distribución y escalado de estos contenedores, permitiendo una ejecución paralela eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be1b38-d0c9-484f-b740-d0428ada2cf3",
   "metadata": {},
   "source": [
    "### Plataformas de machine learning en la nube\n",
    "\n",
    "Plataformas como AWS SageMaker, Google AI Platform y Azure Machine Learning proporcionan herramientas para la construcción, entrenamiento y despliegue de modelos de ML y DL en la nube. Estas plataformas soportan la paralelización automática de tareas.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Entrenamiento distribuido en SageMaker: SageMaker distribuye automáticamente el entrenamiento de modelos en múltiples nodos y GPUs, optimizando el uso de recursos y acelerando el proceso de entrenamiento.\n",
    "\n",
    "**Almacenamiento y procesamiento de datos en la nube**\n",
    "\n",
    "El almacenamiento y procesamiento de grandes volúmenes de datos es fundamental para ML y DL. Servicios como Amazon S3, Google Cloud Storage y Azure Blob Storage permiten almacenar datos de manera distribuida y acceder a ellos de forma paralela.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- Procesamiento de datos en BigQuery: Google BigQuery permite la ejecución de consultas SQL en grandes conjuntos de datos almacenados en la nube, procesando los datos en paralelo para obtener resultados rápidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5649f7-e6e1-4c29-934c-e5b262372a69",
   "metadata": {},
   "source": [
    "### Implementaciones\n",
    "\n",
    "#### Entrenamiento de redes neuronales con datos divididos entre varias GPUs\n",
    "\n",
    "El entrenamiento de redes neuronales a gran escala se puede acelerar significativamente mediante la paralelización de datos. En este enfoque, el conjunto de datos de entrenamiento se divide entre varias GPUs. Cada GPU calcula los gradientes para su subconjunto de datos y, posteriormente, estos gradientes se combinan para actualizar los parámetros del modelo global. Este método se conoce como Data Parallelism.\n",
    "\n",
    "Implementación:\n",
    "\n",
    "- Los datos de entrada se dividen en fragmentos y se distribuyen entre las GPUs disponibles.\n",
    "- Cada GPU realiza el cálculo de gradientes en su subconjunto de datos.\n",
    "-  Los gradientes calculados por cada GPU se combinan (generalmente mediante una operación de reducción, como all-reduce) para actualizar los parámetros del modelo global.\n",
    "\n",
    "#### Gradient Boosting Machines (GBM)\n",
    "El algoritmo GBM construye árboles de decisión secuencialmente, donde cada árbol intenta corregir los errores cometidos por los árboles anteriores. Sin embargo, los cálculos de gradientes y actualizaciones de los parámetros pueden paralelizarse.\n",
    "\n",
    "Implementación:\n",
    "- Inicia con una predicción base.\n",
    "- Cada árbol se construye en función del gradiente de la pérdida respecto a la predicción actual.\n",
    "- Aunque la construcción de árboles es secuencial, los cálculos de gradientes y ajustes pueden realizarse en paralelo.\n",
    "\n",
    "#### Redes neuronales convolucionales (CNNs)\n",
    "\n",
    "Las CNNs son particularmente adecuadas para la paralelización debido a la naturaleza independiente de las convoluciones en diferentes filtros y capas. En Model Parallelism, diferentes capas de una CNN pueden ser asignadas a distintas GPUs para procesarse en paralelo.\n",
    "\n",
    "Implementación:\n",
    "\n",
    "- Divide las capas de la red entre las GPUs.\n",
    "- Cada GPU realiza el forward pass de su conjunto de capas.\n",
    "- Las GPUs calculan los gradientes y los combinan para actualizar los parámetros.\n",
    "\n",
    "#### Redes neuronales recursivas (RNNs)\n",
    "Las RNNs son utilizadas para datos secuenciales y pueden ser paralelizadas mediante la división de secuencias largas entre múltiples GPUs. Cada GPU procesa una subsecuencia, lo que mejora la eficiencia del entrenamiento.\n",
    "\n",
    "Implementación:\n",
    "\n",
    "- Divide la secuencia de entrada en subsecuencias.\n",
    "- Cada GPU procesa su subsecuencia.\n",
    "- Los resultados de cada subsecuencia se combinan para la actualización del modelo.\n",
    "\n",
    "#### Transformers\n",
    "Los modelos de transformers, como BERT, utilizan múltiples capas de autoatención que pueden ser paralelizadas utilizando Pipeline Parallelism. Esto implica que diferentes capas de autoatención se procesan en paralelo, mejorando la eficiencia del entrenamiento.\n",
    "\n",
    "Implementación:\n",
    "\n",
    "- Divide las capas del transformer en etapas.\n",
    "- Procesa cada etapa en paralelo.\n",
    "- Asegura que las etapas se sincronizan correctamente.\n",
    "\n",
    "#### SGD paralelo\n",
    "El descenso de gradiente estocástico (SGD) puede paralelizarse dividiendo los datos de entrenamiento entre varios nodos. Cada nodo calcula los gradientes de forma independiente y luego se combinan para actualizar los parámetros del modelo global.\n",
    "\n",
    "Implementación:\n",
    "\n",
    "- Los datos de entrenamiento se dividen entre los nodos.\n",
    "- Cada nodo calcula los gradientes para su subconjunto de datos.\n",
    "- Los gradientes se combinan para actualizar los parámetros del modelo global.\n",
    "\n",
    "#### Métodos de Monte Carlo\n",
    "Los métodos de Monte Carlo son utilizados en optimización estocástica y aprendizaje por refuerzo. Pueden ser paralelizados evaluando múltiples muestras simultáneamente.\n",
    "\n",
    "Implementación\n",
    "\n",
    "- Genera múltiples muestras simultáneamente.\n",
    "- Evalua las muestras en paralelo.\n",
    "- Combina los resultados para la actualización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fcf58e-3bdf-4be5-83df-532a47a0071b",
   "metadata": {},
   "source": [
    "Entrenamiento de redes neuronales con datos divididos entre varias GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4c638-0b08-4bbf-a97e-1baa5febe771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Modelo de ejemplo\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Creación de un dataset de ejemplo\n",
    "x = torch.randn(10000, 784)\n",
    "y = torch.randint(0, 10, (10000,))\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# División del modelo entre múltiples GPUs\n",
    "model = SimpleNN().to(device)\n",
    "if num_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(10):\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoca {epoch+1}, Perdida: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Modelo de ejemplo\n",
    "class SimpleNN(models.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = layers.Dense(256, activation='relu')\n",
    "        self.fc2 = layers.Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Creación de un dataset de ejemplo\n",
    "x = tf.random.normal((10000, 784))\n",
    "y = tf.random.uniform((10000,), maxval=10, dtype=tf.int32)\n",
    "dataset = Dataset.from_tensor_slices((x, y)).shuffle(10000).batch(32)\n",
    "\n",
    "# División del modelo entre múltiples GPUs\n",
    "with tf.device(device):\n",
    "    model = SimpleNN()\n",
    "\n",
    "if num_gpus > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = SimpleNN()\n",
    "        optimizer = optimizers.SGD(learning_rate=0.01)\n",
    "        criterion = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "else:\n",
    "    optimizer = optimizers.SGD(learning_rate=0.01)\n",
    "    criterion = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer=optimizer, loss=criterion)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(10):\n",
    "    for data, target in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(data, training=True)\n",
    "            loss = criterion(target, output)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    print(f\"Epoca {epoch+1}, Perdida: {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f194ea-7bf6-46f3-821c-9abbd44b5361",
   "metadata": {},
   "source": [
    "Para ilustrar cómo paralelizar los cálculos de gradientes en GBM, usaremos lightgbm que soporta paralelización de manera nativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ebba5-a1c8-43ae-925a-c8f3daff0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generación de un dataset de ejemplo\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_classes=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Creación del dataset de LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# Configuración del modelo\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'n_jobs': -1  # Usar múltiples núcleos para la paralelización\n",
    "}\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "bst = lgb.train(params, train_data, valid_sets=[test_data], num_boost_round=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ba9ab-34a3-42a6-b340-fec8cfa90c3e",
   "metadata": {},
   "source": [
    "Redes Neuronales Convolucionales (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403cb61-5784-4ef8-97e6-3bd676794d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Modelo de ejemplo (CNN)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64 * 24 * 24, 128)  # Ajustar las dimensiones\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)  # Cambia a esta línea para aplanar correctamente\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Carga de datos de ejemplo (MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# División del modelo entre múltiples GPUs\n",
    "model = SimpleCNN().to(device)\n",
    "if num_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(10):\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoca {epoch+1}, Perdida: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2024cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Modelo de ejemplo (CNN)\n",
    "class SimpleCNN(models.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, kernel_size=3, activation='relu')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation='relu')\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(128, activation='relu')\n",
    "        self.fc2 = layers.Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Carga de datos de ejemplo (MNIST)\n",
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = y_train.astype('int32')\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(64)\n",
    "\n",
    "# División del modelo entre múltiples GPUs\n",
    "with tf.device(device):\n",
    "    model = SimpleCNN()\n",
    "\n",
    "if num_gpus > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = SimpleCNN()\n",
    "        optimizer = optimizers.SGD(learning_rate=0.01)\n",
    "        criterion = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "else:\n",
    "    optimizer = optimizers.SGD(learning_rate=0.01)\n",
    "    criterion = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer=optimizer, loss=criterion)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(10):\n",
    "    for data, target in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(data, training=True)\n",
    "            loss = criterion(target, output)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    print(f\"Epoca {epoch+1}, Perdida: {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02ce90-8192-4ee1-98ca-d9bc05251a1b",
   "metadata": {},
   "source": [
    "Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ce81c-331e-4f48-b40c-fbace7b4bac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Modelo de ejemplo (BERT)\n",
    "class SimpleBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc = nn.Linear(768, 2)  # Suponiendo una tarea de clasificación binaria\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)[0]\n",
    "        x = self.fc(x[:, 0, :])\n",
    "        return x\n",
    "\n",
    "# Tokenización de ejemplo\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "texts = [\"Example sentence fo BERT model.\"] * 10\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# División del modelo entre múltiples GPUs\n",
    "model = SimpleBERT().to(device)\n",
    "if num_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs['input_ids'].to(device))\n",
    "    loss = criterion(outputs, torch.tensor([1]*10).to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoca{epoch+1}, Entrenamiento: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow.keras import layers, optimizers, losses\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Modelo de ejemplo (BERT)\n",
    "class SimpleBERT(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleBERT, self).__init__()\n",
    "        self.bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc = layers.Dense(2)  # Suponiendo una tarea de clasificación binaria\n",
    "\n",
    "    def call(self, inputs):\n",
    "        bert_output = self.bert(inputs)[0]\n",
    "        cls_output = bert_output[:, 0, :]\n",
    "        output = self.fc(cls_output)\n",
    "        return output\n",
    "\n",
    "# Tokenización de ejemplo\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "texts = [\"Example sentence for BERT model.\"] * 10\n",
    "inputs = tokenizer(texts, return_tensors='tf', padding=True, truncation=True)\n",
    "\n",
    "# División del modelo entre múltiples GPUs\n",
    "if num_gpus > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = SimpleBERT()\n",
    "        optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "        criterion = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "else:\n",
    "    model = SimpleBERT()\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    criterion = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer=optimizer, loss=criterion)\n",
    "\n",
    "# Etiquetas de ejemplo\n",
    "labels = tf.constant([1] * 10)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(inputs['input_ids'])\n",
    "        loss = criterion(labels, outputs)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    print(f\"Epoca {epoch+1}, Entrenamiento: {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b96cfb-7f67-4b2b-b7f0-84ba3502a74c",
   "metadata": {},
   "source": [
    "Para ilustrar cómo paralelizar el SGD, utilizamos `torch.distributed` para implementar el paralelismo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5e762-1e0a-4de9-8fe3-a51b063d3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "def demo_basic(rank, world_size):\n",
    "    print(f\"Proceso {rank} empezando...\")\n",
    "    setup(rank, world_size)\n",
    "    print(f\"Proceso {rank} ha completado la configuración.\")\n",
    "    \n",
    "    try:\n",
    "        model = ToyModel().to(rank)\n",
    "        ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "        dataset = torch.randn(20, 10)\n",
    "        targets = torch.randn(20, 5)\n",
    "\n",
    "        for epoch in range(10):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ddp_model(dataset.to(rank))\n",
    "            loss = loss_fn(outputs, targets.to(rank))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if rank == 0:\n",
    "                print(f\"Epoca {epoch+1}, Perdida: {loss.item()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Proceso {rank} encontró un error: {e}\")\n",
    "    finally:\n",
    "        cleanup()\n",
    "        print(f\"Proceso {rank} ha terminado la limpieza.\")\n",
    "\n",
    "def run_demo(demo_fn, world_size):\n",
    "    processes = []\n",
    "    for rank in range(world_size):\n",
    "        p = mp.Process(target=demo_fn, args=(rank, world_size))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    world_size = 2\n",
    "    run_demo(demo_basic, world_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuración del entorno\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Modelo de ejemplo (TensorFlow)\n",
    "class ToyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = layers.Dense(10, activation='relu')\n",
    "        self.net2 = layers.Dense(5)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.net1(x)\n",
    "        return self.net2(x)\n",
    "\n",
    "def demo_basic(strategy):\n",
    "    print(\"Empezando entrenamiento con TensorFlow...\")\n",
    "\n",
    "    # Configuración del modelo dentro de la estrategia\n",
    "    with strategy.scope():\n",
    "        model = ToyModel()\n",
    "        optimizer = optimizers.SGD(learning_rate=0.001)\n",
    "        loss_fn = losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "        global_batch_size = 4 * strategy.num_replicas_in_sync\n",
    "    \n",
    "    # Datos de ejemplo\n",
    "    dataset = np.random.randn(20, 10).astype(np.float32)\n",
    "    targets = np.random.randn(20, 5).astype(np.float32)\n",
    "\n",
    "    # Creación del dataset de TensorFlow\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((dataset, targets)).batch(global_batch_size)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(inputs, training=True)\n",
    "            per_example_loss = loss_fn(targets, predictions)\n",
    "            loss = tf.nn.compute_average_loss(per_example_loss, global_batch_size=global_batch_size)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    for epoch in range(10):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for batch in train_dataset:\n",
    "            inputs, targets = batch\n",
    "            loss = strategy.run(train_step, args=(inputs, targets))\n",
    "            total_loss += strategy.reduce(tf.distribute.ReduceOp.SUM, loss, axis=None)\n",
    "            num_batches += 1\n",
    "        print(f\"Epoca {epoch+1}, Perdida: {total_loss / num_batches}\")\n",
    "\n",
    "    print(\"Entrenamiento completado.\")\n",
    "\n",
    "def run_demo():\n",
    "    # Creación de la estrategia para múltiples GPUs\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    demo_basic(strategy)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a91c3-ac01-4699-bf6f-8d3dbd9049a7",
   "metadata": {},
   "source": [
    "Métodos de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d715ef9-e2b2-4f64-8eca-401ac0e6f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def monte_carlo_simulation(num_simulations):\n",
    "    count_inside = 0\n",
    "    for _ in range(num_simulations):\n",
    "        x, y = torch.rand(2)\n",
    "        if x**2 + y**2 <= 1.0:\n",
    "            count_inside += 1\n",
    "    return count_inside\n",
    "\n",
    "def parallel_monte_carlo(num_simulations, num_processes):\n",
    "    with mp.Pool(num_processes) as pool:\n",
    "        results = pool.map(monte_carlo_simulation, [num_simulations // num_processes] * num_processes)\n",
    "    return sum(results) / num_simulations * 4\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_simulations = 1000000\n",
    "    num_processes = 4\n",
    "    pi_estimate = parallel_monte_carlo(num_simulations, num_processes)\n",
    "    print(f\"El valor de Pi estimado: {pi_estimate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad43b11c-ebc3-4801-96a6-205de636c14d",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1 . Implementa un modelo de red neuronal simple y entrenarlo utilizando paralelización de datos en múltiples GPUs.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Crea un modelo de red neuronal simple (por ejemplo, una red completamente conectada).\n",
    "- Utiliza torch.nn.DataParallel para paralelizar el entrenamiento del modelo en múltiples GPUs.\n",
    "- Entrena el modelo en el conjunto de datos MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6977fdc-f845-47c4-8f3e-a2d031624c78",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "\n",
    "1. Implementa y completa el pseudocódigo.\n",
    "2. Ejecuta el entrenamiento en un sistema con múltiples GPUs.\n",
    "3. Analiza el rendimiento y la aceleración obtenida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daebd59e-540c-4903-abfc-b32b1234a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ff160-ca25-4fdb-a4eb-8818c955a197",
   "metadata": {},
   "source": [
    "2 . Implementa un modelo de GBM utilizando lightgbm y realizar el entrenamiento utilizando múltiples núcleos de CPU.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Crea un conjunto de datos sintético.\n",
    "- Utiliza lightgbm para entrenar un modelo de GBM, configurando la paralelización con múltiples núcleos de CPU.\n",
    "- Evalua el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f75546-87d4-42b0-b028-ddb2b00fe5e5",
   "metadata": {},
   "source": [
    "**Tareas:**\n",
    "\n",
    "1. Implementa y completa el pseudocódigo.\n",
    "2. Ajusta los parámetros del modelo para mejorar la precisión.\n",
    "3. Evalua el rendimiento del modelo en términos de tiempo de entrenamiento y precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9740ec0-3a36-4b72-9164-347940a3d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fcfbc9-42a7-4db0-9a6b-18eba605c048",
   "metadata": {},
   "source": [
    "3 . Implementa una CNN y entrena utilizando paralelización de modelos en múltiples GPUs.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Define una arquitectura CNN.\n",
    "- Utiliza torch.nn.DataParallel para paralelizar el modelo en múltiples GPUs.\n",
    "- Entrena el modelo en el conjunto de datos CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203eb336-bd53-4f95-a3ff-7bcb94e09633",
   "metadata": {},
   "source": [
    "**Tareas:**\n",
    "\n",
    "1. Implementa y completa el pseudocódigo.\n",
    "2. Ejecuta el entrenamiento en un sistema con múltiples GPUs.\n",
    "3. Evalua la precisión del modelo y el tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789636f-f7fa-4306-b159-d251f931f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34293f49-0d88-4726-b9ca-977526981001",
   "metadata": {},
   "source": [
    "4 .Implementa un modelo transformer simple y entrena utilizando pipeline parallelism en múltiples GPUs.\n",
    "\n",
    "Instrucciones: \n",
    "\n",
    "- Define una arquitectura de transformer.\n",
    "- Utiliza torch.nn.DataParallel para paralelizar las capas del transformer en múltiples GPUs.\n",
    "- Entrena el modelo en un conjunto de datos de procesamiento de lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0317958-4f9e-4d6f-b551-13924074232d",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "  \n",
    "1. Implementa y completa el pseudocódigo.\n",
    "2. Ejecuta el entrenamiento en un sistema con múltiples GPUs.\n",
    "3. Analiza el rendimiento y la precisión del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499d51d-0394-437a-a09b-56608c4d23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdc61d-fc75-4ca4-82bb-13f6304c77f5",
   "metadata": {},
   "source": [
    "5 . Implementa el algoritmo SGD paralelo en un entorno distribuido utilizando torch.distributed.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Configura un entorno distribuido utilizando torch.distributed.\n",
    "- Divide los datos de entrenamiento entre múltiples nodos.\n",
    "- Implementa el algoritmo SGD paralelo donde cada nodo calcula los gradientes de forma independiente y luego los gradientes se agregan para actualizar los parámetros del modelo global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f644f-336a-49fa-b1eb-403c85bbe693",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "  \n",
    "1. Implementa y completa el pseudocódigo.\n",
    "2. Ejecuta el entrenamiento en un entorno distribuido con múltiples nodos.\n",
    "3. Evalua el rendimiento del modelo y el tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5274e8-ad63-4d2b-9e33-c635ce713834",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b898cb4-ed97-4ac8-9030-bbc83c1c37b0",
   "metadata": {},
   "source": [
    "6 . Implementa un algoritmo de Monte Carlo para la estimación de Pi y paralelizarlo utilizando multiprocessing.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Escribe un algoritmo de Monte Carlo para estimar Pi.\n",
    "- Utiliza multiprocessing para paralelizar la generación de muestras y la evaluación.\n",
    "- Compara el tiempo de ejecución en comparación con una implementación secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7f9cf-06d4-4f74-b4e0-aa0f61ff3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import time\n",
    "\n",
    "def monte_carlo_pi_part(n):\n",
    "    count = 0\n",
    "    for _ in range(n):\n",
    "        x, y = random.random(), random.random()\n",
    "        if x**2 + y**2 <= 1.0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def parallel_monte_carlo_pi(total_samples, num_processes):\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    samples_per_process = [total_samples // num_processes] * num_processes\n",
    "    counts = pool.map(monte_carlo_pi_part, samples_per_process)\n",
    "    pi_estimate = sum(counts) / total_samples * 4\n",
    "    return pi_estimate\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total_samples = 10**7\n",
    "    num_processes = 4\n",
    "\n",
    "    start_time = time.time()\n",
    "    pi_estimate = parallel_monte_carlo_pi(total_samples, num_processes)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Pi estimado: {pi_estimate}\")\n",
    "    print(f\"Tiempo tomado: {end_time - start_time} en segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176bdb0-5b3c-45c1-9ee7-cb0343011e52",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "\n",
    "1. Implementa y completa el pseudocódigo.\n",
    "2. Ejecuta la estimación de Pi utilizando diferentes números de procesos.\n",
    "3. Evalua el tiempo de ejecución y la precisión de la estimación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed807c-e66b-41bc-937f-3b7051e9435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696defc3-968d-499e-bbde-70aa94fe1c94",
   "metadata": {},
   "source": [
    "**Procesamiento de logs**\n",
    "\n",
    "El procesamiento de logs en sistemas distribuidos es una tarea esencial para la gestión de grandes volúmenes de datos generados por aplicaciones y sistemas. La clave para procesar logs de manera eficiente es dividir los datos en fragmentos y distribuir estos fragmentos entre varios nodos para procesamiento paralelo. Posteriormente, los resultados parciales se combinan en una fase de reducción para generar la salida final.\n",
    "\n",
    "El procesamiento de logs implica las siguientes etapas:\n",
    "\n",
    "- División de datos: Los logs se dividen en fragmentos más pequeños que pueden ser procesados en paralelo.\n",
    "- Distribución de tareas: Estos fragmentos se distribuyen entre múltiples nodos en un clúster.\n",
    "- Procesamiento paralelo: Cada nodo procesa su fragmento de manera independiente, aplicando filtros, transformaciones y agregaciones necesarias.\n",
    "- Reducción y agregación: Los resultados parciales de cada nodo se combinan para obtener la salida final, que puede ser un resumen de los logs o informes detallados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b95ad-3608-48cc-9516-f1f5bfd53c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "def process_log_fragment(log_fragment):\n",
    "    # Implementar el procesamiento del fragmento de log\n",
    "    processed_data = []\n",
    "    for line in log_fragment:\n",
    "        if \"ERROR\" in line:\n",
    "            processed_data.append(line)\n",
    "    return processed_data\n",
    "\n",
    "def read_log_file(file_path, chunk_size=1024):\n",
    "    with open(file_path, 'r') as f:\n",
    "        while True:\n",
    "            lines = f.readlines(chunk_size)\n",
    "            if not lines:\n",
    "                break\n",
    "            yield lines\n",
    "\n",
    "def combine_results(results):\n",
    "    combined = []\n",
    "    for result in results:\n",
    "        combined.extend(result)\n",
    "    return combined\n",
    "\n",
    "def process_logs_in_parallel(log_file_path, num_workers=4):\n",
    "    log_fragments = read_log_file(log_file_path)\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        future_to_fragment = {executor.submit(process_log_fragment, fragment): fragment for fragment in log_fragments}\n",
    "        for future in as_completed(future_to_fragment):\n",
    "            results.append(future.result())\n",
    "    combined_results = combine_results(results)\n",
    "    return combined_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log_file_path = 'large_log_file.log'\n",
    "    processed_logs = process_logs_in_parallel(log_file_path)\n",
    "    for log in processed_logs:\n",
    "        print(log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a5ad5a-62b0-4ebf-a4af-5aaa7cac2e4f",
   "metadata": {},
   "source": [
    "El uso de frameworks como Hadoop MapReduce o Apache Spark facilita este tipo de procesamiento distribuido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d2ecc-84e0-4c2a-bea5-fc23c7b2849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"Log Processing\").getOrCreate()\n",
    "\n",
    "# Leer los logs desde un archivo\n",
    "logs = spark.read.text(\"hdfs://path/to/logs\")\n",
    "\n",
    "# Función de procesamiento de logs\n",
    "def process_log(line):\n",
    "    # Procesamiento personalizado del log\n",
    "    return line\n",
    "\n",
    "# Aplicar la función de procesamiento a cada línea del log\n",
    "processed_logs = logs.rdd.map(process_log)\n",
    "\n",
    "# Guardar los resultados procesados\n",
    "processed_logs.saveAsTextFile(\"hdfs://path/to/processed_logs\")\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976791ee-4841-4130-97c0-b437ef784356",
   "metadata": {},
   "source": [
    "**Análisis de grandes datos (Big Data Analytics)**\n",
    "\n",
    "El análisis de grandes datos implica el procesamiento y análisis de volúmenes masivos de datos para extraer información significativa. Herramientas como Apache Spark permiten realizar este tipo de análisis en paralelo, utilizando un modelo de programación distribuido.\n",
    "\n",
    "En el contexto de Big Data, se utilizan dos tipos de operaciones principales:\n",
    "\n",
    "- Transformaciones: Operaciones que crean un nuevo conjunto de datos a partir de un existente, como map, filter y reduceByKey.\n",
    "- Acciones: Operaciones que devuelven un valor al controlador de Spark, como count, collect y saveAsTextFile.\n",
    "\n",
    "Apache Spark distribuye los datos y las operaciones entre múltiples nodos, permitiendo un procesamiento eficiente a gran escala.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44074f-25ad-495b-bd65-8ee4a7dd192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Big Data Analytics\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Leer datos de ejemplo\n",
    "data = [(\"Checha\", 34), (\"Aco\", 45), (\"Tomo\", 29)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Realizar transformaciones\n",
    "df_filtered = df.filter(df.Age > 30)\n",
    "df_grouped = df_filtered.groupBy(\"Name\").count()\n",
    "\n",
    "# Ejecutar una acción\n",
    "df_grouped.show()\n",
    "\n",
    "# Detener la sesión de Spark\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b57c5e-e940-4145-a066-46313f5be14e",
   "metadata": {},
   "source": [
    "**Programación de pasaje de mensajes (Message Passing Interface, MPI)**\n",
    "\n",
    "MPI es un estándar para la programación paralela en sistemas distribuidos que permite la comunicación eficiente entre nodos mediante el paso de mensajes. MPI es ampliamente utilizado en aplicaciones de alto rendimiento donde la comunicación y la sincronización entre procesos son esenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb372878-44c6-443f-9e03-e19d6c89aab2",
   "metadata": {},
   "source": [
    "**Algoritmos distribuidos**\n",
    "\n",
    "Los algoritmos distribuidos están diseñados para sistemas donde los componentes son nodos autónomos que interactúan mediante comunicación de red. Estos algoritmos resuelven problemas donde la información y el control están distribuidos. \n",
    "\n",
    "Dos ejemplos importantes son los algoritmos de consenso y los algoritmos de elección de líder.\n",
    "\n",
    "Algoritmos de consenso\n",
    "\n",
    "- Paxos y Raft: Estos algoritmos aseguran que todos los nodos en un sistema distribuido acuerden un valor único, crucial para la consistencia de los datos.\n",
    "\n",
    "Algoritmos de elección de líder\n",
    "\n",
    "- Determinan un líder entre un grupo de nodos, utilizado para coordinar actividades en sistemas distribuidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54721c-1bb2-4027-a4e2-d4f6c47fb7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ejemplo simple: Raft\n",
    "import random\n",
    "import threading\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node_id):\n",
    "        self.node_id = node_id\n",
    "        self.state = \"follower\"\n",
    "        self.votes = 0\n",
    "\n",
    "    def start_election(self):\n",
    "        self.state = \"candidate\"\n",
    "        self.votes = 1  # vote for self\n",
    "        print(f\"Nodo {self.node_id} inicia una eleccion\")\n",
    "\n",
    "    def receive_vote(self):\n",
    "        self.votes += 1\n",
    "        print(f\"Nodo {self.node_id} recive un voto\")\n",
    "\n",
    "nodes = [Node(i) for i in range(5)]\n",
    "leader_elected = threading.Event()\n",
    "\n",
    "def run_node(node):\n",
    "    while not leader_elected.is_set():\n",
    "        if node.state == \"follower\" and random.random() < 0.05:\n",
    "            node.start_election()\n",
    "            for peer in nodes:\n",
    "                if peer != node:\n",
    "                    peer.receive_vote()\n",
    "            if node.votes > len(nodes) / 2:\n",
    "                node.state = \"leader\"\n",
    "                leader_elected.set()\n",
    "                print(f\"Nodo {node.node_id} es elegido como lider\")\n",
    "\n",
    "threads = [threading.Thread(target=run_node, args=(node,)) for node in nodes]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df942e4b-4839-4f53-87f6-1dd4a374c1b8",
   "metadata": {},
   "source": [
    "Algoritmo de elección de líder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e92f38-fa45-4feb-aa91-946df5a790c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class LeaderElection:\n",
    "    def __init__(self, num_nodes):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.nodes = [i for i in range(num_nodes)]\n",
    "        self.leader = None\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def elect_leader(self):\n",
    "        with self.lock:\n",
    "            if self.leader is None:\n",
    "                self.leader = max(self.nodes)\n",
    "                print(f\"Nodo {self.leader} es elegido como lider\")\n",
    "\n",
    "def node_task(election):\n",
    "    election.elect_leader()\n",
    "\n",
    "election = LeaderElection(num_nodes=5)\n",
    "threads = [threading.Thread(target=node_task, args=(election,)) for _ in range(election.num_nodes)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec805417-0037-4ca3-9e84-b6a9a1e2b7b2",
   "metadata": {},
   "source": [
    "### Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59631bb-06ba-4fe3-abe3-2576313a24b6",
   "metadata": {},
   "source": [
    "1 . Implementa un sistema de procesamiento de logs utilizando el paradigma MapReduce para dividir los logs, procesarlos en paralelo y combinar los resultados.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Divide el archivo de logs en fragmentos.\n",
    "- Implementa la función map para procesar cada fragmento de logs y filtrar las líneas que contienen \"ERROR\".\n",
    "- Implementa la función reduce para combinar los resultados parciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dab0b-c3e1-4b91-9f0f-c2f04b69e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def map_function(log_fragment):\n",
    "    # Filtrar líneas con \"ERROR\"\n",
    "    return [line for line in log_fragment if \"ERROR\" in line]\n",
    "\n",
    "def reduce_function(mapped_data):\n",
    "    # Combinar los resultados de todos los mappers\n",
    "    return [line for sublist in mapped_data for line in sublist]\n",
    "\n",
    "def read_log_file(file_path, chunk_size=1024):\n",
    "    with open(file_path, 'r') as f:\n",
    "        while True:\n",
    "            lines = f.readlines(chunk_size)\n",
    "            if not lines:\n",
    "                break\n",
    "            yield lines\n",
    "\n",
    "def process_logs_in_parallel(log_file_path, num_workers=4):\n",
    "    log_fragments = read_log_file(log_file_path)\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        future_to_fragment = {executor.submit(map_function, fragment): fragment for fragment in log_fragments}\n",
    "        for future in as_completed(future_to_fragment):\n",
    "            results.append(future.result())\n",
    "    combined_results = reduce_function(results)\n",
    "    return combined_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log_file_path = 'large_log_file.log'\n",
    "    processed_logs = process_logs_in_parallel(log_file_path)\n",
    "    for log in processed_logs:\n",
    "        print(log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ac1d3-4fb9-4304-85bc-d155409cdac2",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "  \n",
    "1. Implementa y completa el código base.\n",
    "2. Ejecuta el procesamiento de logs en un sistema con múltiples hilos.\n",
    "3. Evalua el rendimiento y la eficiencia del procesamiento paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfcbf4-1555-4a06-9d96-45dfcfdcc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74e136-401c-410a-a1b0-9c68e346d620",
   "metadata": {},
   "source": [
    "2 . Implementa un análisis de grandes datos utilizando Apache Spark para procesar y analizar un conjunto de datos grande.\n",
    "\n",
    "Instrucciones\n",
    "    \n",
    "- Configura una sesión de Spark.\n",
    "- Lea un conjunto de datos grande.\n",
    "- Realiza transformaciones y acciones sobre los datos.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Implementa el código base para este ejercicio.\n",
    "2. Ejecuta el análisis de datos en un entorno de Spark.\n",
    "3. Evalua la escalabilidad y eficiencia del procesamiento de datos en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f86c3-12eb-44e1-bfd6-8b4d28ad3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a5476-36eb-42cd-b80b-ceb2e0de26cc",
   "metadata": {},
   "source": [
    "3 . Implementa el algoritmo de K-Means para clustering utilizando paralelización en múltiples hilos o procesos.\n",
    "\n",
    "Instrucciones\n",
    "\n",
    "- Implementa la inicialización de centroides.\n",
    "- Asigna puntos de datos a los centroides más cercanos en paralelo.\n",
    "- Recalcula los centroides en paralelo.\n",
    "- Repite hasta la convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a040db43-6bb3-4632-a6e8-7ae497ca6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def initialize_centroids(data, k):\n",
    "    indices = np.random.choice(data.shape[0], k, replace=False)\n",
    "    return data[indices]\n",
    "\n",
    "def assign_clusters(data, centroids):\n",
    "    clusters = {}\n",
    "    for x in data:\n",
    "        closest_centroid = np.argmin([np.linalg.norm(x - centroid) for centroid in centroids])\n",
    "        if closest_centroid not in clusters:\n",
    "            clusters[closest_centroid] = []\n",
    "        clusters[closest_centroid].append(x)\n",
    "    return clusters\n",
    "\n",
    "def update_centroids(clusters):\n",
    "    return [np.mean(clusters[k], axis=0) for k in clusters]\n",
    "\n",
    "def kmeans_parallel(data, k, num_workers=4, max_iters=100):\n",
    "    ## Completa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86312ae5-e503-4895-bd5b-058dac031aed",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "  \n",
    "1. Implementa y completa el código base.\n",
    "2. Ejecuta el algoritmo de K-Means en un conjunto de datos grande.\n",
    "3. Evalua la convergencia y la calidad del clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ec41a-7c17-48f4-860a-0db8907c51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c069b3-71ff-4a83-8f28-06e3c4e44033",
   "metadata": {},
   "source": [
    "4 . Implementa un programa MPI que sincroniza múltiples procesos utilizando barreras.\n",
    "\n",
    "Instrucciones\n",
    "\n",
    "- Configura un entorno MPI.\n",
    "- Implementa la sincronización de procesos con MPI_Barrier.\n",
    "- Haz que cada proceso realice una tarea antes y después de la barrera.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Implementa y completa el código base.\n",
    "2. Ejecuta el programa en un entorno MPI con múltiples procesos.\n",
    "3. Evalua la sincronización y el comportamiento de los procesos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e5426-b3f7-471c-a920-80f9e3c407d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62e089-7b52-4c1d-97c2-121e178a5a0a",
   "metadata": {},
   "source": [
    "5 . Implementa un programa MPI que utiliza MPI_Allreduce para realizar operaciones de reducción entre todos los procesos.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Configura un entorno MPI.\n",
    "- Implementa un cálculo distribuido donde cada proceso genera un valor.\n",
    "- Utiliza MPI_Allreduce para sumar los valores generados por todos los procesos.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Implementa y completa el código base.\n",
    "2. Ejecuta el programa en un entorno MPI con múltiples procesos.\n",
    "3. Evalua la eficiencia y corrección del cálculo distribuido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bd760-ce02-4f3e-b96b-1cea4e4162d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6efd6-f079-4cf1-803a-45e98102b9ae",
   "metadata": {},
   "source": [
    "### Ejercicios de repaso\n",
    "\n",
    "1 . Implementa el algoritmo de Merge Sort usando paralelización para dividir y vencer.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Implementa la función de merge sort que divide el problema en sub-problemas.\n",
    "- Paraleliza la división de los sub-problemas utilizando concurrent.futures.ThreadPoolExecutor.\n",
    "- Ejecuta el algoritmo de Merge Sort en un conjunto de datos grande.\n",
    "- Evalua la eficiencia y tiempo de ejecución del algoritmo paralelo en comparación con la versión secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e467c-0cee-4bd4-8fdb-d824f43f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b46da2-f6cc-4548-9846-aa1fbee785b2",
   "metadata": {},
   "source": [
    "2 . Implementa un algoritmo de reducción para sumar los elementos de una matriz utilizando paralelización.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "* Divide la matriz en fragmentos.\n",
    "* Calcula la suma de cada fragmento en paralelo.\n",
    "* Combina los resultados parciales en una suma total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43145eb3-ceac-40a0-9537-2f3253eeaa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def sum_matrix_part(matrix_part):\n",
    "    return np.sum(matrix_part)\n",
    "\n",
    "def parallel_sum_matrix(matrix, num_workers=4):\n",
    "    rows, cols = matrix.shape\n",
    "    chunk_size = rows // num_workers\n",
    "    futures = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        for i in range(num_workers):\n",
    "            start_row = i * chunk_size\n",
    "            end_row = (i + 1) * chunk_size if i != num_workers - 1 else rows\n",
    "            futures.append(executor.submit(sum_matrix_part, matrix[start_row:end_row, :]))\n",
    "\n",
    "    total_sum = sum(f.result() for f in futures)\n",
    "    return total_sum\n",
    "\n",
    "# Datos de ejemplo\n",
    "matrix = np.random.rand(1000, 1000)\n",
    "total_sum = parallel_sum_matrix(matrix)\n",
    "print(\"Suma total de matriz:\", total_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198fb08-b0f2-4732-9ae3-0e583e060213",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "  \n",
    "1. Implementa y completa el código base.\n",
    "2. Ejecuta el algoritmo de reducción en una matriz grande.\n",
    "3. Evalua la eficiencia y tiempo de ejecución del algoritmo paralelo en comparación con la versión secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94568521-9da7-4042-9914-e7d0056fad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a56b10-db40-4783-83c0-b5f81a90bc66",
   "metadata": {},
   "source": [
    "3 .Implementa un algoritmo de barrido paralelo para buscar un elemento en un conjunto de datos.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Divide el conjunto de datos en fragmentos.\n",
    "- Busca el elemento en cada fragmento en paralelo.\n",
    "- Combina los resultados parciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c483969-6b37-4c3c-ba98-ca4d39397597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def find_element_in_part(data_part, element):\n",
    "    return element in data_part\n",
    "\n",
    "def parallel_find_element(data, element, num_workers=4):\n",
    "    chunk_size = len(data) // num_workers\n",
    "    futures = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        for i in range(num_workers):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = (i + 1) * chunk_size if i != num_workers - 1 else len(data)\n",
    "            futures.append(executor.submit(find_element_in_part, data[start_idx:end_idx], element))\n",
    "\n",
    "    found = any(f.result() for f in futures)\n",
    "    return found\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = list(range(10000))\n",
    "element = 5000\n",
    "found = parallel_find_element(data, element)\n",
    "print(f\"Elemento {element} encontrado:\", found)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cee020-e7d5-45b9-aadd-f88696360c5b",
   "metadata": {},
   "source": [
    "**Tareas**\n",
    "  \n",
    "1. Implementa y completa el código base.\n",
    "2. Ejecuta el algoritmo de búsqueda en un conjunto de datos grande.\n",
    "3. Evalua la eficiencia y tiempo de ejecución del algoritmo paralelo en comparación con la versión secuencial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348fddc-b18a-4217-8c22-294847e89263",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu repuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc6bed-c43e-4ee5-a2f3-9295c56ecfb4",
   "metadata": {},
   "source": [
    "4 . Implementa la búsqueda en anchura (BFS) en un grafo utilizando paralelización.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Implementa la estructura de datos del grafo.\n",
    "- Implementa el algoritmo BFS.\n",
    "- Paraleliza el procesamiento de los nodos en cada nivel del BFS.\n",
    "- Ejecuta el algoritmo BFS en un grafo grande.\n",
    "- Evalua la eficiencia y tiempo de ejecución del algoritmo paralelo en comparación con la versión secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae605186-001a-4747-a6b9-e5649a53a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0dc13c-bf5f-4657-bbd7-1b563b999283",
   "metadata": {},
   "source": [
    "5 . Implementa la búsqueda en profundidad (DFS) en un grafo utilizando paralelización.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Implementa la estructura de datos del grafo.\n",
    "- Implementa el algoritmo DFS.\n",
    "- Paraleliza el procesamiento de los nodos en la recursión DFS.\n",
    "- Ejecuta el algoritmo DFS en un grafo grande.\n",
    "- Evalua la eficiencia y tiempo de ejecución del algoritmo paralelo en comparación con la versión secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4839a-1e54-4062-b1a3-4a8ff29f25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
