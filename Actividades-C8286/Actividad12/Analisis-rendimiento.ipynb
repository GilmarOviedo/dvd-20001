{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a3b0ae-e4cc-498e-9f7a-14db03b00cbb",
   "metadata": {},
   "source": [
    "## Análisis de desempeño y escalabilidad en computación paralela\n",
    "\n",
    "El análisis de desempeño y escalabilidad en computación paralela es crucial para entender cómo los algoritmos y sistemas pueden aprovechar múltiples procesadores para mejorar el rendimiento. Este análisis incluye conceptos fundamentales como la Ley de Amdahl y la Ley de Gustafson, así como medidas clave como el `speedup` y la eficiencia. \n",
    "También es esencial considerar el balanceo de carga y las técnicas para medir y optimizar el rendimiento. \n",
    "\n",
    "**Ley de Amdahl**\n",
    "\n",
    "La Ley de Amdahl, formulada por Gene Amdahl en 1967, es una fórmula utilizada para encontrar el límite superior de aceleración de un programa paralelo. Esta ley es fundamental para entender las limitaciones inherentes al paralelismo.\n",
    "\n",
    "\n",
    "La ley de Amdahl se expresa matemáticamente como:\n",
    "\n",
    "$$S(N) = \\frac{1}{(1 - P) + \\frac{P}{N}}$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $S(N)$ es el speedup con $N$ procesadores.\n",
    "- $P$ es la fracción del programa que puede paralelizarse.\n",
    "- $1 - P$ es la fracción del programa que debe ejecutarse secuencialmente.\n",
    "\n",
    "\n",
    " **Speedup (S)**: Es la medida de cuánto más rápido se ejecuta un programa con múltiples procesadores en comparación con uno solo.\n",
    " \n",
    " **Fracción paralelizable (P)**: Indica la porción del programa que puede beneficiarse del paralelismo.\n",
    " \n",
    " **Límite de aceleración**: A medida que $N$ aumenta, el término $\\frac{P}{N}$ se vuelve insignificante, y el speedup máximo está limitado por $\\frac{1}{1 - P}$.\n",
    "\n",
    "Por ejemplo, si el 90% de un programa puede paralelizarse $P = 0.9$, el speedup máximo es $10$, sin importar cuántos procesadores se utilicen.\n",
    "\n",
    "Un caso real donde se aplicó la Ley de Amdahl es el desarrollo del software para simulaciones meteorológicas. En este contexto, solo una fracción del cálculo (aproximadamente el 80%) puede paralelizarse debido a las dependencias inherentes en los datos meteorológicos.\n",
    "\n",
    "En la práctica, esto significa que incluso con un número muy grande de procesadores, el speedup máximo está limitado por la porción secuencial del programa. Por ejemplo, con  $P = 0.8$, el speedup máximo es:\n",
    "\n",
    "$$S(N \\to \\infty) = \\frac{1}{1 - 0.8} = 5$$\n",
    "\n",
    "Esto implica que, sin importar cuántos procesadores se utilicen, la aceleración no puede superar 5 veces el tiempo de ejecución secuencial.\n",
    "\n",
    "\n",
    "#### Ley de Gustafson\n",
    "\n",
    "La ley de Gustafson, propuesta por John L. Gustafson en 1988, ofrece una perspectiva diferente y más optimista sobre el paralelismo, sugiriendo que la velocidad de un programa paralelo puede aumentar linealmente con el número de procesadores.\n",
    "\n",
    "\n",
    "La ley de Gustafson se expresa como:\n",
    "\n",
    "$$S(N) = N - (N - 1) \\cdot (1 - P)$$\n",
    "\n",
    "Donde:\n",
    "- $S(N)$ es el speedup con $N$ procesadores.\n",
    "- $P$ es la fracción del programa que puede paralelizarse.\n",
    "\n",
    "\n",
    "**Escalabilidad**: Gustafson argumenta que los problemas grandes pueden ser escalados para aprovechar el paralelismo, con un crecimiento en la porción paralelizable.\n",
    "\n",
    "**Aceleración escalable**: A diferencia de la ley de Amdahl, esta fórmula sugiere que el speedup puede crecer indefinidamente con $N$, siempre y cuando $P$ aumente con el tamaño del problema.\n",
    "\n",
    "Por ejemplo, si $P = 0.9$ y $N = 100$, entonces $S(100) = 100 - 99 \\cdot 0.1 = 91$.\n",
    "\n",
    "\n",
    "Un caso real de aplicación de la Ley de Gustafson se observa en proyectos de renderización gráfica en la industria cinematográfica, donde los problemas pueden ser escalados para aprovechar el paralelismo. En la práctica, si se tiene $P = 0.95$ y $N = 100$:\n",
    "\n",
    "$$S(100) = 100 - 99 \\cdot 0.05 = 95.05$$\n",
    "\n",
    "Esto muestra que el speedup puede crecer casi linealmente con el número de procesadores, siempre que se pueda escalar la parte paralelizable del problema.\n",
    "\n",
    "**Experimentación:**\n",
    "Para comparar ambas leyes en la práctica, se pueden realizar experimentos utilizando diferentes algoritmos y tamaños de problema. Supongamos que ejecutamos un algoritmo de procesamiento de imágenes con diferentes fracciones paralelizables $P$ y medimos el speedup en una máquina con hasta 64 procesadores.\n",
    "\n",
    "**Escenario 1 - Baja paralelización (P = 0.5):**\n",
    "- Ley de Amdahl: El speedup máximo será limitado significativamente:\n",
    "  $$ S(64) = \\frac{1}{0.5 + \\frac{0.5}{64}} = 1.96$$\n",
    "- Ley de Gustafson: El speedup será:\n",
    "  $$S(64) = 64 - 63 \\cdot 0.5 = 32.5$$\n",
    "\n",
    "**Escenario 2 - Alta paralelización (P = 0.9):**\n",
    "- Ley de Amdahl: El speedup máximo será mayor:\n",
    "  $$S(64) = \\frac{1}{0.1 + \\frac{0.9}{64}} = 6.4$$\n",
    "- Ley de Gustafson: El speedup será:\n",
    "  $$S(64) = 64 - 63 \\cdot 0.1 = 57.3$$\n",
    "\n",
    "Estos resultados experimentales demostrarían que la Ley de Amdahl subestima el potencial de escalabilidad en aplicaciones altamente paralelizables, mientras que la Ley de Gustafson proporciona una estimación más optimista.\n",
    "\n",
    "#### Speedup y eficiencia\n",
    "\n",
    "El speedup y la eficiencia son métricas clave para evaluar el desempeño de algoritmos paralelos.\n",
    "\n",
    "##### Speedup\n",
    "\n",
    "El speedup $S$ es la razón del tiempo de ejecución del mejor algoritmo secuencial $T_s$ al tiempo de ejecución del algoritmo paralelo $T_p$:\n",
    "\n",
    "$$S = \\frac{T_s}{T_p}$$\n",
    "\n",
    "Esta métrica indica cuántas veces es más rápido el programa paralelo comparado con su contraparte secuencial.\n",
    "\n",
    "##### Eficiencia\n",
    "\n",
    "La eficiencia $E$ es la razón del speedup al número de procesadores $N$:\n",
    "\n",
    "$$E = \\frac{S}{N}$$\n",
    "\n",
    "Esta métrica indica qué tan bien se utilizan los procesadores disponibles. Una eficiencia de 1 (o 100%) indica uso óptimo.\n",
    "\n",
    "\n",
    "#### Overhead de comunicación\n",
    "\n",
    "**Impacto del overhead:**\n",
    "\n",
    "El overhead de comunicación se refiere al tiempo adicional requerido para coordinar y transferir datos entre procesadores en un sistema paralelo. Este overhead puede ser un factor limitante significativo en el rendimiento del paralelismo. Por ejemplo, en aplicaciones de simulación molecular, donde las partículas deben comunicarse entre sí en cada paso del tiempo, el overhead de comunicación puede consumir una porción considerable del tiempo total de ejecución.\n",
    "\n",
    "**Minimización del overhead:**\n",
    "\n",
    "Para minimizar este overhead, se pueden utilizar técnicas como:\n",
    "- **Comunicación Asincrónica:** Permitir que los procesadores continúen trabajando mientras esperan datos de otros procesadores.\n",
    "- **Agrupamiento de Mensajes:** Enviar varios mensajes en uno solo para reducir la frecuencia de comunicación.\n",
    "- **Topologías de Red Eficientes:** Usar topologías de red que minimicen el número de saltos entre procesadores, como la topología de malla o el hipercubo.\n",
    "\n",
    "#### Latencia y ancho de banda\n",
    "\n",
    "**Latencia:**\n",
    "La latencia es el tiempo que tarda un mensaje en viajar desde su fuente hasta su destino. En sistemas distribuidos, la latencia puede ser afectada por la distancia física entre nodos, la congestión de la red, y las colas en los routers. En aplicaciones de alta frecuencia, como el comercio de alta frecuencia, una latencia baja es crucial para la toma de decisiones rápidas.\n",
    "\n",
    "**Ancho de banda:**\n",
    "El ancho de banda se refiere a la cantidad de datos que pueden ser transferidos por la red en un tiempo dado. En aplicaciones como el procesamiento de grandes volúmenes de datos (Big Data), un alto ancho de banda es esencial para mover datos rápidamente entre nodos de procesamiento.\n",
    "\n",
    "**Optimización:**\n",
    "Para optimizar tanto la latencia como el ancho de banda, se pueden emplear estrategias como:\n",
    "\n",
    "- **Redes de alta velocidad:** Utilizar redes de alta velocidad como Infiniband o Ethernet de 10/40/100 Gbps.\n",
    "- **Compresión de datos:** Reducir la cantidad de datos a transferir mediante técnicas de compresión.\n",
    "- **Estrategias de colocación:** Colocar datos y tareas en nodos cercanos para minimizar la distancia de comunicación.\n",
    "\n",
    "### Experimentos y simulaciones\n",
    "\n",
    "Para ilustrar el impacto del overhead y las métricas de latencia y ancho de banda, se pueden diseñar y ejecutar experimentos en un cluster de computación.\n",
    "\n",
    "**Experimento 1 - Overhead de comunicación:**\n",
    "\n",
    "- **Setup:** Implementar un algoritmo de multiplicación de matrices en un cluster con diferentes topologías de red.\n",
    "- **Medición:** Comparar el tiempo de ejecución total y el tiempo dedicado a la comunicación en topologías de malla, anillo, y hipercubo.\n",
    "- **Resultados esperados:** Identificar la topología con menor overhead y analizar cómo la elección de topología afecta el rendimiento del algoritmo.\n",
    "\n",
    "**Experimento 2 - Latencia y ancho de banda:**\n",
    "\n",
    "- **Setup:** Configurar un entorno distribuido para procesamiento de datos con diferentes configuraciones de red (e.g., Ethernet de 1 Gbps vs. 100 Gbps).\n",
    "- **Medición:** Medir el tiempo de ejecución de tareas de procesamiento de datos bajo diferentes configuraciones de red.\n",
    "- **Resultados esperados:** Evaluar el impacto de la latencia y el ancho de banda en el tiempo de procesamiento y determinar las configuraciones óptimas para diferentes tipos de tareas.\n",
    "\n",
    "Estos experimentos proporcionarían datos empíricos valiosos para entender cómo el overhead de comunicación, la latencia, y el ancho de banda influyen en el rendimiento de aplicaciones paralelas y distribuidas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f8136-d3b1-4bb4-89ef-f8cd29755374",
   "metadata": {},
   "source": [
    "### Speedup y eficiencia en entornos heterogéneos\n",
    "\n",
    "#### Introducción\n",
    "\n",
    "El análisis de speedup y eficiencia en entornos heterogéneos es una tarea compleja que involucra la integración de diversos tipos de procesadores y aceleradores. A medida que las aplicaciones requieren un mayor rendimiento, la utilización de GPUs, FPGAs y otros aceleradores se ha convertido en una práctica común. Estos aceleradores ofrecen ventajas significativas en términos de procesamiento paralelo y rendimiento energético. Sin embargo, la gestión de estos recursos en un sistema heterogéneo presenta desafíos únicos en términos de escalabilidad y eficiencia.\n",
    "\n",
    "#### Aceleradores hardware\n",
    "\n",
    "**Unidades de procesamiento gráfico (GPUs)**\n",
    "\n",
    "Las GPUs están diseñadas para manejar operaciones de procesamiento paralelo masivo, lo que las hace ideales para tareas que pueden ser divididas en múltiples sub-tareas ejecutadas en paralelo. Las GPUs son particularmente eficaces en aplicaciones de aprendizaje profundo, simulaciones científicas y renderizado gráfico.\n",
    "\n",
    "**Ejemplo de uso de GPU:**\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuración de un modelo simple de TensorFlow para ejecutarse en una GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Supongamos que `train_images` y `train_labels` son los datos de entrenamiento\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "```\n",
    "\n",
    "El uso de GPUs puede mejorar el speedup significativamente debido a su capacidad para manejar miles de hilos en paralelo, reduciendo así el tiempo de procesamiento en comparación con CPUs tradicionales.\n",
    "\n",
    "**Field-Programmable Gate Arrays (FPGAs)**\n",
    "\n",
    "Las FPGAs ofrecen un enfoque diferente al procesamiento paralelo. Estos dispositivos son reconfigurables y pueden ser programados para realizar tareas específicas con una eficiencia energética muy alta. Las FPGAs son utilizadas en aplicaciones donde se requiere procesamiento en tiempo real y latencia ultra baja, como en telecomunicaciones, procesamiento de señales y sistemas embebidos.\n",
    "\n",
    "**Ejemplo de uso de FPGA:**\n",
    "\n",
    "```vhdl\n",
    "-- Ejemplo de un módulo simple en VHDL para sumar dos números\n",
    "library IEEE;\n",
    "use IEEE.STD_LOGIC_1164.ALL;\n",
    "use IEEE.STD_LOGIC_ARITH.ALL;\n",
    "use IEEE.STD_LOGIC_UNSIGNED.ALL;\n",
    "\n",
    "entity Adder is\n",
    "    Port ( A : in STD_LOGIC_VECTOR (31 downto 0);\n",
    "           B : in STD_LOGIC_VECTOR (31 downto 0);\n",
    "           SUM : out STD_LOGIC_VECTOR (31 downto 0));\n",
    "end Adder;\n",
    "\n",
    "architecture Behavioral of Adder is\n",
    "begin\n",
    "    SUM <= A + B;\n",
    "end Behavioral;\n",
    "```\n",
    "\n",
    "La ventaja de las FPGAs radica en su capacidad para ser optimizadas específicamente para la tarea que se está ejecutando, ofreciendo un balance único entre rendimiento y consumo energético.\n",
    "\n",
    "**Otros aceleradores**\n",
    "\n",
    "Además de GPUs y FPGAs, otros aceleradores como las unidades de procesamiento tensorial (TPUs) y los procesadores de señales digitales (DSPs) también juegan un papel crucial en entornos heterogéneos. Las TPUs, desarrolladas por Google, están optimizadas para el entrenamiento y la inferencia de modelos de aprendizaje profundo. Los DSPs, por otro lado, son utilizados principalmente en aplicaciones de procesamiento de señales, como audio y video.\n",
    "\n",
    "#### Speedup en entornos heterogéneos\n",
    "\n",
    "El speedup es una métrica clave que mide la mejora en el rendimiento cuando se utiliza un sistema paralelo o distribuido en comparación con un sistema secuencial. En entornos heterogéneos, el cálculo del speedup se complica debido a la diversidad de arquitecturas y capacidades de procesamiento.\n",
    "\n",
    "**Modelo de speedup para GPUs**\n",
    "\n",
    "El speedup en sistemas que utilizan GPUs puede ser modelado utilizando la Ley de Amdahl modificada para tener en cuenta la porción de la tarea que puede ser paralelizada y el overhead de comunicación entre CPU y GPU.\n",
    "\n",
    "$$S_{GPU} = \\frac{1}{(1 - P) + \\frac{P}{S_{GPU}} + O_{comm}}$$\n",
    "\n",
    "donde:\n",
    "- $P$ es la fracción de la tarea que puede ser paralelizada.\n",
    "- $S_{GPU}$ es el speedup de la porción paralelizada en la GPU.\n",
    "- $O_{comm}$ es el overhead de comunicación entre CPU y GPU.\n",
    "\n",
    "**Modelo de speedup para FPGAs**\n",
    "\n",
    "Para FPGAs, el speedup también depende de la eficiencia del mapeo de la tarea al hardware reconfigurable y del overhead asociado con la reconfiguración del hardware.\n",
    "\n",
    "$$S_{FPGA} = \\frac{1}{(1 - P) + \\frac{P}{S_{FPGA}} + O_{config}}$$\n",
    "\n",
    "donde:\n",
    "- $P$ es la fracción de la tarea que puede ser paralelizada.\n",
    "- $S_{FPGA}$ es el speedup de la porción paralelizada en la FPGA.\n",
    "- $O_{config}$ es el overhead de reconfiguración del FPGA.\n",
    "\n",
    "#### Eficiencia en entornos heterogéneos\n",
    "\n",
    "La eficiencia en sistemas heterogéneos es otra métrica importante que mide la utilización de los recursos disponibles. La eficiencia puede ser afectada por diversos factores, incluyendo la carga de trabajo, la distribución de tareas y el overhead de comunicación.\n",
    "\n",
    "#### Factores que afectan la eficiencia\n",
    "\n",
    "1. **Balance de carga:**\n",
    "   En entornos heterogéneos, es crucial distribuir las tareas de manera que todos los recursos se utilicen de manera equilibrada. El balance de carga puede ser desafiante debido a las diferencias en las capacidades de procesamiento de los diferentes tipos de aceleradores.\n",
    "\n",
    "2. **Overhead de comunicación:**\n",
    "   La comunicación entre diferentes tipos de procesadores y aceleradores puede introducir overhead significativo, afectando la eficiencia global del sistema. Optimizar la comunicación y minimizar el overhead es esencial para mantener alta eficiencia.\n",
    "\n",
    "3. **Granularidad de las tareas:**\n",
    "   La granularidad de las tareas (el tamaño de las sub-tareas en que se divide una tarea) debe ser adecuada para el tipo de acelerador utilizado. Las GPUs, por ejemplo, son más eficientes con tareas de granularidad fina, mientras que las FPGAs pueden manejar mejor tareas de granularidad más gruesa.\n",
    "\n",
    "4. **Administración de recursos:**\n",
    "   La administración efectiva de recursos, incluyendo la asignación de tareas y la gestión de memoria, es crucial para mantener la eficiencia en sistemas heterogéneos.\n",
    "\n",
    "### Escalabilidad heterogénea\n",
    "\n",
    "La escalabilidad se refiere a la capacidad de un sistema para mantener su rendimiento y eficiencia a medida que se incrementa el número de nodos o el tamaño de la carga de trabajo. En entornos heterogéneos, mantener la escalabilidad puede ser particularmente desafiante debido a las diferencias en las arquitecturas y capacidades de procesamiento.\n",
    "\n",
    "#### Técnicas para mantener la escalabilidad\n",
    "\n",
    "1. **Descomposición de tareas:**\n",
    "   La descomposición eficiente de tareas en sub-tareas que puedan ser distribuidas entre diferentes tipos de procesadores es crucial para mantener la escalabilidad. Las técnicas de descomposición deben tener en cuenta las características específicas de los aceleradores utilizados.\n",
    "\n",
    "2. **Algoritmos adaptativos:**\n",
    "   Los algoritmos adaptativos que pueden ajustar dinámicamente la distribución de tareas y la asignación de recursos basándose en el estado actual del sistema pueden mejorar significativamente la escalabilidad. Estos algoritmos pueden redistribuir tareas entre procesadores y aceleradores para equilibrar la carga y minimizar el overhead.\n",
    "\n",
    "3. **Modelo de programación heterogénea:**\n",
    "   Un modelo de programación que soporte de manera efectiva la heterogeneidad de los recursos es esencial para la escalabilidad. Modelos como OpenCL y CUDA permiten la programación de aplicaciones para ejecutarse en diferentes tipos de aceleradores.\n",
    "\n",
    "4. **Optimización de la comunicación:**\n",
    "   Optimizar la comunicación entre los diferentes componentes del sistema es esencial para mantener la escalabilidad. Tecnologías como las redes de alta velocidad y las técnicas de comunicación asíncrona pueden reducir el overhead y mejorar la eficiencia.\n",
    "\n",
    "#### Ejemplos de implementación\n",
    "\n",
    "**Aprendizaje profundo con GPUs y TPUs**\n",
    "\n",
    "En aplicaciones de aprendizaje profundo, la escalabilidad se logra mediante el uso de múltiples GPUs y TPUs. Las bibliotecas de aprendizaje profundo como TensorFlow y PyTorch soportan la distribución de tareas de entrenamiento y evaluación en múltiples aceleradores.\n",
    "\n",
    "**Ejemplo de uso de múltiples GPUs:**\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Supongamos que `train_images` y `train_labels` son los datos de entrenamiento\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "```\n",
    "\n",
    "**Procesamiento de señales con FPGAs**\n",
    "\n",
    "En aplicaciones de procesamiento de señales, las FPGAs pueden ser utilizadas para implementar filtros digitales y otras operaciones de procesamiento de señales con baja latencia y alta eficiencia energética.\n",
    "\n",
    "**Ejemplo de implementación de un filtro digital en una FPGA:**\n",
    "\n",
    "```vhdl\n",
    "library IEEE;\n",
    "use IEEE.STD_LOGIC_1164.ALL;\n",
    "use IEEE.STD_LOG\n",
    "\n",
    "IC_ARITH.ALL;\n",
    "use IEEE.STD_LOGIC_UNSIGNED.ALL;\n",
    "\n",
    "entity DigitalFilter is\n",
    "    Port ( clk : in STD_LOGIC;\n",
    "           rst : in STD_LOGIC;\n",
    "           data_in : in STD_LOGIC_VECTOR (15 downto 0);\n",
    "           data_out : out STD_LOGIC_VECTOR (15 downto 0));\n",
    "end DigitalFilter;\n",
    "\n",
    "architecture Behavioral of DigitalFilter is\n",
    "    signal coeffs : array (0 to 4) of integer := (1, -2, 3, -2, 1);\n",
    "    signal buffer : array (0 to 4) of integer;\n",
    "begin\n",
    "    process(clk, rst)\n",
    "    begin\n",
    "        if rst = '1' then\n",
    "            buffer <= (others => 0);\n",
    "            data_out <= (others => '0');\n",
    "        elsif rising_edge(clk) then\n",
    "            buffer(0) <= to_integer(unsigned(data_in));\n",
    "            for i in 1 to 4 loop\n",
    "                buffer(i) <= buffer(i - 1);\n",
    "            end loop;\n",
    "            data_out <= std_logic_vector(to_unsigned(buffer(0) * coeffs(0) +\n",
    "                                                      buffer(1) * coeffs(1) +\n",
    "                                                      buffer(2) * coeffs(2) +\n",
    "                                                      buffer(3) * coeffs(3) +\n",
    "                                                      buffer(4) * coeffs(4), 16));\n",
    "        end if;\n",
    "    end process;\n",
    "end Behavioral;\n",
    "```\n",
    "\n",
    "#### Computación en la nube con aceleradores heterogéneos\n",
    "\n",
    "Los proveedores de servicios en la nube, como AWS, Google Cloud y Azure, ofrecen instancias con aceleradores heterogéneos que permiten a los desarrolladores desplegar y escalar aplicaciones de alto rendimiento utilizando una combinación de CPUs, GPUs y FPGAs.\n",
    "\n",
    "**Ejemplo de configuración de una instancia en la nube:**\n",
    "\n",
    "```bash\n",
    "# AWS CLI para lanzar una instancia con GPU\n",
    "aws ec2 run-instances --image-id ami-0abcdef1234567890 \\\n",
    "                      --instance-type p3.2xlarge \\\n",
    "                      --key-name MyKeyPair \\\n",
    "                      --security-groups my-sg\n",
    "```\n",
    "\n",
    "La integración de aceleradores hardware en sistemas heterogéneos requiere un enfoque cuidadoso para maximizar el speedup y la eficiencia, y mantener la escalabilidad en un entorno con recursos diversos y capacidades de procesamiento variadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16584a-fef5-44a9-8140-85c572842413",
   "metadata": {},
   "source": [
    "### Medición y optimización de rendimiento en computación paralela y distribuida\n",
    "\n",
    "La medición y optimización del rendimiento son componentes cruciales para garantizar que los sistemas paralelos y distribuidos funcionen de manera eficiente y eficaz. A continuación, se presentan métodos y técnicas avanzadas para medir y optimizar el desempeño en estos sistemas.\n",
    "\n",
    "#### Métodos de medición\n",
    "\n",
    "1. **Profiling:**\n",
    "\n",
    "    El profiling es una técnica utilizada para identificar las partes del código que consumen más tiempo y recursos. Herramientas como gprof, perf, y Intel VTune Amplifier son comúnmente utilizadas para este propósito. Estas herramientas proporcionan un desglose detallado del tiempo de ejecución de funciones específicas, permitiendo a los desarrolladores identificar cuellos de botella en el rendimiento.\n",
    "\n",
    "   **Ejemplo de uso de gprof:**\n",
    "   ```bash\n",
    "   gcc -pg -o my_program my_program.c\n",
    "   ./my_program\n",
    "   gprof my_program gmon.out > analysis.txt\n",
    "   ```\n",
    "\n",
    "2. **Benchmarks:**\n",
    "   Los benchmarks son pruebas estándar que permiten comparar el rendimiento de diferentes programas o sistemas bajo condiciones similares. Los benchmarks como SPEC MPI2007, LINPACK, y NAS Parallel Benchmarks son utilizados para evaluar el rendimiento de aplicaciones paralelas y distribuidas. Estos benchmarks proporcionan métricas comparativas que pueden ser utilizadas para evaluar la eficiencia y escalabilidad de los sistemas.\n",
    "\n",
    "#### Optimización\n",
    "\n",
    "1. **Reducción de la contención de recursos:**\n",
    "   La contención de recursos ocurre cuando múltiples procesadores intentan acceder a un recurso compartido simultáneamente, causando retrasos. Para minimizar este problema, se pueden emplear técnicas como el uso de algoritmos de locking más eficientes (e.g., spinlocks, mutexes de bajo coste) y el diseño de algoritmos sin bloqueos (lock-free).\n",
    "\n",
    "   **Ejemplo de uso de mutexes en C++:**\n",
    "   ```cpp\n",
    "   std::mutex mtx;\n",
    "   void thread_function() {\n",
    "       std::lock_guard<std::mutex> guard(mtx);\n",
    "       // Código que accede a recursos compartidos\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **Mejora de la localidad de datos:**\n",
    "   La localidad de datos se refiere a la proximidad de los datos en memoria. Mejorar la localidad de datos puede reducir significativamente la latencia de acceso a memoria. Técnicas como el bloqueado (blocking) y el uso de estructuras de datos que mejoren la cacheabilidad (e.g., arrays contiguos en lugar de listas enlazadas) son fundamentales.\n",
    "\n",
    "   **Ejemplo de bloqueado en multiplicación de matrices:**\n",
    "   ```cpp\n",
    "   void blocked_matrix_multiply(int N, double **A, double **B, double **C, int blockSize) {\n",
    "       for (int ii = 0; ii < N; ii += blockSize) {\n",
    "           for (int jj = 0; jj < N; jj += blockSize) {\n",
    "               for (int kk = 0; kk < N; kk += blockSize) {\n",
    "                   for (int i = ii; i < std::min(ii + blockSize, N); ++i) {\n",
    "                       for (int j = jj; j < std::min(jj + blockSize, N); ++j) {\n",
    "                           for (int k = kk; k < std::min(kk + blockSize, N); ++k) {\n",
    "                               C[i][j] += A[i][k] * B[k][j];\n",
    "                           }\n",
    "                       }\n",
    "                   }\n",
    "               }\n",
    "           }\n",
    "       }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "3. **Reducción de la sobrecarga de comunicación:**\n",
    "   La comunicación entre procesadores puede ser un cuello de botella significativo en sistemas paralelos. Minimizar la cantidad de datos transferidos y utilizar métodos eficientes de comunicación, como la comunicación asincrónica y el agrupamiento de mensajes, puede mejorar el rendimiento.\n",
    "\n",
    "   **Ejemplo de uso de MPI para comunicación asincrónica:**\n",
    "   ```cpp\n",
    "   MPI_Request request;\n",
    "   MPI_Isend(data, count, MPI_DOUBLE, dest, tag, MPI_COMM_WORLD, &request);\n",
    "   MPI_Wait(&request, MPI_STATUS_IGNORE);\n",
    "   ```\n",
    "\n",
    "#### Ejemplo: Optimización de un algoritmo de multiplicación de matrices\n",
    "\n",
    "La multiplicación de matrices es una operación común en muchas aplicaciones científicas y de ingeniería. A continuación, se presenta un análisis detallado de cómo se puede optimizar este algoritmo tanto en su implementación secuencial como en su versión paralela.\n",
    "\n",
    "**Implementación secuencial:**\n",
    "```python\n",
    "def sequential_matrix_multiply(A, B):\n",
    "    N = len(A)\n",
    "    C = [[0] * N for _ in range(N)]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                C[i][j] += A[i][k] * B[k][j]\n",
    "    return C\n",
    "```\n",
    "\n",
    "**Implementación paralela con multiprocessing:**\n",
    "```python\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def parallel_matrix_multiply_worker(args):\n",
    "    A, B, i, N = args\n",
    "    C_row = np.zeros(N)\n",
    "    for j in range(N):\n",
    "        for k in range(N):\n",
    "            C_row[j] += A[i][k] * B[k][j]\n",
    "    return C_row\n",
    "\n",
    "def parallel_matrix_multiply(A, B):\n",
    "    N = len(A)\n",
    "    C = np.zeros((N, N))\n",
    "    with Pool() as pool:\n",
    "        args = [(A, B, i, N) for i in range(N)]\n",
    "        C_rows = pool.map(parallel_matrix_multiply_worker, args)\n",
    "    for i in range(N):\n",
    "        C[i] = C_rows[i]\n",
    "    return C\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    N = 1000\n",
    "    A = np.random.rand(N, N)\n",
    "    B = np.random.rand(N, N)\n",
    "    C = parallel_matrix_multiply(A, B)\n",
    "```\n",
    "\n",
    "**Optimización adicional: uso de bloqueado:**\n",
    "El uso de técnicas de bloqueado (blocking) puede mejorar la localidad de datos y reducir el acceso a la memoria principal, optimizando así el rendimiento del algoritmo.\n",
    "\n",
    "**Implementación de bloqueado:**\n",
    "```python\n",
    "def blocked_matrix_multiply(A, B, blockSize):\n",
    "    N = len(A)\n",
    "    C = [[0] * N for _ in range(N)]\n",
    "    for ii in range(0, N, blockSize):\n",
    "        for jj in range(0, N, blockSize):\n",
    "            for kk in range(0, N, blockSize):\n",
    "                for i in range(ii, min(ii + blockSize, N)):\n",
    "                    for j in range(jj, min(jj + blockSize, N)):\n",
    "                        for k in range(kk, min(kk + blockSize, N)):\n",
    "                            C[i][j] += A[i][k] * B[k][j]\n",
    "    return C\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    N = 1000\n",
    "    blockSize = 50\n",
    "    A = np.random.rand(N, N)\n",
    "    B = np.random.rand(N, N)\n",
    "    C = blocked_matrix_multiply(A, B, blockSize)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2b7a0-f278-40e4-ab7b-df1fc0e92d3c",
   "metadata": {},
   "source": [
    "### Técnicas de balanceo de carga\n",
    "\n",
    "El balanceo de carga es una técnica fundamental en la computación distribuida y en la administración de sistemas para mejorar la eficiencia y el rendimiento de los sistemas de múltiples nodos. A medida que las aplicaciones se vuelven más complejas y demandan mayor capacidad de procesamiento, el balanceo de carga avanzado se convierte en una necesidad crítica. \n",
    "\n",
    "#### Balanceo de carga estático vs. dinámico\n",
    "\n",
    "El balanceo de carga se puede clasificar en estático y dinámico. En el balanceo de carga estático, las tareas se distribuyen entre los nodos antes de la ejecución del programa y no cambian durante el tiempo de ejecución. Este enfoque es adecuado para sistemas con cargas de trabajo predecibles. Sin embargo, no es ideal para entornos donde las cargas de trabajo son variables e impredecibles.\n",
    "\n",
    "El balanceo de carga dinámico, en cambio, ajusta la distribución de las tareas durante el tiempo de ejecución, basándose en el estado actual del sistema. Este enfoque es más adecuado para entornos dinámicos y heterogéneos donde la carga de trabajo puede variar significativamente.\n",
    "\n",
    "#### Particionamiento de datos dinámico\n",
    "\n",
    "El particionamiento de datos dinámico es una técnica avanzada de balanceo de carga que ajusta la distribución de datos entre nodos de acuerdo con las variaciones en la carga de trabajo y el estado del sistema. Esta técnica es particularmente útil en aplicaciones donde la carga de trabajo puede ser altamente irregular y cambiante.\n",
    "\n",
    "1. **Hashing consistente:**\n",
    "   El hashing consistente es una técnica utilizada para distribuir datos de manera uniforme entre nodos. A diferencia del hashing tradicional, el hashing consistente minimiza los cambios en la asignación de datos cuando se añaden o eliminan nodos. Esto es crucial para mantener el equilibrio de carga en sistemas distribuidos.\n",
    "\n",
    "   **Implementación:**\n",
    "   En un sistema de hashing consistente, cada nodo y cada clave se asignan a puntos en un anillo hash. Las claves son asignadas al nodo más cercano en el anillo, y cuando un nodo se añade o se elimina, solo un subconjunto de las claves se reasigna, minimizando la redistribución.\n",
    "\n",
    "2. **Reparto basado en la carga:**\n",
    "   En esta técnica, los datos se redistribuyen dinámicamente entre nodos en función de su carga actual. Los nodos sobrecargados pueden transferir parte de sus datos a nodos menos cargados para equilibrar la carga de trabajo.\n",
    "\n",
    "   **Ejemplo en MapReduce:**\n",
    "   En un sistema MapReduce, los datos de entrada se dividen en bloques, y las tareas de mapeo se asignan a nodos basándose en su proximidad a los datos. Durante la fase de reducción, los datos pueden redistribuirse para equilibrar la carga entre los nodos de reducción.\n",
    "\n",
    "3. **Descomposición dinámica:**\n",
    "   La descomposición dinámica ajusta la granularidad de las tareas basándose en la carga de trabajo actual. Por ejemplo, en un sistema de simulación de partículas, las partículas pueden agruparse en regiones de diferente tamaño dependiendo de la densidad de partículas y la carga de procesamiento requerida.\n",
    "\n",
    "   **Aplicación en simulación:**\n",
    "   En simulaciones de dinámica molecular, las regiones del espacio de simulación con alta densidad de partículas pueden subdividirse en celdas más pequeñas para distribuir la carga de procesamiento de manera más equitativa entre los nodos.\n",
    "\n",
    "#### Algoritmos adaptativos\n",
    "\n",
    "Los algoritmos adaptativos son una clase avanzada de técnicas de balanceo de carga que ajustan dinámicamente la asignación de tareas basándose en el rendimiento y el estado del sistema en tiempo real. Estos algoritmos pueden mejorar significativamente la eficiencia y la utilización de recursos en sistemas distribuidos.\n",
    "\n",
    "1. **Algoritmos de rebalanceo:**\n",
    "   Los algoritmos de rebalanceo ajustan la distribución de tareas durante la ejecución para mantener un equilibrio óptimo. Estos algoritmos monitorean continuamente el rendimiento del sistema y redistribuyen las tareas según sea necesario.\n",
    "\n",
    "   **Algoritmo de rebalanceo en gráficos:**\n",
    "   En la renderización de gráficos distribuidos, los nodos que se quedan atrás en el procesamiento de cuadros pueden transferir parte de su carga a nodos menos ocupados para mantener una tasa de cuadros uniforme.\n",
    "\n",
    "2. **Algoritmos de aprendizaje por refuerzo:**\n",
    "   Los algoritmos de aprendizaje por refuerzo utilizan técnicas de inteligencia artificial para aprender y adaptarse a las condiciones cambiantes del sistema. Estos algoritmos pueden mejorar el rendimiento a largo plazo mediante la optimización continua de la distribución de tareas.\n",
    "\n",
    "   **Aplicación en sistemas en tiempo real:**\n",
    "   En sistemas de control en tiempo real, los algoritmos de aprendizaje por refuerzo pueden ajustar la asignación de tareas en función de la retroalimentación del entorno, optimizando así el rendimiento y la eficiencia energética.\n",
    "\n",
    "3. **Algoritmos de programación lineal:**\n",
    "   Los algoritmos de programación lineal resuelven problemas de asignación de tareas mediante la optimización matemática. Estos algoritmos pueden encontrar la distribución óptima de tareas que minimiza el tiempo de ejecución total o maximiza la utilización de recursos.\n",
    "\n",
    "   **Ejemplo en computación en la nube:**\n",
    "   En entornos de computación en la nube, los algoritmos de programación lineal pueden optimizar la asignación de máquinas virtuales a las cargas de trabajo para minimizar el coste y maximizar el rendimiento.\n",
    "\n",
    "4. **Algoritmos basados en el tiempo de ejecución:**\n",
    "   Estos algoritmos ajustan la asignación de tareas basándose en el tiempo de ejecución observado de las tareas. Por ejemplo, en sistemas de renderización distribuida, las tareas de renderización que tardan más tiempo en completarse pueden subdividirse y redistribuirse para equilibrar la carga.\n",
    "\n",
    "   **Uso en renderización distribuida:**\n",
    "   En la renderización de películas CGI, las escenas complejas pueden dividirse en subescenas más pequeñas y asignarse a diferentes nodos, ajustando dinámicamente la carga en función del tiempo de renderización observado.\n",
    "\n",
    "5. **Algoritmos genéticos:**\n",
    "   Los algoritmos genéticos utilizan técnicas evolutivas para encontrar soluciones óptimas al problema del balanceo de carga. Estos algoritmos generan una población de posibles soluciones y las evolucionan mediante selección, cruce y mutación para encontrar la mejor distribución de tareas.\n",
    "\n",
    "   **Aplicación en redes neuronales distribuidas:**\n",
    "   En el entrenamiento distribuido de redes neuronales, los algoritmos genéticos pueden optimizar la distribución de datos y tareas entre los nodos para acelerar el tiempo de entrenamiento y mejorar la precisión del modelo.\n",
    "\n",
    "6. **Modelos de predicción basados en el comportamiento:**\n",
    "   Estos modelos utilizan datos históricos para predecir la carga futura y ajustar la distribución de tareas en consecuencia. Los modelos de predicción pueden basarse en técnicas estadísticas, machine learning o análisis de series temporales.\n",
    "\n",
    "   **Aplicación en gestión de infraestructura TI:**\n",
    "   En la gestión de infraestructuras TI, los modelos de predicción pueden anticipar picos de carga y redistribuir tareas preventivamente para evitar sobrecargas y garantizar un rendimiento óptimo.\n",
    "\n",
    "#### Técnicas de minimizando el overhead\n",
    "\n",
    "Minimizar el overhead es crucial para maximizar la eficiencia del balanceo de carga. El overhead puede provenir de la comunicación entre nodos, la sincronización y la gestión de tareas.\n",
    "\n",
    "1. **Comunicación asincrónica:**\n",
    "   La comunicación asincrónica permite a los nodos continuar procesando mientras esperan respuestas de otros nodos, reduciendo el tiempo de inactividad. Tecnologías como MPI (Message Passing Interface) soportan la comunicación asincrónica.\n",
    "\n",
    "   **Ejemplo con MPI:**\n",
    "   ```cpp\n",
    "   MPI_Request request;\n",
    "   MPI_Isend(data, count, MPI_DOUBLE, dest, tag, MPI_COMM_WORLD, &request);\n",
    "   MPI_Wait(&request, MPI_STATUS_IGNORE);\n",
    "   ```\n",
    "\n",
    "2. **Reducción de la frecuencia de sincronización:**\n",
    "   Disminuir la frecuencia de sincronización entre nodos puede reducir el overhead de comunicación. Esto se puede lograr mediante técnicas como la relajación de la consistencia y el uso de modelos de consistencia eventual.\n",
    "\n",
    "   **Uso en sistemas de base de datos distribuidas:**\n",
    "   En bases de datos distribuidas, la consistencia eventual permite que las actualizaciones se propaguen de manera asíncrona, reduciendo la necesidad de sincronización frecuente y mejorando el rendimiento.\n",
    "\n",
    "3. **Agregación de mensajes:**\n",
    "   La agregación de mensajes reduce el número de comunicaciones al combinar múltiples mensajes en uno solo. Esto es particularmente útil en sistemas donde el overhead de comunicación es alto.\n",
    "\n",
    "   **Aplicación en redes de sensores:**\n",
    "   En redes de sensores, los datos de múltiples sensores pueden agregarse en un solo mensaje antes de ser transmitidos, reduciendo el número de transmisiones y ahorrando energía.\n",
    "\n",
    "4. **Planificación de tareas basada en prioridades:**\n",
    "   Asignar prioridades a las tareas y planificarlas en consecuencia puede mejorar la eficiencia del sistema. Las tareas de alta prioridad pueden ejecutarse primero, reduciendo el tiempo de espera y mejorando el rendimiento general.\n",
    "\n",
    "   **Ejemplo en sistemas de tiempo real:**\n",
    "   En sistemas de control en tiempo real, las tareas críticas pueden asignarse una mayor prioridad para garantizar que se completen a tiempo, mientras que las tareas menos críticas pueden planificarse para ejecutarse en segundo plano.\n",
    "\n",
    "\n",
    "El balanceo de carga es una técnica crucial en la computación paralela y distribuida que busca optimizar el uso de los recursos y maximizar el rendimiento del sistema. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43b326-3083-408d-9627-1cf67b4ee2ce",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1 . Investiga y analiza un proyecto de investigación o una aplicación industrial donde se haya aplicado la Ley de Amdahl para mejorar el rendimiento del sistema.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Selecciona un caso real de un proyecto de investigación o una aplicación industrial (e.g., simulaciones meteorológicas, procesamiento de imágenes médicas).\n",
    "- Investiga cómo se aplicó la Ley de Amdahl para identificar las partes del sistema que podían ser paralelizadas.\n",
    "- Analiza los resultados obtenidos en términos de speedup y eficiencia.\n",
    "- Discute las limitaciones encontradas y cómo se abordaron.\n",
    "\n",
    "Preguntas de discusión:\n",
    "\n",
    "- ¿Qué fracción del código se pudo paralelizar $P$ y cual es la fracción secuencial $(1 -P)$.\n",
    "- ¿Cuál fue el speedup teórico máximo según la Ley de Amdahl?\n",
    "- ¿Cómo se comparan los resultados reales con los teóricos?\n",
    "- ¿Qué técnicas se utilizaron para minimizar la fracción secuencial?\n",
    "\n",
    "2 . Investiga y analiza un proyecto de investigación o una aplicación industrial donde se haya aplicado la Ley de Gustafson para mejorar el rendimiento del sistema.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Selecciona un caso real de un proyecto de investigación o una aplicación industrial (e.g., renderización gráfica, análisis de grandes volúmenes de datos).\n",
    "- Investiga cómo se aplicó la Ley de Gustafson para escalar la aplicación y mejorar el rendimiento.\n",
    "- Analiza los resultados obtenidos en términos de speedup y eficiencia.\n",
    "- Discute las ventajas y desventajas encontradas al aplicar esta ley.\n",
    "\n",
    "Preguntas de discusión:\n",
    "\n",
    "- ¿Cómo se determinó la fracción paralelizable $(P)$ del código?\n",
    "- ¿Cuál fue el speedup obtenido con un número creciente de procesadores?\n",
    "- ¿Cómo se comparan los resultados reales con las predicciones de la Ley de Gustafson?\n",
    "- ¿Qué mejoras en la eficiencia se observaron al escalar el tamaño del problema?\n",
    "\n",
    "3 . Comparación práctica de las leyes de Amdahl y Gustafson\n",
    "\n",
    "Implementa un experimento comparativo para observar cómo se comportan la Ley de Amdahl y la Ley de Gustafson en diferentes escenarios y tamaños de problema.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Diseña un experimento utilizando una aplicación sencilla (por ejemplo, multiplicación de matrices).\n",
    "- Implementa la versión secuencial y paralela del algoritmo.\n",
    "- Mide el tiempo de ejecución para diferentes fracciones paralelizables $(P)$ y diferentes números de procesadores.\n",
    "- Calcula el speedup teórico y comparar con los resultados reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71cf09-b6c6-464b-a71b-a65512f5ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def matrix_multiply(A, B, start_row, end_row):\n",
    "    C = np.zeros((end_row - start_row, B.shape[1]))\n",
    "    for i in range(start_row, end_row):\n",
    "        for j in range(B.shape[1]):\n",
    "            C[i - start_row][j] = np.dot(A[i, :], B[:, j])\n",
    "    return C\n",
    "\n",
    "def parallel_matrix_multiply(A, B, num_workers):\n",
    "    rows_per_worker = A.shape[0] // num_workers\n",
    "    args = [(A, B, i * rows_per_worker, (i + 1) * rows_per_worker) for i in range(num_workers)]\n",
    "    \n",
    "    with Pool(num_workers) as pool:\n",
    "        results = pool.starmap(matrix_multiply, args)\n",
    "    \n",
    "    return np.vstack(results)\n",
    "\n",
    "N = 1024\n",
    "A = np.random.rand(N, N)\n",
    "B = np.random.rand(N, N)\n",
    "\n",
    "# Ejecución secuencial\n",
    "start_time = time.time()\n",
    "C_seq = matrix_multiply(A, B, 0, N)\n",
    "end_time = time.time()\n",
    "print(f\"Tiempo secuencial: {end_time - start_time} segundos\")\n",
    "\n",
    "# Ejecución paralela\n",
    "num_workers = 4\n",
    "start_time = time.time()\n",
    "C_par = parallel_matrix_multiply(A, B, num_workers)\n",
    "end_time = time.time()\n",
    "print(f\"Tiempo paralelo con {num_workers} trabajadores: {end_time - start_time} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4dc383-d0c9-463a-a6a4-0188077d1868",
   "metadata": {},
   "source": [
    "Preguntas de discusión:\n",
    "\n",
    "- ¿Cómo se comportan las dos leyes con diferentes fracciones paralelizables?\n",
    "- ¿En qué escenarios la Ley de Gustafson ofrece mejores predicciones que la Ley de Amdahl?\n",
    "- ¿Qué limitaciones se observan en ambos casos?\n",
    "\n",
    "4 . Explora cómo la comunicación entre procesadores afecta el rendimiento y cómo se puede minimizar este overhead.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Implementa un algoritmo de suma de vectores que distribuya los datos entre múltiples procesadores.\n",
    "- Mide el tiempo de ejecución total y el tiempo dedicado a la comunicación entre procesadores.\n",
    "- Experimenta con diferentes tamaños de datos y números de procesadores.\n",
    ". Analiza} el overhead de comunicación y proponer técnicas para minimizarlo (por ejemplo, comunicación asíncrona, agrupamiento de mensajes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fcafd-69c2-4d56-85f2-3ff6d31ed745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "N = 1024\n",
    "local_N = N // size\n",
    "\n",
    "if rank == 0:\n",
    "    vector = np.random.rand(N)\n",
    "else:\n",
    "    vector = None\n",
    "\n",
    "local_vector = np.zeros(local_N)\n",
    "comm.Scatter(vector, local_vector, root=0)\n",
    "\n",
    "local_sum = np.sum(local_vector)\n",
    "total_sum = comm.reduce(local_sum, op=MPI.SUM, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Suma total: {total_sum}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a4bf2-6bfd-4a03-98a7-07286a4d34cc",
   "metadata": {},
   "source": [
    "Preguntas de discusión:\n",
    "\n",
    "¿Cómo afecta el overhead de comunicación al rendimiento global del algoritmo?\n",
    "¿Qué técnicas se pueden utilizar para reducir este overhead?\n",
    "¿Cómo cambia el overhead con el aumento del número de procesadores?\n",
    "\n",
    "5 . Estudia la latencia y el ancho de banda en sistemas distribuidos y cómo influyen en la eficiencia del paralelismo.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Implementa un algoritmo de comunicación punto a punto (por ejemplo,  intercambio de mensajes) utilizando MPI.\n",
    "- Mide la latencia y el ancho de banda para diferentes tamaños de mensajes.\n",
    "- Analiza cómo estos parámetros afectan la eficiencia de un algoritmo paralelo.\n",
    "- Propone mejoras para optimizar la comunicación en sistemas distribuidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded2dc6-29fc-4e3a-9272-6992aa3b1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "message_size = 1024 * 1024  # 1 MB\n",
    "message = np.random.rand(message_size) if rank == 0 else np.empty(message_size)\n",
    "\n",
    "if rank == 0:\n",
    "    start_time = time.time()\n",
    "    comm.Send([message, MPI.DOUBLE], dest=1, tag=0)\n",
    "    comm.Recv([message, MPI.DOUBLE], source=1, tag=1)\n",
    "    end_time = time.time()\n",
    "    print(f\"Latencia: {end_time - start_time} segundos\")\n",
    "else:\n",
    "    comm.Recv([message, MPI.DOUBLE], source=0, tag=0)\n",
    "    comm.Send([message, MPI.DOUBLE], dest=0, tag=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d63f87-a793-4f48-b3bb-9d94f0af4567",
   "metadata": {},
   "source": [
    "6 . Implementa un algoritmo de multiplicación de matrices utilizando tanto CPU como GPU y analizar el speedup obtenido al variar el tamaño de las matrices.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Implementa la multiplicación de matrices en Python usando NumPy para la versión en CPU.\n",
    "2. Implementa la multiplicación de matrices usando CUDA con PyCUDA para la versión en GPU.\n",
    "3. Mide los tiempos de ejecución para diferentes tamaños de matrices (e.g., 256x256, 512x512, 1024x1024).\n",
    "4. Calcula el speedup obtenido al usar la GPU en comparación con la CPU.\n",
    "5. Analiza el impacto del tamaño de la matriz en el speedup y discutir los resultados.\n",
    "\n",
    "**Código base:**\n",
    "\n",
    "*CPU:*\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def cpu_matrix_multiply(A, B):\n",
    "    return np.dot(A, B)\n",
    "\n",
    "N = 1024\n",
    "A = np.random.rand(N, N).astype(np.float32)\n",
    "B = np.random.rand(N, N).astype(np.float32)\n",
    "\n",
    "start_time = time.time()\n",
    "C = cpu_matrix_multiply(A, B)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tiempo de CPU: {end_time - start_time} segundos\")\n",
    "```\n",
    "\n",
    "*GPU:*\n",
    "\n",
    "```python\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "N = 1024\n",
    "A = np.random.rand(N, N).astype(np.float32)\n",
    "B = np.random.rand(N, N).astype(np.float32)\n",
    "C = np.zeros((N, N)).astype(np.float32)\n",
    "\n",
    "A_gpu = cuda.mem_alloc(A.nbytes)\n",
    "B_gpu = cuda.mem_alloc(B.nbytes)\n",
    "C_gpu = cuda.mem_alloc(C.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(A_gpu, A)\n",
    "cuda.memcpy_htod(B_gpu, B)\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "__global__ void matrixMul(float *A, float *B, float *C, int N)\n",
    "{\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    float sum = 0.0;\n",
    "    for (int k = 0; k < N; k++) {\n",
    "        sum += A[row * N + k] * B[k * N + col];\n",
    "    }\n",
    "    C[row * N + col] = sum;\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "matrixMul = mod.get_function(\"matrixMul\")\n",
    "\n",
    "block_size = 16\n",
    "grid_size = (N + block_size - 1) // block_size\n",
    "\n",
    "start_time = time.time()\n",
    "matrixMul(A_gpu, B_gpu, C_gpu, np.int32(N), block=(block_size, block_size, 1), grid=(grid_size, grid_size))\n",
    "cuda.memcpy_dtoh(C, C_gpu)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\" Tiempo de GPU: {end_time - start_time} segundos\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c84078-cb3b-4db3-9edc-82aaf5813162",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46d3f0-25dc-466f-9879-1badcbceb9e1",
   "metadata": {},
   "source": [
    "7 . Implementa un filtro digital simple en una FPGA y analizar el rendimiento en comparación con una implementación en CPU.\n",
    "\n",
    "**Tareas:**\n",
    "1. Diseñar e implementar un filtro FIR en VHDL.\n",
    "2. Implementar el mismo filtro en Python para ejecutarlo en una CPU.\n",
    "3. Configurar y sintetizar el diseño en una FPGA.\n",
    "4. Medir los tiempos de ejecución y el consumo de energía en ambos casos.\n",
    "5. Comparar los resultados y discutir las ventajas y desventajas de cada enfoque.\n",
    "\n",
    "**Código base en VHDL:**\n",
    "\n",
    "```vhdl\n",
    "library IEEE;\n",
    "use IEEE.STD_LOGIC_1164.ALL;\n",
    "use IEEE.STD_LOGIC_ARITH.ALL;\n",
    "use IEEE.STD_LOGIC_UNSIGNED.ALL;\n",
    "\n",
    "entity DigitalFilter is\n",
    "    Port ( clk : in STD_LOGIC;\n",
    "           rst : in STD_LOGIC;\n",
    "           data_in : in STD_LOGIC_VECTOR (15 downto 0);\n",
    "           data_out : out STD_LOGIC_VECTOR (15 downto 0));\n",
    "end DigitalFilter;\n",
    "\n",
    "architecture Behavioral of DigitalFilter is\n",
    "    signal coeffs : array (0 to 4) of integer := (1, -2, 3, -2, 1);\n",
    "    signal buffer : array (0 to 4) of integer;\n",
    "begin\n",
    "    process(clk, rst)\n",
    "    begin\n",
    "        if rst = '1' then\n",
    "            buffer <= (others => 0);\n",
    "            data_out <= (others => '0');\n",
    "        elsif rising_edge(clk) then\n",
    "            buffer(0) <= to_integer(unsigned(data_in));\n",
    "            for i in 1 to 4 loop\n",
    "                buffer(i) <= buffer(i - 1);\n",
    "            end loop;\n",
    "            data_out <= std_logic_vector(to_unsigned(buffer(0) * coeffs(0) +\n",
    "                                                      buffer(1) * coeffs(1) +\n",
    "                                                      buffer(2) * coeffs(2) +\n",
    "                                                      buffer(3) * coeffs(3) +\n",
    "                                                      buffer(4) * coeffs(4), 16));\n",
    "        end if;\n",
    "    end process;\n",
    "end Behavioral;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdee6c30-154c-4f64-ba62-1d587de0659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ab86c-5ca7-41cc-a2a9-7b115f9029e3",
   "metadata": {},
   "source": [
    "8 . Implementa un algoritmo de simulación distribuida que utilice tanto CPUs como GPUs, y optimizar la comunicación entre estos componentes para minimizar el overhead.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Diseña un algoritmo de simulación que divida las tareas entre CPUs y GPUs.\n",
    "2. Implementa el algoritmo utilizando PyCUDA para la parte de GPU y MPI para la comunicación entre nodos.\n",
    "3. Mide los tiempos de comunicación y procesamiento por separado.\n",
    "4. Optimiza la comunicación utilizando técnicas como el batching de mensajes y la comunicación asíncrona.\n",
    "5. Analiza el impacto de las optimizaciones en el rendimiento general del sistema.\n",
    "\n",
    "**Código base:**\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "N = 1024\n",
    "A = np.random.rand(N, N).astype(np.float32)\n",
    "B = np.random.rand(N, N).astype(np.float32)\n",
    "C = np.zeros((N, N)).astype(np.float32)\n",
    "\n",
    "A_gpu = cuda.mem_alloc(A.nbytes)\n",
    "B_gpu = cuda.mem_alloc(B.nbytes)\n",
    "C_gpu = cuda.mem_alloc(C.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(A_gpu, A)\n",
    "cuda.memcpy_htod(B_gpu, B)\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "__global__ void matrixMul(float *A, float *B, float *C, int N)\n",
    "{\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    float sum = 0.0;\n",
    "    for (int k = 0; k < N; k++) {\n",
    "        sum += A[row * N + k] * B[k * N + col];\n",
    "    }\n",
    "    C[row * N + col] = sum;\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "matrixMul = mod.get_function(\"matrixMul\")\n",
    "\n",
    "block_size = 16\n",
    "grid_size = (N + block_size - 1) // block_size\n",
    "\n",
    "# Split the work among nodes\n",
    "if rank == 0:\n",
    "    start_row = 0\n",
    "    end_row = N // size\n",
    "else:\n",
    "    start_row = rank * (N // size)\n",
    "    end_row = (rank + 1) * (N // size)\n",
    "\n",
    "start_time = MPI.Wtime()\n",
    "matrixMul(A_gpu, B_gpu, C_gpu, np.int32(N), block=(block_size, block_size, 1), grid=(grid_size, grid_size))\n",
    "cuda.memcpy_dtoh(C[start_row:end_row], C_gpu[start_row:end_row])\n",
    "comm.Barrier()\n",
    "end_time = MPI.Wtime()\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Tiempo total: {end_time - start_time}en segundos\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fba03c-0625-4eef-b83a-bc64ed4204a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e23909-fe2b-4e9f-9e90-e19bcdbcaabc",
   "metadata": {},
   "source": [
    "9 . Diseña y ejecuta un experimento para evaluar la escalabilidad de un sistema heterogéneo que utilice una combinación de CPUs, GPUs y FPGAs.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Selecciona una aplicación adecuada (e.g., simulación de dinámica de fluidos, procesamiento de imágenes).\n",
    "2. Implementa la aplicación utilizando diferentes aceleradores (CPUs, GPUs y FPGAs).\n",
    "3. Configura un entorno de pruebas con una combinación de estos aceleradores.\n",
    "4. Ejecuta la aplicación con diferentes tamaños de problema y número de nodos, y medir el rendimiento y la eficiencia.\n",
    "5. Analiza los resultados para identificar cuellos de botella y discutir la escalabilidad del sistema.\n",
    "\n",
    "**Guía de implementación:**\n",
    "\n",
    "*Configuración del entorno de pruebas:*\n",
    "\n",
    "1. Configura un cluster de computación con nodos que tengan GPUs y FPGAs.\n",
    "2. Desplega el entorno de pruebas utilizando un gestor de recursos como Slurm.\n",
    "\n",
    "*Ejemplo de script de Slurm:*\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=heterogeneous_test\n",
    "#SBATCH --nodes=4\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --gres=gpu:2,fpga:1\n",
    "#SBATCH --time=02:00:00\n",
    "#SBATCH --output\n",
    "\n",
    "=output_%j.txt\n",
    "\n",
    "module load cuda\n",
    "module load intel_fpga\n",
    "\n",
    "srun --mpi=pmi2 python simulation.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397c103-111d-4e7c-bb17-61e4063eac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c19719-dd8a-4445-b73e-a05674689d36",
   "metadata": {},
   "source": [
    "10 .[Opcional]Desarrolla un modelo matemático para predecir el speedup y la eficiencia en un sistema heterogéneo basado en las características de los componentes del sistema y la carga de trabajo.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Revisa la literatura sobre modelos de speedup y eficiencia, como las Leyes de Amdahl y Gustafson.\n",
    "2. Desarrolla un modelo que tenga en cuenta la heterogeneidad del sistema, incluyendo CPUs, GPUs y FPGAs.\n",
    "3. Valida el modelo con datos experimentales obtenidos de la ejecución de aplicaciones en un sistema heterogéneo.\n",
    "4. Compara los resultados del modelo con las mediciones reales y discutir cualquier discrepancia.\n",
    "5. Ajusta el modelo según sea necesario para mejorar su precisión.\n",
    "\n",
    "**Ejemplo de fórmula:**\n",
    "\n",
    "$$ S = \\frac{T_s}{T_p} = \\frac{T_s}{T_{cpu} + T_{gpu} + T_{fpga} + T_{com}} $$\n",
    "\n",
    "Donde:\n",
    "- $T_s$ es el tiempo de ejecución en un sistema secuencial.\n",
    "- $T_p$ es el tiempo de ejecución en el sistema paralelo.\n",
    "- $T_{cpu}$, $T_{gpu}$, $T_{fpga}$ son los tiempos de ejecución en CPU, GPU y FPGA respectivamente.\n",
    "- $T_{com}$ es el tiempo de comunicación entre los componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f9769-6d75-4901-a6ea-e662106b3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115a6f1-6f9e-486a-b1a7-0aa211bd933c",
   "metadata": {},
   "source": [
    "11 . Utiliza herramientas de profiling y benchmarking para identificar cuellos de botella en el rendimiento de aplicaciones paralelas.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "* Implementa un programa paralelo (por ejemplo multiplicación de matrices) en C o C++.\n",
    "* Utiliza herramientas de profiling (e.g., gprof, perf) para identificar las partes del código que consumen más tiempo.\n",
    "* Realiza benchmarking con diferentes tamaños de matrices y comparar los resultados.\n",
    "* Optimiza el código basado en los resultados del profiling y benchmarking.\n",
    "* Realiza los pasos anteriores usando python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f7d46-7c6f-45f4-8bf0-3fe1051fb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <chrono>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "void matrix_multiply(const vector<vector<int>>& A, const vector<vector<int>>& B, vector<vector<int>>& C, int N) {\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        for (int j = 0; j < N; ++j) {\n",
    "            C[i][j] = 0;\n",
    "            for (int k = 0; k < N; ++k) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int N = 1000;\n",
    "    vector<vector<int>> A(N, vector<int>(N, 1));\n",
    "    vector<vector<int>> B(N, vector<int>(N, 1));\n",
    "    vector<vector<int>> C(N, vector<int>(N, 0));\n",
    "\n",
    "    auto start = chrono::high_resolution_clock::now();\n",
    "    matrix_multiply(A, B, C, N);\n",
    "    auto end = chrono::high_resolution_clock::now();\n",
    "\n",
    "    chrono::duration<double> diff = end - start;\n",
    "    cout << \"Tiempo de ejecución: \" << diff.count() << \" s\" << endl;\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fc6af-e403-46d5-8497-7d1fd0ce0c14",
   "metadata": {},
   "source": [
    "**Instrucciones de profiling:**\n",
    "\n",
    "- Compila con g++ -o matrix_mult matrix_mult.cpp -pg\n",
    "- Ejecuta el programa: ./matrix_mult\n",
    ". Genera el reporte de profiling: gprof ./matrix_mult gmon.out > report.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953a950-2014-4cad-89ec-e8bca7d17734",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a561c3-314e-432f-9c3f-925a9b113811",
   "metadata": {},
   "source": [
    "12 . Implementa y evalua diferentes técnicas de balanceo de carga en aplicaciones paralelas.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Implementa un algoritmo de simulación (por ejemplo el cálculo de pi) con balanceo de carga estático.\n",
    "- Implementa el mismo algoritmo con balanceo de carga dinámico.\n",
    "- Compara el rendimiento y la eficiencia de ambas implementaciones bajo diferentes cargas de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526efde4-8adb-4b9a-ac49-253a708a3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de balanceo estatico\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "N = 10000000\n",
    "local_N = N // size\n",
    "\n",
    "def compute_pi(local_N):\n",
    "    count = 0\n",
    "    for i in range(local_N):\n",
    "        x = np.random.rand()\n",
    "        y = np.random.rand()\n",
    "        if x**2 + y**2 <= 1.0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "local_count = compute_pi(local_N)\n",
    "total_count = comm.reduce(local_count, op=MPI.SUM, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    pi = 4 * total_count / N\n",
    "    print(f\"Estimación de pi: {pi}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d9c98-0323-453a-9b91-a4e25f88c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Ejemplo para balanceo dinámico\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "N = 10000000\n",
    "chunk_size = 1000\n",
    "\n",
    "def compute_pi(chunk_size):\n",
    "    count = 0\n",
    "    for _ in range(chunk_size):\n",
    "        x = np.random.rand()\n",
    "        y = np.random.rand()\n",
    "        if x**2 + y**2 <= 1.0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "total_count = 0\n",
    "\n",
    "if rank == 0:\n",
    "    tasks = N // chunk_size\n",
    "    for i in range(1, size):\n",
    "        comm.send(tasks, dest=i, tag=0)\n",
    "    for i in range(tasks):\n",
    "        local_count = comm.recv(source=MPI.ANY_SOURCE, tag=1)\n",
    "        total_count += local_count\n",
    "    for i in range(1, size):\n",
    "        comm.send(0, dest=i, tag=0)  # Enviar señal de terminación\n",
    "else:\n",
    "    while True:\n",
    "        tasks = comm.recv(source=0, tag=0)\n",
    "        if tasks == 0:\n",
    "            break\n",
    "        local_count = compute_pi(chunk_size)\n",
    "        comm.send(local_count, dest=0, tag=1)\n",
    "\n",
    "if rank == 0:\n",
    "    pi = 4 * total_count / N\n",
    "    print(f\"Estimación de pi: {pi}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597bcd5-6c74-4de3-8d18-160db61ac5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a6a31-0650-41e8-ab74-ce51d4389d48",
   "metadata": {},
   "source": [
    "13 . Mide y analiza la latencia y el ancho de banda de un sistema de comunicación paralelo.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Implementa un programa para medir la latencia de comunicación punto a punto usando MPI.\n",
    "- Implementa un programa para medir el ancho de banda de comunicación usando MPI.\n",
    "- Analiza los resultados y discutir cómo la latencia y el ancho de banda afectan el rendimiento de aplicaciones paralelas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366b121-785f-4018-91b2-11f709ed47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo para latencia\n",
    "from mpi4py import MPI\n",
    "import time\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    start_time = time.time()\n",
    "    comm.send('ping', dest=1, tag=0)\n",
    "    comm.recv(source=1, tag=1)\n",
    "    end_time = time.time()\n",
    "    print(f\"Latencia: {end_time - start_time} segundos\")\n",
    "\n",
    "elif rank == 1:\n",
    "    msg = comm.recv(source=0, tag=0)\n",
    "    comm.send('pong', dest=0, tag=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256af11-3fac-4f84-8111-e7b0b1b4e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo para ancho de banda\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "N = 1000000  # Tamaño del mensaje\n",
    "data = np.ones(N, dtype='float64')\n",
    "\n",
    "if rank == 0:\n",
    "    start_time = time.time()\n",
    "    comm.Send([data, MPI.DOUBLE], dest=1, tag=0)\n",
    "    end_time = time.time()\n",
    "    print(f\"Ancho de banda: {N * 8 / (end_time - start_time) / 1e6} MB/s\")\n",
    "\n",
    "elif rank == 1:\n",
    "    comm.Recv([data, MPI.DOUBLE], source=0, tag=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1827d6-5da2-4d60-8e68-c62a4fc5389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28a8d4-44e3-4982-888f-d16e2a8e4b73",
   "metadata": {},
   "source": [
    "14 . Evaluar el impacto del overhead de comunicación en el rendimiento de aplicaciones paralelas.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Implementa un programa paralelo (e.g., suma de matrices) utilizando MPI.\n",
    "- Mide el tiempo de ejecución con diferentes tamaños de mensajes y número de procesadores.\n",
    "- Analiza el overhead de comunicación y su impacto en el rendimiento global.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce2f8e-c6b6-434f-8119-168ddd199221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "N = 10000  # Tamaño de las matrices\n",
    "A = np.random.rand(N, N) if rank == 0 else None\n",
    "B = np.random.rand(N, N) if rank == 0 else None\n",
    "C = np.zeros((N, N)) if rank == 0 else None\n",
    "\n",
    "if rank == 0:\n",
    "    start_time = time.time()\n",
    "\n",
    "# Distribuir las matrices a todos los procesos\n",
    "A = comm.bcast(A, root=0)\n",
    "B = comm.bcast(B, root=0)\n",
    "\n",
    "# Suma de matrices en paralelo\n",
    "rows_per_proc = N // size\n",
    "local_A = A[rank*rows_per_proc:(rank+1)*rows_per_proc, :]\n",
    "local_C = np.zeros_like(local_A)\n",
    "\n",
    "for i in range(rows_per_proc):\n",
    "    for j in range(N):\n",
    "        local_C[i, j] = local_A[i, j] + B[i, j]\n",
    "\n",
    "# Recopilar los resultados en el proceso raíz\n",
    "comm.Gather(local_C, C, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    end_time = time.time()\n",
    "    print(f\"Tiempo total de ejecución: {end_time - start_time} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4370b8a-fc58-4f85-8cfb-98c34fd2cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
