{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc986a81",
   "metadata": {},
   "source": [
    "## Modelos de programación distribuida\n",
    "\n",
    "La programación distribuida se refiere a un paradigma de programación en el que múltiples procesos o nodos trabajan juntos para resolver un problema, comunicándose y coordinando sus acciones a través de una red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ddd0a5",
   "metadata": {},
   "source": [
    "### Arquitectura de MPI\n",
    "\n",
    "MPI es una especificación estándar que define cómo los datos pueden ser intercambiados entre múltiples procesos que pueden estar ejecutándose en una misma máquina o en diferentes máquinas conectadas por una red. No es una implementación por sí misma, sino una especificación; existen múltiples implementaciones de MPI, como MPICH, OpenMPI y MVAPICH, cada una optimizada para diferentes arquitecturas y redes.\n",
    "\n",
    "**Procesos y comunicaciones**\n",
    "\n",
    "En MPI, cada tarea o proceso es generalmente una instancia separada de un programa que puede ejecutarse en un procesador diferente o en el mismo procesador en paralelo. Estos procesos se comunican entre sí mediante el envío y recepción de mensajes. MPI proporciona varias funciones para facilitar esta comunicación:\n",
    "\n",
    "* `MPI_Send` y `MPI_Recv`: Estas son las funciones básicas de envío y recepción de mensajes en MPI. MPI_Send permite a un proceso enviar datos a otro, mientras que MPI_Recv permite a un proceso recibir datos. Ambos son bloqueantes por defecto, lo que significa que el proceso remitente esperará hasta que el mensaje haya sido enviado y el receptor hasta que el mensaje haya sido recibido.\n",
    "\n",
    "* `MPI_Isend` y `MPI_Irecv`: Estas funciones son las versiones no bloqueantes de MPI_Send y MPI_Recv. Permiten que los procesos continúen con sus tareas mientras se completan las operaciones de comunicación en el fondo. Esto puede mejorar el rendimiento en aplicaciones donde la latencia de comunicación es crítica.\n",
    "\n",
    "* `MPI_Bcast`: La función de difusión (broadcast) permite enviar un mensaje desde un proceso a todos los demás procesos en un grupo. Esto es útil cuando un nodo necesita distribuir datos a todos los otros nodos.\n",
    "\n",
    "* `MPI_Scatter` y `MPI_Gather`: MPI_Scatter distribuye datos desde un proceso a todos los procesos en un grupo, mientras que MPI_Gather recopila datos de todos los procesos en un grupo en un solo proceso. Estas funciones son esenciales para operaciones de descomposición y recolección de datos.\n",
    "\n",
    "* `MPI_Allgather` y `MPI_Alltoall`: MPI_Allgather es una operación en la que todos los procesos envían datos a todos los otros procesos y reciben datos de todos los demás. MPI_Alltoall permite a todos los procesos enviar datos a todos los demás procesos y recibir datos de todos los otros procesos, facilitando operaciones de intercambio complejo de datos.\n",
    "\n",
    "**Comunicación colectiva**\n",
    "\n",
    "MPI soporta operaciones colectivas que involucran todos los procesos en un grupo:\n",
    "\n",
    "* `MPI_Barrier`: Esta función sirve como un punto de sincronización en el que todos los procesos deben esperar hasta que todos hayan alcanzado este punto antes de continuar. Es útil para coordinar fases de ejecución en programas distribuidos.\n",
    "\n",
    "* `MPI_Reduce` y `MPI_Allreduce`: MPI_Reduce combina los datos de todos los procesos y devuelve el resultado a un solo proceso, mientras que MPI_Allreduce hace lo mismo pero devuelve el resultado a todos los procesos. Estas funciones son vitales para operaciones que requieren la combinación de resultados parciales, como la suma de vectores.\n",
    "\n",
    "**Topologías de comunicación**\n",
    "\n",
    "MPI permite definir topologías de comunicación para organizar los procesos en estructuras lógicas que pueden coincidir con la estructura del problema:\n",
    "\n",
    "* `MPI_Cart_create`: Crea una topología cartesiana que organiza los procesos en una malla o cuadrícula. Esto es útil para problemas de malla estructurada en simulaciones científicas.\n",
    "\n",
    "* `MPI_Graph_create`: Define una topología gráfica arbitraria, permitiendo una mayor flexibilidad para problemas con patrones de comunicación no regulares.\n",
    "\n",
    "**Grupos y comunicadores**\n",
    "\n",
    "En MPI, los grupos y comunicadores son fundamentales para gestionar la comunicación entre procesos:\n",
    "\n",
    "* Grupos: Un grupo en MPI es una colección ordenada de procesos. Los grupos permiten organizar los procesos en subconjuntos que pueden comunicarse entre sí de manera independiente de otros grupos.\n",
    "\n",
    "* Comunicadores: Un comunicador define un contexto de comunicación dentro de un grupo. `MPI_COMM_WORLD` es el comunicador predefinido que incluye todos los procesos. Los comunicadores pueden ser duplicados (`MPI_Comm_dup`) o divididos (`MPI_Comm_split`) para crear nuevos contextos de comunicación.\n",
    "\n",
    "**Sincronización y consistencia**\n",
    "\n",
    "La sincronización y la consistencia de los datos son cruciales en aplicaciones distribuidas para asegurar que todos los procesos trabajen con datos coherentes:\n",
    "\n",
    "- `MPI_Wait` y `MPI_Test`: Estas funciones se utilizan con operaciones no bloqueantes. `MPI_Wait` espera a que una operación no bloqueante se complete, mientras que MPI_Test verifica si una operación no bloqueante se ha completado sin bloquear el proceso.\n",
    "\n",
    "* `MPI_Barrier`: Aparte de ser una operación colectiva, `MPI_Barrier` también asegura que todos los procesos hayan alcanzado un punto particular en el código, ayudando a coordinar y sincronizar las fases del programa.\n",
    "\n",
    "**Implementaciones y optimización**\n",
    "\n",
    "Las implementaciones de MPI están altamente optimizadas para diferentes arquitecturas y redes. MPICH y OpenMPI son dos de las implementaciones más populares, ambas ofreciendo características avanzadas como:\n",
    "\n",
    "* Optimización de redes: Implementaciones de MPI están diseñadas para aprovechar al máximo las capacidades de red, como InfiniBand, Ethernet y otros interconexiones de alta velocidad, utilizando técnicas como la multiplexación de mensajes y la compresión de datos para reducir la latencia y aumentar el rendimiento.\n",
    "\n",
    "* Binding de procesos: MPI permite el binding de procesos a núcleos específicos del procesador para minimizar la contención de recursos y maximizar el rendimiento, especialmente en sistemas multinúcleo.\n",
    "\n",
    "* Tolerancia a fallos: Aunque no todos los estándares MPI soportan nativamente la tolerancia a fallos, algunas implementaciones como `ULFM` (User Level Failure Mitigation) proporcionan mecanismos para manejar fallos de procesos y continuar la ejecución.\n",
    "\n",
    "**Herramientas y bibliotecas complementarias**\n",
    "\n",
    "MPI es frecuentemente utilizado en conjunto con otras herramientas y bibliotecas para mejorar el desarrollo y la ejecución de aplicaciones distribuidas:\n",
    "\n",
    "* Herramientas de depuración: Herramientas como TotalView y DDT proporcionan capacidades avanzadas de depuración para programas MPI, permitiendo a los desarrolladores rastrear y solucionar problemas en aplicaciones paralelas.\n",
    "\n",
    "* Bibliotecas de alto Nivel: Librerías como PETSc y Trilinos construyen sobre MPI para proporcionar estructuras de datos y algoritmos paralelos de alto nivel, facilitando el desarrollo de aplicaciones científicas complejas.\n",
    "\n",
    "**Rendimiento y escalabilidad**\n",
    "\n",
    "El rendimiento y la escalabilidad son aspectos críticos en la programación con MPI. Los desarrolladores deben considerar:\n",
    "\n",
    "* Overhead de comunicación: Minimizar el overhead de comunicación es esencial para el desempeño de aplicaciones MPI. Esto se puede lograr mediante el uso de comunicaciones no bloqueantes, la agregación de mensajes y la optimización de las topologías de comunicación.\n",
    "\n",
    "* Balance de carga: Asegurar que todas las tareas estén equitativamente distribuidas entre los procesos es crucial para evitar cuellos de botella. Técnicas de balance de carga dinámico pueden ser utilizadas para redistribuir tareas en tiempo de ejecución.\n",
    "\n",
    "* Modelos híbridos: En muchos casos, combinar MPI con otros modelos de programación paralela, como OpenMP, puede proporcionar mejoras significativas en el rendimiento al aprovechar el paralelismo tanto a nivel de nodo como de red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8632340",
   "metadata": {},
   "source": [
    "### Ejemplos\n",
    "\n",
    "Este ejemplo en C utiliza MPI para resolver una operación de reducción personalizada sobre una topología cartesiana de procesos. La reducción personalizada calculará la suma de cuadrados de elementos distribuidos en una malla 2D.\n",
    "\n",
    "\n",
    "Nota: Una topología cartesiana de procesos es una estructura que organiza y distribuye procesos en un sistema paralelo o distribuido en una forma de grilla o matriz multidimensional, típicamente en dos o tres dimensiones. Esta organización facilita la comunicación y coordinación entre los procesos, especialmente en aplicaciones que requieren operaciones de vecinos o que se benefician de una disposición espacial regular, como en simulaciones numéricas, procesamiento de imágenes, y ciertos algoritmos de computación científica.\n",
    "\n",
    "\n",
    "- 2D Topología: Los procesos se organizan en una matriz bidimensional.\n",
    "- 3D Topología: Los procesos se organizan en una matriz tridimensional.\n",
    "\n",
    "Vecindad:\n",
    "\n",
    "Cada proceso tiene vecinos a los que puede comunicarse directamente. En una topología 2D, un proceso puede comunicarse con hasta cuatro vecinos (arriba, abajo, izquierda, derecha).\n",
    "\n",
    "En una topología 3D, un proceso puede comunicarse con hasta seis vecinos (arriba, abajo, izquierda, derecha, frente, detrás).\n",
    "\n",
    "Coordenadas cartesianas:\n",
    "\n",
    "Cada proceso tiene una coordenada única que lo identifica en la grilla. Por ejemplo, en una topología 2D, un proceso podría estar en la coordenada (i, j).\n",
    "\n",
    "Comunicación eficiente:\n",
    "\n",
    "La organización cartesiana facilita la implementación de patrones de comunicación locales, lo cual es eficiente y escalable, reduciendo la latencia y el overhead en las comunicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6212bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "// Función de operación personalizada para suma de cuadrados\n",
    "void sum_of_squares(void *in, void *inout, int *len, MPI_Datatype *dptr) {\n",
    "    int i;\n",
    "    for (i = 0; i < *len; i++) {\n",
    "        ((double*)inout)[i] += ((double*)in)[i] * ((double*)in)[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int size, rank;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\n",
    "    int dims[2] = {0, 0};\n",
    "    MPI_Dims_create(size, 2, dims);\n",
    "\n",
    "    int periods[2] = {0, 0};\n",
    "    MPI_Comm cart_comm;\n",
    "    MPI_Cart_create(MPI_COMM_WORLD, 2, dims, periods, 0, &cart_comm);\n",
    "\n",
    "    double local_value = rank + 1.0;\n",
    "    double global_value;\n",
    "\n",
    "    MPI_Op custom_op;\n",
    "    MPI_Op_create(&sum_of_squares, 1, &custom_op);\n",
    "\n",
    "    MPI_Reduce(&local_value, &global_value, 1, MPI_DOUBLE, custom_op, 0, cart_comm);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        printf(\"Resultado de la suma de cuadrados: %f\\n\", global_value);\n",
    "    }\n",
    "\n",
    "    MPI_Op_free(&custom_op);\n",
    "    MPI_Comm_free(&cart_comm);\n",
    "    MPI_Finalize();\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60123c7f",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Topología cartesiana: Se crea una topología cartesiana para distribuir los procesos en una malla 2D.\n",
    "* Operación personalizada: Se define una operación de reducción personalizada (sum_of_squares) que calcula la suma de los cuadrados de los elementos.\n",
    "* Reducción colectiva: `MPI_Reduce` se utiliza para aplicar la operación personalizada a todos los elementos y obtener el resultado en el proceso raíz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b73df",
   "metadata": {},
   "source": [
    "Este ejemplo en Python utiliza MPI para realizar una operación de `scatter` y `gather` no bloqueante, seguido de una reducción colectiva para calcular la media de los elementos distribuidos en un grupo de procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be199b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# Datos iniciales en el proceso raíz\n",
    "if rank == 0:\n",
    "    data = np.arange(size * 10, dtype='d')\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "# Crear un array para recibir datos en cada proceso\n",
    "recvbuf = np.empty(10, dtype='d')\n",
    "\n",
    "# Operaciones no bloqueantes de scatter y gather\n",
    "req = comm.Iscatter(data, recvbuf, root=0)\n",
    "req.Wait()\n",
    "\n",
    "# Cada proceso realiza alguna operación sobre sus datos\n",
    "recvbuf = recvbuf**2\n",
    "\n",
    "# Buffer para recopilar resultados\n",
    "if rank == 0:\n",
    "    gathered_data = np.empty(size * 10, dtype='d')\n",
    "else:\n",
    "    gathered_data = None\n",
    "\n",
    "req = comm.Igather(recvbuf, gathered_data, root=0)\n",
    "req.Wait()\n",
    "\n",
    "# Proceso raíz realiza reducción colectiva para calcular la media\n",
    "if rank == 0:\n",
    "    mean_value = np.mean(gathered_data)\n",
    "    print(f\"Media de los cuadrados: {mean_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b274004",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Scatter no bloqueante: `comm.Iscatter` se utiliza para distribuir los datos desde el proceso raíz a todos los otros procesos de manera no bloqueante.\n",
    "* Gather no bloqueante: `comm.Igather` se usa para recopilar los datos procesados desde todos los procesos de vuelta al proceso raíz de manera no bloqueante.\n",
    "* Reducción colectiva: Se calcula la media de los elementos recolectados en el proceso raíz utilizando operaciones de NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4fce7",
   "metadata": {},
   "source": [
    "Este ejemplo en C implementa el algoritmo de la suma prefix usando comunicaciones no bloqueantes (`MPI_Isend` y `MPI_Irecv`) y grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int size, rank;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\n",
    "    int *sendbuf = malloc(size * sizeof(int));\n",
    "    int *recvbuf = malloc(size * sizeof(int));\n",
    "\n",
    "    // Inicializar datos\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        sendbuf[i] = rank + i;\n",
    "    }\n",
    "\n",
    "    // Operaciones no bloqueantes\n",
    "    MPI_Request reqs[2];\n",
    "    MPI_Isend(sendbuf, size, MPI_INT, (rank + 1) % size, 0, MPI_COMM_WORLD, &reqs[0]);\n",
    "    MPI_Irecv(recvbuf, size, MPI_INT, (rank - 1 + size) % size, 0, MPI_COMM_WORLD, &reqs[1]);\n",
    "\n",
    "    // Esperar a que las operaciones se completen\n",
    "    MPI_Waitall(2, reqs, MPI_STATUSES_IGNORE);\n",
    "\n",
    "    // Realizar la suma prefix\n",
    "    for (int i = 1; i < size; i++) {\n",
    "        recvbuf[i] += recvbuf[i-1];\n",
    "    }\n",
    "\n",
    "    printf(\"Proceso %d: \", rank);\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        printf(\"%d \", recvbuf[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    free(sendbuf);\n",
    "    free(recvbuf);\n",
    "    MPI_Finalize();\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193ea23",
   "metadata": {},
   "source": [
    "Explicación:\n",
    "\n",
    "* Comunicación asincrónica: Utiliza `MPI_Isend` y `MPI_Irecv` para enviar y recibir datos de forma no bloqueante.\n",
    "* Suma Prefix: Después de la comunicación, cada proceso calcula la suma prefix de los datos recibidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0e958",
   "metadata": {},
   "source": [
    "Este ejemplo en Python utiliza MPI para resolver el problema de la multiplicación de matrices de manera distribuida, dividiendo las filas de la matriz entre los procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# Tamaño de la matriz\n",
    "N = 8\n",
    "\n",
    "# Inicializar matrices\n",
    "if rank == 0:\n",
    "    A = np.random.rand(N, N)\n",
    "    B = np.random.rand(N, N)\n",
    "else:\n",
    "    A = np.empty((N, N), dtype='d')\n",
    "    B = np.empty((N, N), dtype='d')\n",
    "\n",
    "# Broadcast de la matriz B a todos los procesos\n",
    "comm.Bcast(B, root=0)\n",
    "\n",
    "# Dividir la matriz A entre los procesos\n",
    "rows_per_process = N // size\n",
    "local_A = np.empty((rows_per_process, N), dtype='d')\n",
    "\n",
    "comm.Scatter(A, local_A, root=0)\n",
    "\n",
    "# Cada proceso realiza la multiplicación de su subconjunto de filas\n",
    "local_C = np.dot(local_A, B)\n",
    "\n",
    "# Recopilar los resultados en la matriz C completa en el proceso raíz\n",
    "C = None\n",
    "if rank == 0:\n",
    "    C = np.empty((N, N), dtype='d')\n",
    "\n",
    "comm.Gather(local_C, C, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Matriz A:\")\n",
    "    print(A)\n",
    "    print(\"Matriz B:\")\n",
    "    print(B)\n",
    "    print(\"Matriz C (resultado de A*B):\")\n",
    "    print(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f80dc",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Broadcast de matriz: La matriz B se distribuye a todos los procesos utilizando comm.Bcast.\n",
    "* Scatter de matriz: La matriz A se divide en subconjuntos de filas que se distribuyen a los procesos utilizando comm.Scatter.\n",
    "* Multiplicación local: Cada proceso multiplica su subconjunto de filas de A con la matriz B.\n",
    "* Gather de resultados: Los resultados se recopilan en el proceso raíz utilizando `comm.Gather`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4d078",
   "metadata": {},
   "source": [
    "Este ejemplo en C utiliza una topología gráfica y realiza una operación de comunicación colectiva personalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "void my_operation(void *invec, void *inoutvec, int *len, MPI_Datatype *datatype) {\n",
    "    int i;\n",
    "    for (i = 0; i < *len; i++) {\n",
    "        ((int*)inoutvec)[i] += ((int*)invec)[i] * ((int*)invec)[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int size, rank;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\n",
    "    int edges[2 * size];\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        edges[2 * i] = (i + 1) % size;\n",
    "        edges[2 * i + 1] = (i - 1 + size) % size;\n",
    "    }\n",
    "\n",
    "    MPI_Comm graph_comm;\n",
    "    int index[size];\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        index[i] = 2 * (i + 1);\n",
    "    }\n",
    "    MPI_Graph_create(MPI_COMM_WORLD, size, index, edges, 0, &graph_comm);\n",
    "\n",
    "    int local_value = rank + 1;\n",
    "    int global_value;\n",
    "\n",
    "    MPI_Op myop;\n",
    "    MPI_Op_create(&my_operation, 1, &myop);\n",
    "\n",
    "    MPI_Reduce(&local_value, &global_value, 1, MPI_INT, myop, 0, graph_comm);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        printf(\"Resultado de la operación personalizada: %d\\n\", global_value);\n",
    "    }\n",
    "\n",
    "    MPI_Op_free(&myop);\n",
    "    MPI_Comm_free(&graph_comm);\n",
    "    MPI_Finalize();\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e98786",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Topología gráfica: Se crea una topología gráfica con conexiones personalizadas entre los procesos.\n",
    "* Operación personalizada: Se define y utiliza una operación personalizada para la reducción colectiva.\n",
    "* Reducción colectiva: `MPI_Reduce` aplica la operación personalizada a todos los procesos y obtiene el resultado en el proceso raíz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65276c",
   "metadata": {},
   "source": [
    "Este ejemplo en Python implementa un algoritmo de búsqueda paralela utilizando comunicaciones no bloqueantes y grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69082845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# Definir el tamaño del problema\n",
    "N = 100000\n",
    "sub_size = N // size\n",
    "\n",
    "# Inicializar datos\n",
    "if rank == 0:\n",
    "    data = np.random.randint(0, 100, N)\n",
    "    target = np.random.randint(0, 100)\n",
    "else:\n",
    "    data = None\n",
    "    target = None\n",
    "\n",
    "# Broadcast del target a todos los procesos\n",
    "target = comm.bcast(target, root=0)\n",
    "\n",
    "# Scatter de los datos a los procesos\n",
    "sub_data = np.empty(sub_size, dtype='i')\n",
    "comm.Scatter(data, sub_data, root=0)\n",
    "\n",
    "# Búsqueda en el subconjunto de datos\n",
    "found_indices = np.where(sub_data == target)[0]\n",
    "\n",
    "# Recolectar resultados\n",
    "all_found_indices = comm.gather(found_indices, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    all_found_indices = np.concatenate(all_found_indices)\n",
    "    print(f\"Índices encontrados del objetivo ({target}): {all_found_indices}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144cd28",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Broadcast del objetivo: El valor objetivo de búsqueda se distribuye a todos los procesos utilizando `comm.bcast`.\n",
    "* Scatter de datos: Los datos se dividen entre los procesos utilizando `comm.Scatter`.\n",
    "* Búsqueda local: Cada proceso busca el valor objetivo en su subconjunto de datos.\n",
    "* Gather de resultados: Los índices encontrados se recopilan en el proceso raíz utilizando `comm.gather`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff1d2d",
   "metadata": {},
   "source": [
    "### Remote Procedure Call (RPC)\n",
    "\n",
    "Remote Procedure Call (RPC) es una tecnología fundamental en la computación distribuida, que permite a un programa ejecutar procedimientos en una máquina remota como si fueran locales. Este mecanismo es esencial para la comunicación y colaboración entre sistemas distribuidos, facilitando la implementación de aplicaciones escalables y de alta disponibilidad.\n",
    "\n",
    "**Arquitectura de RPC**\n",
    "\n",
    "La arquitectura de RPC consiste en varios componentes clave que facilitan la comunicación entre el cliente y el servidor. Los elementos principales incluyen el stub del cliente, el stub del servidor, el protocolo de comunicación, y el middleware de RPC.\n",
    "\n",
    "**Stub del cliente**\n",
    "\n",
    "El stub del cliente es un componente que reside en el lado del cliente y actúa como un intermediario entre la aplicación cliente y la red. Cuando el cliente invoca un procedimiento remoto, el stub del cliente:\n",
    "\n",
    "* Empaqueta (serializa) los parámetros: Convierte los parámetros de la llamada al procedimiento en un formato adecuado para su transmisión a través de la red.\n",
    "* Envía la solicitud: Transmite los datos empaquetados al stub del servidor mediante el protocolo de comunicación especificado.\n",
    "\n",
    "**Stub del servidor**\n",
    "\n",
    "El stub del servidor reside en el lado del servidor y se encarga de recibir las solicitudes del cliente. Sus principales responsabilidades incluyen:\n",
    "\n",
    "* Desempaquetar (deserializar) los parámetros: Convierte los datos recibidos de vuelta a un formato utilizable por el procedimiento en el servidor.\n",
    "* Invocar el procedimiento: Llama al procedimiento solicitado en el servidor con los parámetros desempaquetados.\n",
    "* Empaquetar y enviar la respuesta: Tras ejecutar el procedimiento, empaqueta los resultados y los envía de vuelta al stub del cliente.\n",
    "\n",
    "**Protocolo de comunicación**\n",
    "\n",
    "El protocolo de comunicación define cómo se transmiten los mensajes entre el cliente y el servidor. Los protocolos más comunes utilizados en RPC incluyen TCP/IP para comunicaciones fiables y UDP para comunicaciones más rápidas pero no garantizadas. Los mensajes en RPC típicamente consisten en:\n",
    "\n",
    "- Solicitudes: Mensajes enviados desde el cliente al servidor para solicitar la ejecución de un procedimiento remoto.\n",
    "- Respuestas: Mensajes enviados desde el servidor al cliente con los resultados de la ejecución del procedimiento.\n",
    "\n",
    "**Middleware de RPC**\n",
    "\n",
    "El middleware de RPC es una capa intermedia que facilita la comunicación entre el cliente y el servidor, gestionando tareas como la localización del servidor, la conexión y desconexión, y la seguridad. Proporciona una abstracción que simplifica el uso de RPC para los desarrolladores.\n",
    "\n",
    "**Funcionamiento de RPC**\n",
    "\n",
    "El proceso de una llamada RPC se puede desglosar en varios pasos clave:\n",
    "\n",
    "1. Invocación del cliente: El cliente llama a un procedimiento remoto a través del stub del cliente.\n",
    "2. Serialización y envío: El stub del cliente serializa los parámetros de la llamada y envía la solicitud al stub del servidor.\n",
    "3. Recepción y deserialización: El stub del servidor recibe la solicitud y deserializa los parámetros.\n",
    "4. Ejecución del Procedimiento: El procedimiento remoto se ejecuta en el servidor con los parámetros proporcionados.\n",
    "5. Serialización de la Respuesta: El resultado del procedimiento se serializa y se envía de vuelta al cliente.\n",
    "6. Recepción de la Respuesta: El stub del cliente recibe y deserializa la respuesta, y el resultado se devuelve al cliente.\n",
    "\n",
    "**Tipos de RPC**\n",
    "\n",
    "Síncrono\n",
    "\n",
    "En una llamada RPC síncrona, el cliente espera a que el servidor complete la ejecución del procedimiento y envíe la respuesta antes de continuar con su ejecución. Este modelo es simple de implementar y utilizar, pero puede introducir latencia y bloquear al cliente si el servidor tarda mucho en responder.\n",
    "\n",
    "Asíncrono\n",
    "\n",
    "En una llamada RPC asíncrona, el cliente no espera la respuesta del servidor de inmediato. En su lugar, puede continuar con otras tareas y manejar la respuesta cuando esté disponible. Este modelo mejora la eficiencia y la capacidad de respuesta del cliente, pero es más complejo de implementar debido a la necesidad de gestionar las respuestas de manera no bloqueante.\n",
    "\n",
    "**Manejo de errores y excepciones**\n",
    "\n",
    "El manejo de errores es crucial en RPC, dado que la comunicación en red puede fallar por diversas razones. Los errores pueden ocurrir en varias etapas del proceso RPC:\n",
    "\n",
    "- Errores de conexión: Pueden ocurrir al intentar conectar al servidor, como la falta de respuesta del servidor o problemas de red.\n",
    "- Errores de transmisión: Problemas durante el envío o recepción de datos, como paquetes perdidos o corrompidos.\n",
    "- Errores de ejecución: Errores que ocurren durante la ejecución del procedimiento remoto, como excepciones no controladas en el servidor.\n",
    "\n",
    "Para manejar estos errores, RPC generalmente implementa mecanismos de reintento, detección de fallos y recuperación, así como el uso de excepciones para notificar al cliente sobre problemas específicos.\n",
    "\n",
    "**Seguridad en RPC**\n",
    "\n",
    "La seguridad es un aspecto crítico en RPC, especialmente cuando se utilizan redes no seguras. Los principales aspectos de seguridad incluyen:\n",
    "\n",
    "- Autenticación: Verificación de la identidad del cliente y del servidor para asegurarse de que ambas partes son quienes dicen ser.\n",
    "- Autorización: Control de acceso para asegurar que el cliente tiene permiso para ejecutar el procedimiento solicitado.\n",
    "- Encriptación: Protección de los datos transmitidos para evitar que sean interceptados o modificados por terceros.\n",
    "- Integridad: Garantizar que los datos no han sido alterados durante la transmisión.\n",
    "\n",
    "**Implementaciones de RPC**\n",
    "\n",
    "XML-RPC\n",
    "\n",
    "[XML-RPC](https://es.wikipedia.org/wiki/XML-RPC) es un protocolo sencillo que utiliza XML para codificar las llamadas a procedimientos y HTTP como protocolo de transporte. Es fácil de implementar y ampliamente compatible, pero puede ser menos eficiente debido a la sobrecarga del XML.\n",
    "\n",
    "JSON-RPC\n",
    "\n",
    "[JSON-RPC](https://www.jsonrpc.org/) es similar a XML-RPC, pero utiliza JSON para la codificación de mensajes. Esto reduce la sobrecarga y mejora la eficiencia, especialmente para aplicaciones web.\n",
    "\n",
    "gRPC\n",
    "\n",
    "[gRPC](https://grpc.io/) es una implementación moderna de RPC desarrollada por Google. Utiliza Protocol Buffers (protobuf) para la serialización de datos y soporta múltiples lenguajes de programación. gRPC es altamente eficiente y soporta características avanzadas como autenticación, compresión, y streaming bidireccional.\n",
    "\n",
    "Apache Thrift\n",
    "\n",
    "[Apache Thrift](https://thrift.apache.org/) es una biblioteca y framework para RPC desarrollada por Facebook. Soporta múltiples lenguajes y utiliza un lenguaje de definición de interfaz (IDL) para definir los servicios y tipos de datos. Thrift facilita la interoperabilidad entre diferentes lenguajes y plataformas.\n",
    "\n",
    "**Casos de uso de RPC**\n",
    "\n",
    "Microservicios\n",
    "\n",
    "En una arquitectura de microservicios, los RPC son fundamentales para la comunicación entre servicios. Cada microservicio puede ser desarrollado y desplegado de manera independiente, y utilizan RPC para invocar servicios remotos y colaborar en la ejecución de tareas.\n",
    "\n",
    "Aplicaciones distribuidas\n",
    "\n",
    "RPC es ampliamente utilizado en aplicaciones distribuidas que requieren la ejecución de procedimientos en múltiples nodos. Esto incluye bases de datos distribuidas, sistemas de archivos distribuidos, y aplicaciones de procesamiento de datos en paralelo.\n",
    "\n",
    "Servicios web\n",
    "\n",
    "RPC es la base de muchos servicios web, permitiendo a los servidores web ejecutar procedimientos remotos en respuesta a las solicitudes de los clientes. Esto es común en APIs RESTful y SOAP.\n",
    "\n",
    "**Optimización y rendimiento**\n",
    "\n",
    "La eficiencia de las llamadas RPC es crítica para el rendimiento de las aplicaciones distribuidas. Algunas estrategias de optimización incluyen:\n",
    "\n",
    "* Compresión de datos: Reducir el tamaño de los mensajes transmitidos para disminuir la latencia y el ancho de banda necesario.\n",
    "* Batching de solicitudes: Agrupar múltiples solicitudes en un solo mensaje para reducir la sobrecarga de la comunicación.\n",
    "* Caching de resultados: Almacenar en caché los resultados de procedimientos comunes para evitar llamadas repetidas innecesarias.\n",
    "* Load balancing: Distribuir las solicitudes entre múltiples servidores para equilibrar la carga y mejorar la disponibilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343506b",
   "metadata": {},
   "source": [
    "### Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2ebf1",
   "metadata": {},
   "source": [
    "gRPC es una implementación moderna de RPC que utiliza Protocol Buffers (protobuf) para la serialización de datos. Este ejemplo muestra cómo implementar un servicio RPC que incluye autenticación y manejo de errores.\n",
    "\n",
    "**Definición del servicio con Protocol Buffers**\n",
    "\n",
    "Primero, definimos el servicio en un archivo .proto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax = \"proto3\";\n",
    "\n",
    "package example;\n",
    "\n",
    "service MathService {\n",
    "    rpc Add (AddRequest) returns (AddResponse);\n",
    "}\n",
    "\n",
    "message AddRequest {\n",
    "    double a = 1;\n",
    "    double b = 2;\n",
    "}\n",
    "\n",
    "message AddResponse {\n",
    "    double result = 1;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe87f9",
   "metadata": {},
   "source": [
    "Implementación del servidor en C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <grpc/grpc.h>\n",
    "#include <grpcpp/server.h>\n",
    "#include <grpcpp/server_builder.h>\n",
    "#include <grpcpp/server_context.h>\n",
    "#include \"example.grpc.pb.h\"\n",
    "\n",
    "class MathServiceImpl final : public example::MathService::Service {\n",
    "    grpc::Status Add(grpc::ServerContext* context, const example::AddRequest* request,\n",
    "                     example::AddResponse* response) override {\n",
    "        // Autenticación básica\n",
    "        auto auth_md = context->auth_context()->FindPropertyValues(\"authorization\");\n",
    "        if (auth_md.empty() || auth_md[0].data() != \"valid_token\") {\n",
    "            return grpc::Status(grpc::StatusCode::UNAUTHENTICATED, \"Invalid token\");\n",
    "        }\n",
    "\n",
    "        // Lógica del procedimiento remoto\n",
    "        double sum = request->a() + request->b();\n",
    "        response->set_result(sum);\n",
    "\n",
    "        return grpc::Status::OK;\n",
    "    }\n",
    "};\n",
    "\n",
    "void RunServer() {\n",
    "    std::string server_address(\"0.0.0.0:50051\");\n",
    "    MathServiceImpl service;\n",
    "\n",
    "    grpc::ServerBuilder builder;\n",
    "    builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());\n",
    "    builder.RegisterService(&service);\n",
    "    std::unique_ptr<grpc::Server> server(builder.BuildAndStart());\n",
    "    std::cout << \"Server listening on \" << server_address << std::endl;\n",
    "    server->Wait();\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    RunServer();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80eb15",
   "metadata": {},
   "source": [
    "Implementación del cliente en C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <grpcpp/grpcpp.h>\n",
    "#include \"example.grpc.pb.h\"\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    std::string target_str = \"localhost:50051\";\n",
    "    auto channel = grpc::CreateChannel(target_str, grpc::InsecureChannelCredentials());\n",
    "    std::unique_ptr<example::MathService::Stub> stub(example::MathService::NewStub(channel));\n",
    "\n",
    "    // Crear la solicitud\n",
    "    example::AddRequest request;\n",
    "    request.set_a(3.0);\n",
    "    request.set_b(4.0);\n",
    "\n",
    "    // Contexto para la llamada RPC\n",
    "    grpc::ClientContext context;\n",
    "\n",
    "    // Autenticación básica\n",
    "    context.AddMetadata(\"authorization\", \"valid_token\");\n",
    "\n",
    "    // Respuesta\n",
    "    example::AddResponse response;\n",
    "\n",
    "    // Realizar la llamada RPC\n",
    "    grpc::Status status = stub->Add(&context, request, &response);\n",
    "\n",
    "    if (status.ok()) {\n",
    "        std::cout << \"Resultado: \" << response.result() << std::endl;\n",
    "    } else {\n",
    "        std::cout << \"Error: \" << status.error_message() << std::endl;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e121ff",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Autenticación: El servidor verifica un token de autenticación en los metadatos de la solicitud. Si el token es inválido, devuelve un error de autenticación.\n",
    "* Manejo de errores: El cliente y el servidor manejan los errores adecuadamente, devolviendo mensajes de error específicos cuando ocurren problemas.\n",
    "* Optimización: Utiliza gRPC y Protocol Buffers para una comunicación eficiente y serialización de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d589b",
   "metadata": {},
   "source": [
    "Este ejemplo en Python implementa un servicio RPC con gRPC que incluye autenticación y manejo de errores.\n",
    "\n",
    "Definición del servicio con Protocol Buffers\n",
    "\n",
    "El archivo `.proto` es el mismo que en el ejemplo de C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170228e3",
   "metadata": {},
   "source": [
    "\n",
    "Implementación del servidor en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import grpc\n",
    "import example_pb2\n",
    "import example_pb2_grpc\n",
    "\n",
    "class MathService(example_pb2_grpc.MathServiceServicer):\n",
    "    def Add(self, request, context):\n",
    "        # Autenticación básica\n",
    "        metadata = dict(context.invocation_metadata())\n",
    "        if 'authorization' not in metadata or metadata['authorization'] != 'valid_token':\n",
    "            context.set_code(grpc.StatusCode.UNAUTHENTICATED)\n",
    "            context.set_details('Invalid token')\n",
    "            return example_pb2.AddResponse()\n",
    "\n",
    "        # Lógica del procedimiento remoto\n",
    "        result = request.a + request.b\n",
    "        return example_pb2.AddResponse(result=result)\n",
    "\n",
    "def serve():\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    example_pb2_grpc.add_MathServiceServicer_to_server(MathService(), server)\n",
    "    server.add_insecure_port('[::]:50051')\n",
    "    server.start()\n",
    "    server.wait_for_termination()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    serve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791fdcc",
   "metadata": {},
   "source": [
    "Implementación del cliente en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import example_pb2\n",
    "import example_pb2_grpc\n",
    "\n",
    "def run():\n",
    "    with grpc.insecure_channel('localhost:50051') as channel:\n",
    "        stub = example_pb2_grpc.MathServiceStub(channel)\n",
    "\n",
    "        # Crear la solicitud\n",
    "        request = example_pb2.AddRequest(a=3.0, b=4.0)\n",
    "\n",
    "        # Contexto para la llamada RPC\n",
    "        metadata = (('authorization', 'valid_token'),)\n",
    "\n",
    "        # Realizar la llamada RPC\n",
    "        try:\n",
    "            response = stub.Add(request, metadata=metadata)\n",
    "            print(\"Resultado: \", response.result)\n",
    "        except grpc.RpcError as e:\n",
    "            print(f\"Error: {e.code()} - {e.details()}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a61c0",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Autenticación: Igual que en el ejemplo en C, el servidor verifica un token de autenticación.\n",
    "* Manejo de errores: El servidor maneja los errores de autenticación y el cliente maneja las excepciones de RPC.\n",
    "* Optimización: gRPC y Protocol Buffers para comunicación eficiente y serialización de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7660de0",
   "metadata": {},
   "source": [
    "Este ejemplo muestra cómo implementar un servicio de streaming bidireccional utilizando gRPC en Python. En este caso, los clientes y el servidor pueden enviar y recibir múltiples mensajes a lo largo de una única conexión RPC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3772c1a",
   "metadata": {},
   "source": [
    "**Definición del servicio con Protocol Buffers**\n",
    "\n",
    "Primero, definimos el servicio en un archivo .proto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118453d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax = \"proto3\";\n",
    "\n",
    "package example;\n",
    "\n",
    "service ChatService {\n",
    "    rpc Chat (stream ChatMessage) returns (stream ChatMessage);\n",
    "}\n",
    "\n",
    "message ChatMessage {\n",
    "    string user = 1;\n",
    "    string message = 2;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2465442",
   "metadata": {},
   "source": [
    "**Implementación del servidor en Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43367c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import grpc\n",
    "import example_pb2\n",
    "import example_pb2_grpc\n",
    "\n",
    "class ChatService(example_pb2_grpc.ChatServiceServicer):\n",
    "    def Chat(self, request_iterator, context):\n",
    "        for chat_message in request_iterator:\n",
    "            response_message = example_pb2.ChatMessage(\n",
    "                user=\"Server\",\n",
    "                message=f\"Received from {chat_message.user}: {chat_message.message}\"\n",
    "            )\n",
    "            yield response_message\n",
    "\n",
    "def serve():\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    example_pb2_grpc.add_ChatServiceServicer_to_server(ChatService(), server)\n",
    "    server.add_insecure_port('[::]:50051')\n",
    "    server.start()\n",
    "    server.wait_for_termination()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    serve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb274b",
   "metadata": {},
   "source": [
    "**Implementación del cliente en Python**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import example_pb2\n",
    "import example_pb2_grpc\n",
    "\n",
    "def generate_messages():\n",
    "    messages = [\n",
    "        example_pb2.ChatMessage(user=\"Client1\", message=\"Hello!\"),\n",
    "        example_pb2.ChatMessage(user=\"Client1\", message=\"How are you?\"),\n",
    "        example_pb2.ChatMessage(user=\"Client1\", message=\"Goodbye!\")\n",
    "    ]\n",
    "    for msg in messages:\n",
    "        yield msg\n",
    "\n",
    "def run():\n",
    "    with grpc.insecure_channel('localhost:50051') as channel:\n",
    "        stub = example_pb2_grpc.ChatServiceStub(channel)\n",
    "        responses = stub.Chat(generate_messages())\n",
    "        for response in responses:\n",
    "            print(f\"Received: {response.user}: {response.message}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5dbdc",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Streaming bidireccional: Tanto el cliente como el servidor pueden enviar y recibir múltiples mensajes a lo largo de una única conexión.\n",
    "* Iteradores de solicitud y respuesta: Utiliza iteradores para manejar las secuencias de mensajes tanto en el cliente como en el servidor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8efcc",
   "metadata": {},
   "source": [
    "Este ejemplo muestra cómo implementar un servicio gRPC en Python con manejo avanzado de errores y lógica de reintentos.\n",
    "\n",
    "**Definición del servicio con Protocol Buffers**\n",
    "\n",
    "El archivo .proto es similar al anterior, pero con un método adicional que podría fallar intencionalmente para demostrar el manejo de errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax = \"proto3\";\n",
    "\n",
    "package example;\n",
    "\n",
    "service MathService {\n",
    "    rpc Add (AddRequest) returns (AddResponse);\n",
    "    rpc Divide (DivideRequest) returns (DivideResponse);\n",
    "}\n",
    "\n",
    "message AddRequest {\n",
    "    double a = 1;\n",
    "    double b = 2;\n",
    "}\n",
    "\n",
    "message AddResponse {\n",
    "    double result = 1;\n",
    "}\n",
    "\n",
    "message DivideRequest {\n",
    "    double numerator = 1;\n",
    "    double denominator = 2;\n",
    "}\n",
    "\n",
    "message DivideResponse {\n",
    "    double result = 1;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ff473",
   "metadata": {},
   "source": [
    "Implementación del servidor en Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import grpc\n",
    "import example_pb2\n",
    "import example_pb2_grpc\n",
    "\n",
    "class MathService(example_pb2_grpc.MathServiceServicer):\n",
    "    def Add(self, request, context):\n",
    "        result = request.a + request.b\n",
    "        return example_pb2.AddResponse(result=result)\n",
    "    \n",
    "    def Divide(self, request, context):\n",
    "        if request.denominator == 0:\n",
    "            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)\n",
    "            context.set_details('Denominator cannot be zero')\n",
    "            return example_pb2.DivideResponse()\n",
    "        result = request.numerator / request.denominator\n",
    "        return example_pb2.DivideResponse(result=result)\n",
    "\n",
    "def serve():\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    example_pb2_grpc.add_MathServiceServicer_to_server(MathService(), server)\n",
    "    server.add_insecure_port('[::]:50051')\n",
    "    server.start()\n",
    "    server.wait_for_termination()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    serve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a6980",
   "metadata": {},
   "source": [
    "Implementación del cliente en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80896909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import example_pb2\n",
    "import example_pb2_grpc\n",
    "\n",
    "def run():\n",
    "    with grpc.insecure_channel('localhost:50051') as channel:\n",
    "        stub = example_pb2_grpc.MathServiceStub(channel)\n",
    "        \n",
    "        # Prueba del método Add\n",
    "        add_request = example_pb2.AddRequest(a=3.0, b=4.0)\n",
    "        add_response = stub.Add(add_request)\n",
    "        print(f\"Add result: {add_response.result}\")\n",
    "        \n",
    "        # Prueba del método Divide con manejo de errores\n",
    "        divide_request = example_pb2.DivideRequest(numerator=10, denominator=0)\n",
    "        try:\n",
    "            divide_response = stub.Divide(divide_request)\n",
    "            print(f\"Divide result: {divide_response.result}\")\n",
    "        except grpc.RpcError as e:\n",
    "            print(f\"RPC failed: {e.code()} - {e.details()}\")\n",
    "        \n",
    "        # Lógica de reintento para el método Divide\n",
    "        divide_request = example_pb2.DivideRequest(numerator=10, denominator=2)\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                divide_response = stub.Divide(divide_request)\n",
    "                print(f\"Divide result: {divide_response.result}\")\n",
    "                break\n",
    "            except grpc.RpcError as e:\n",
    "                print(f\"Attempt {attempt+1} failed: {e.code()} - {e.details()}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(\"Max retries reached. Exiting.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f888413",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Manejo de errores: El servidor maneja errores específicos como división por cero, y el cliente captura y maneja estas excepciones adecuadamente.\n",
    "* Reintentos: El cliente implementa una lógica de reintento para manejar fallos transitorios en las llamadas RPC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fd0f10",
   "metadata": {},
   "source": [
    "### Remote Method Invocation (RMI)\n",
    "\n",
    "Remote Method Invocation (RMI) es una tecnología en la programación distribuida que permite la invocación de métodos en objetos localizados en diferentes máquinas dentro de una red. Este mecanismo permite que los objetos interactúen como si estuvieran en la misma máquina, facilitando la creación de aplicaciones distribuidas con un enfoque orientado a objetos.\n",
    "\n",
    "**Arquitectura de RMI**\n",
    "\n",
    "La arquitectura de RMI se compone de varios componentes clave que facilitan la comunicación entre los objetos distribuidos: el cliente, el servidor, el registro RMI, y los stubs y skeletons.\n",
    "\n",
    "Cliente\n",
    "\n",
    "El cliente es la entidad que invoca métodos en el objeto remoto. En RMI, el cliente interactúa con una representación local del objeto remoto conocido como stub. El stub actúa como un proxy, gestionando la comunicación con el objeto real que reside en el servidor.\n",
    "\n",
    "Servidor\n",
    "\n",
    "El servidor es la entidad que contiene el objeto remoto, conocido como el skeleton. El servidor expone los métodos del objeto remoto que pueden ser invocados por los clientes. Para que un objeto sea accesible remotamente, debe ser registrado en el registro RMI y debe implementar una interfaz remota.\n",
    "\n",
    "Registro RMI\n",
    "\n",
    "El registro RMI es un servicio que actúa como un directorio de objetos remotos. Los servidores registran sus objetos remotos en el registro RMI, permitiendo a los clientes buscar y obtener referencias a estos objetos. El registro RMI es esencial para la localización de los objetos remotos.\n",
    "\n",
    "Stubs y Skeletons\n",
    "\n",
    "* Stubs: Son representaciones locales del objeto remoto en el cliente. Los stubs contienen el código necesario para enviar las llamadas a métodos, junto con sus parámetros, al servidor y recibir las respuestas. Los stubs ocultan la complejidad de la comunicación de red al cliente.\n",
    "* Skeletons: Son representaciones locales del objeto remoto en el servidor. Los skeletons reciben las solicitudes de los stubs, deserializan los parámetros, invocan el método correspondiente en el objeto real y envían los resultados de vuelta al cliente. A partir de Java 2 SDK, la generación explícita de skeletons ya no es necesaria, pero el concepto sigue siendo relevante.\n",
    "\n",
    "**Proceso de comunicación en RMI**\n",
    "\n",
    "El proceso de comunicación en RMI puede desglosarse en los siguientes pasos:\n",
    "\n",
    "1. Registro del objeto remoto: El servidor crea una instancia del objeto remoto y lo registra en el registro RMI usando un nombre conocido.\n",
    "2. Búsqueda del objeto remoto: El cliente busca el objeto remoto en el registro RMI utilizando el nombre registrado.\n",
    "3. Invocación de métodos remotos: El cliente obtiene un stub del objeto remoto y llama a los métodos del objeto remoto a través de este stub.\n",
    "4. Comunicación de red: El stub serializa los parámetros y los envía al servidor. El skeleton deserializa los parámetros, invoca el método en el objeto remoto y envía el resultado de vuelta al stub.\n",
    "5. Recepción del resultado: El stub deserializa el resultado y lo devuelve al cliente.\n",
    "\n",
    "**Serialización y deserialización**\n",
    "\n",
    "En RMI, los parámetros y los resultados de las llamadas a métodos remotos deben ser serializados y deserializados para ser transmitidos a través de la red. La serialización convierte los objetos en un formato que puede ser enviado a través de la red, mientras que la deserialización reconstruye los objetos a partir de este formato en el destino.\n",
    "\n",
    "Tipos de datos soportados\n",
    "\n",
    "RMI soporta la serialización de varios tipos de datos, incluidos los tipos primitivos de Java, objetos que implementan la interfaz java.io.Serializable, y arreglos de estos tipos. Es importante asegurarse de que todos los objetos que se deseen transmitir a través de RMI sean serializables.\n",
    "\n",
    "Problemas de serialización\n",
    "\n",
    "* Compatibilidad de versiones: Los cambios en la estructura de los objetos pueden causar incompatibilidades en la serialización. Se recomienda utilizar el campo serialVersionUID para manejar versiones de clases.\n",
    "* Rendimiento: La serialización y deserialización pueden introducir sobrecarga en términos de tiempo de procesamiento y uso de memoria. Es importante optimizar los objetos serializables para minimizar esta sobrecarga.\n",
    "\n",
    "**Seguridad en RMI**\n",
    "\n",
    "La seguridad es un aspecto crítico en RMI, dado que implica la ejecución de código remoto. RMI implementa varios mecanismos de seguridad para proteger la comunicación y la integridad del sistema:\n",
    "\n",
    "Políticas de seguridad\n",
    "\n",
    "Las políticas de seguridad en RMI se gestionan utilizando un archivo de políticas que define los permisos necesarios para ejecutar ciertas operaciones. Este archivo especifica qué clases pueden acceder a qué recursos, como archivos y conexiones de red.\n",
    "\n",
    "Autenticación y autorización\n",
    "\n",
    "RMI puede integrar autenticación y autorización para asegurar que solo los usuarios y procesos autorizados puedan invocar métodos remotos. Esto se logra mediante la implementación de javax.security.auth y otros mecanismos de autenticación de Java.\n",
    "\n",
    "Encriptación\n",
    "\n",
    "Para proteger los datos transmitidos a través de la red, RMI puede utilizar SSL/TLS para encriptar la comunicación entre el cliente y el servidor. Esto asegura que los datos no puedan ser interceptados o alterados por terceros durante la transmisión.\n",
    "\n",
    "**Manejo de errores y excepciones**\n",
    "\n",
    "El manejo de errores y excepciones en RMI es crucial para desarrollar aplicaciones robustas y confiables. RMI define varias excepciones específicas que deben ser manejadas adecuadamente:\n",
    "\n",
    "RemoteException\n",
    "\n",
    "La RemoteException es la excepción base para todos los errores de RMI. Puede ocurrir por varias razones, como problemas de red, fallos en la serialización, o errores en la invocación de métodos remotos. Los desarrolladores deben capturar y manejar esta excepción para proporcionar retroalimentación útil al usuario y para implementar lógica de recuperación.\n",
    "\n",
    "Otros tipos de excepciones\n",
    "\n",
    "* NotBoundException: Se lanza cuando el cliente intenta buscar un objeto que no está registrado en el registro RMI.\n",
    "* AlreadyBoundException: Se lanza cuando el servidor intenta registrar un objeto con un nombre que ya está en uso.\n",
    "* AccessException: Se lanza cuando el cliente no tiene permisos suficientes para invocar un método remoto.\n",
    "\n",
    "**Optimización y rendimiento en RMI**\n",
    "\n",
    "La eficiencia de las invocaciones remotas es crítica para el rendimiento de las aplicaciones distribuidas. Algunas estrategias de optimización incluyen:\n",
    "\n",
    "Reducción de llamadas remotas\n",
    "\n",
    "Minimizar el número de llamadas remotas es fundamental para mejorar el rendimiento. Agrupar múltiples operaciones en una sola llamada remota puede reducir la latencia y el overhead de comunicación.\n",
    "\n",
    "Uso de caching\n",
    "\n",
    "Almacenar en caché los resultados de operaciones costosas puede evitar llamadas remotas innecesarias. El caching debe implementarse cuidadosamente para asegurar la coherencia de los datos.\n",
    "\n",
    "Compresión de datos\n",
    "\n",
    "La compresión de los datos antes de la transmisión puede reducir el tamaño de los mensajes y mejorar el tiempo de respuesta. Sin embargo, la compresión y descompresión añaden overhead de procesamiento, por lo que debe utilizarse con moderación.\n",
    "\n",
    "Afinidad de red\n",
    "\n",
    "Asignar clientes a servidores que estén geográficamente cerca puede reducir la latencia de red y mejorar el rendimiento. Esto se logra mediante técnicas de balanceo de carga y direccionamiento inteligente.\n",
    "\n",
    "**Casos de uso de RMI**\n",
    "\n",
    "Aplicaciones empresariales\n",
    "\n",
    "RMI es ampliamente utilizado en aplicaciones empresariales que requieren acceso distribuido a objetos y servicios. Permite a los sistemas distribuir la lógica de negocio y los datos en múltiples servidores, mejorando la escalabilidad y la disponibilidad.\n",
    "\n",
    "Sistemas de información distribuidos\n",
    "\n",
    "En sistemas de información distribuidos, RMI facilita la integración y la comunicación entre diferentes componentes del sistema, permitiendo la creación de aplicaciones complejas que pueden operar en múltiples ubicaciones.\n",
    "\n",
    "\n",
    "**Herramientas y bibliotecas complementarias**\n",
    "\n",
    "JNDI\n",
    "\n",
    "El Java Naming and Directory Interface ([JNDI](https://en.wikipedia.org/wiki/Java_Naming_and_Directory_Interface)) se utiliza a menudo junto con RMI para proporcionar servicios de directorio que permiten a las aplicaciones localizar y acceder a objetos distribuidos.\n",
    "\n",
    "RMI-IIOP\n",
    "\n",
    "[RMI-IIOP](https://es.wikipedia.org/wiki/RMI-IIOP) es una extensión de RMI que permite la interoperabilidad con CORBA (Common Object Request Broker Architecture). Esto facilita la comunicación entre aplicaciones Java y otras aplicaciones que utilizan CORBA.\n",
    "\n",
    "Frameworks de terceros\n",
    "\n",
    "Existen varios frameworks y bibliotecas de terceros que amplían las capacidades de RMI, proporcionando funcionalidades adicionales como balanceo de carga, tolerancia a fallos, y gestión de clústeres.\n",
    "\n",
    "\n",
    "Remote Method Invocation (RMI) en su forma clásica es una tecnología nativa de Java, y no se implementa directamente en C o Python. Sin embargo, en lenguajes como C y Python se pueden utilizar tecnologías similares para lograr la invocación remota de métodos en objetos distribuidos. En Python, esto se puede hacer utilizando Pyro (Python Remote Objects), mientras que en C se puede usar gRPC con una arquitectura de objetos distribuidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ede57",
   "metadata": {},
   "source": [
    "### Ejemplos\n",
    "\n",
    "Pyro es una biblioteca en Python que permite la invocación remota de métodos en objetos distribuidos. A continuación, se presenta un ejemplo avanzado utilizando Pyro con autenticación y manejo de errores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb2540",
   "metadata": {},
   "source": [
    "Definición del objeto remoto en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69535c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyro5.api\n",
    "\n",
    "@Pyro5.api.expose\n",
    "class Calculator(object):\n",
    "    def add(self, a, b):\n",
    "        return a + b\n",
    "\n",
    "    def divide(self, numerator, denominator):\n",
    "        if denominator == 0:\n",
    "            raise ValueError(\"Denominator cannot be zero\")\n",
    "        return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4703d7",
   "metadata": {},
   "source": [
    "Implementación del servidor en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyro5.api\n",
    "\n",
    "def main():\n",
    "    daemon = Pyro5.api.Daemon()\n",
    "    uri = daemon.register(Calculator, \"calculator\")\n",
    "    print(\"Ready. Object uri =\", uri)\n",
    "    daemon.requestLoop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbace2fa",
   "metadata": {},
   "source": [
    "Implementación del cliente en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e529167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyro5.api\n",
    "\n",
    "def main():\n",
    "    uri = \"PYRONAME:calculator\"\n",
    "    calculator = Pyro5.api.Proxy(uri)\n",
    "    \n",
    "    # Prueba del método add\n",
    "    try:\n",
    "        result = calculator.add(3, 4)\n",
    "        print(f\"Add result: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    # Prueba del método divide con manejo de errores\n",
    "    try:\n",
    "        result = calculator.divide(10, 0)\n",
    "        print(f\"Divide result: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e145e",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Autenticación y manejo de errores: Pyro permite manejar excepciones y errores en métodos remotos. En este caso, se lanza una excepción cuando el denominador es cero.\n",
    "* Optimización: Pyro facilita la creación de objetos distribuidos y la invocación remota de métodos de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f1beb",
   "metadata": {},
   "source": [
    "Este ejemplo muestra cómo agregar autenticación a un servicio Pyro para asegurar que solo los clientes autorizados puedan invocar métodos remotos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee54220",
   "metadata": {},
   "source": [
    "Definición del objeto remoto con autenticación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bb57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyro5.api\n",
    "\n",
    "@Pyro5.api.expose\n",
    "class SecureCalculator(object):\n",
    "    def __init__(self, password):\n",
    "        self.password = password\n",
    "\n",
    "    def authenticate(self, password):\n",
    "        if password != self.password:\n",
    "            raise ValueError(\"Invalid password\")\n",
    "\n",
    "    def add(self, a, b):\n",
    "        return a + b\n",
    "\n",
    "    def divide(self, numerator, denominator):\n",
    "        if denominator == 0:\n",
    "            raise ValueError(\"Denominator cannot be zero\")\n",
    "        return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fcd47",
   "metadata": {},
   "source": [
    "Implementación del servidor con autenticación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyro5.api\n",
    "\n",
    "def main():\n",
    "    daemon = Pyro5.api.Daemon()\n",
    "    calculator = SecureCalculator(password=\"secret\")\n",
    "    uri = daemon.register(calculator, \"secure_calculator\")\n",
    "    print(\"Ready. Object uri =\", uri)\n",
    "    daemon.requestLoop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53efa0",
   "metadata": {},
   "source": [
    "Implementación del cliente con autenticación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyro5.api\n",
    "\n",
    "def main():\n",
    "    uri = \"PYRONAME:secure_calculator\"\n",
    "    calculator = Pyro5.api.Proxy(uri)\n",
    "    \n",
    "    try:\n",
    "        # Autenticación\n",
    "        calculator.authenticate(\"secret\")\n",
    "        \n",
    "        # Prueba del método add\n",
    "        result = calculator.add(3, 4)\n",
    "        print(f\"Add result: {result}\")\n",
    "        \n",
    "        # Prueba del método divide con manejo de errores\n",
    "        result = calculator.divide(10, 2)\n",
    "        print(f\"Divide result: {result}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951534cf",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Autenticación: Se implementa un método de autenticación en el servidor que los clientes deben invocar antes de llamar a otros métodos.\n",
    "* Manejo de errores: El servidor lanza excepciones si la autenticación falla o si se intenta una operación inválida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4698bc4",
   "metadata": {},
   "source": [
    "### Actor Model\n",
    "\n",
    "El Actor Model es un modelo de concurrencia en la computación que utiliza actores como unidades fundamentales de computación que se comunican a través de mensajes asíncronos. Este modelo es ampliamente utilizado en sistemas distribuidos y concurrentes debido a su capacidad para simplificar el manejo de la concurrencia y la paralelización.\n",
    "\n",
    "**Conceptos fundamentales**\n",
    "\n",
    "Actores\n",
    "\n",
    "Los actores son las unidades básicas de computación en el Actor Model. Cada actor es una entidad independiente que puede realizar tres acciones fundamentales:\n",
    "\n",
    "- Recibir mensajes: Los actores pueden recibir mensajes de otros actores. Los mensajes son entregados de manera asíncrona, lo que significa que el remitente no necesita esperar una respuesta inmediata.\n",
    "- Procesar mensajes: Al recibir un mensaje, un actor puede ejecutar algún comportamiento definido para manejar ese mensaje.\n",
    "- Enviar mensajes: Los actores pueden enviar mensajes a otros actores. Esto puede incluir responder al remitente del mensaje original o comunicarse con otros actores.\n",
    "\n",
    "Además de estas acciones, los actores también pueden:\n",
    "\n",
    "* Crear nuevos actores: Los actores pueden crear otros actores, permitiendo la creación dinámica de estructuras de computación.\n",
    "* Cambiar tu estado interno: Los actores pueden mantener y modificar un estado interno en respuesta a los mensajes recibidos.\n",
    "\n",
    "Mensajes\n",
    "\n",
    "Los mensajes son la única forma de comunicación entre actores. Son entregados de manera asíncrona, lo que significa que no hay garantías de cuándo serán recibidos por el actor destinatario. Los mensajes en el Actor Model son inmutables, lo que significa que no pueden ser modificados después de ser enviados.\n",
    "\n",
    "Caja de correo (Mailbox)\n",
    "\n",
    "Cada actor tiene una caja de correo (mailbox) donde se almacenan los mensajes entrantes. Los mensajes son procesados en el orden en que llegan, aunque la implementación específica del modelo puede variar. La caja de correo actúa como un buffer, permitiendo que los actores procesen mensajes a su propio ritmo.\n",
    "\n",
    "Comportamiento\n",
    "\n",
    "El comportamiento de un actor define cómo responde a los mensajes que recibe. Esto incluye qué acciones tomar, cómo modificar su estado interno, y qué mensajes enviar en respuesta. El comportamiento puede cambiar dinámicamente en función del estado interno del actor y los mensajes recibidos.\n",
    "\n",
    "**Ventajas técnicas del Actor Model**\n",
    "\n",
    "Desacoplamiento\n",
    "\n",
    "El Actor Model promueve el desacoplamiento entre componentes de un sistema. Los actores no comparten estado entre sí y se comunican exclusivamente a través de mensajes. Esto reduce las dependencias entre componentes y facilita la escalabilidad y mantenibilidad del sistema.\n",
    "\n",
    "Concurrencia y Paralelización\n",
    "\n",
    "Los actores operan de manera concurrente e independiente. Esto permite que múltiples actores ejecuten en paralelo, aprovechando al máximo los recursos de hardware disponibles, como los núcleos de CPU en sistemas multicore y las máquinas en un clúster distribuido.\n",
    "\n",
    "Aislamiento\n",
    "\n",
    "Cada actor tiene su propio estado interno y no comparte estado con otros actores. Esto evita problemas comunes en la concurrencia, como las condiciones de carrera y la necesidad de mecanismos de sincronización complejos.\n",
    "\n",
    "Escalabilidad\n",
    "\n",
    "El Actor Model es intrínsecamente escalable. Los actores pueden ser distribuidos en múltiples nodos en un clúster, y la comunicación asíncrona a través de mensajes facilita la tolerancia a fallos y la redistribución de carga.\n",
    "\n",
    "Tolerancia a Fallos\n",
    "\n",
    "Los sistemas basados en el Actor Model pueden implementar estrategias de tolerancia a fallos mediante la supervisión de actores. Un actor supervisor puede monitorear otros actores y tomar acciones correctivas, como reiniciar actores fallidos, sin afectar el funcionamiento del sistema en su conjunto.\n",
    "\n",
    "**Implementación del Actor Model**\n",
    "\n",
    "Frameworks y bibliotecas\n",
    "\n",
    "Existen varios frameworks y bibliotecas que implementan el Actor Model en diferentes lenguajes de programación. Algunos de los más populares incluyen:\n",
    "\n",
    "* [Akka](https://akka.io/): Un toolkit y runtime para construir aplicaciones concurrentes y distribuidas en la JVM (Java Virtual Machine). Akka es especialmente popular en el ecosistema de Scala y Java.\n",
    "* [Erlang/OTP](https://www.erlang.org/): Un lenguaje de programación y plataforma diseñada para sistemas concurrentes y distribuidos. Erlang utiliza el Actor Model como base para su modelo de concurrencia.\n",
    "* [Microsoft Orleans](https://learn.microsoft.com/es-es/dotnet/orleans/): Un framework para construir aplicaciones distribuidas y escalables en .NET, que implementa el Actor Model con mejoras para la escalabilidad y la simplicidad.\n",
    "* [Ray](https://www.ray.io/): Un framework en Python para aplicaciones distribuidas, que también implementa el Actor Model para manejar la concurrencia y la paralelización.\n",
    "\n",
    "**Arquitectura y componentes clave**\n",
    "\n",
    "La arquitectura de un sistema basado en el Actor Model típicamente incluye los siguientes componentes clave:\n",
    "\n",
    "* Sistema de actores: El contenedor principal que administra la creación, ejecución y supervisión de los actores.\n",
    "* Actores: Las unidades de computación que reciben, procesan y envían mensajes.\n",
    "* Cajas de Correo (Mailboxes): Las estructuras de datos donde se almacenan los mensajes entrantes para cada actor.\n",
    "* Supervisores: Actores especiales que monitorean otros actores y manejan errores y fallos.\n",
    "* Enrutadores (Routers): Componentes que distribuyen mensajes a múltiples actores según reglas definidas, permitiendo balancear la carga y distribuir el trabajo.\n",
    "\n",
    "**Ciclo de vida de los actores**\n",
    "\n",
    "El ciclo de vida de un actor en el Actor Model incluye las siguientes etapas:\n",
    "\n",
    "1. Creación: Un actor es creado por otro actor o por el sistema de actores. Durante la creación, se puede inicializar el estado del actor.\n",
    "2. Ejecución: El actor recibe y procesa mensajes. Esta es la fase principal donde el actor realiza su trabajo.\n",
    "3. Reinicio/Recuperación: Si un actor encuentra un error, puede ser reiniciado por su supervisor. Esto incluye la re-inicialización de su estado.\n",
    "4. Finalización: Un actor puede ser detenido, ya sea por su propia decisión o por el sistema de actores. En esta fase, se pueden realizar tareas de limpieza y liberar recursos.\n",
    "\n",
    "**Manejo de estados y comportamientos**\n",
    "\n",
    "El manejo de estados y comportamientos en el Actor Model es fundamental para su operación efectiva. Los actores pueden cambiar su estado interno en respuesta a los mensajes recibidos. Además, pueden cambiar su comportamiento, lo que implica alterar la lógica con la que procesan los mensajes.\n",
    "\n",
    "Estado interno\n",
    "\n",
    "El estado interno de un actor puede ser cualquier estructura de datos que mantenga la información necesaria para el procesamiento de mensajes. Este estado es aislado y no se comparte con otros actores, lo que elimina la necesidad de mecanismos de sincronización.\n",
    "\n",
    "Comportamientos dinámicos\n",
    "\n",
    "Los actores pueden cambiar dinámicamente su comportamiento mediante la definición de nuevos comportamientos y la adopción de estos en respuesta a ciertos mensajes. Esto permite que los actores reaccionen de manera flexible a diferentes condiciones y eventos durante su ciclo de vida.\n",
    "\n",
    "**Patrones de diseño en el Actor Model**\n",
    "\n",
    "Supervisión y tolerancia a fallos\n",
    "\n",
    "El patrón de supervisión es fundamental en el Actor Model para manejar la tolerancia a fallos. Los supervisores son actores responsables de monitorear otros actores (llamados hijos). Si un actor hijo falla, el supervisor puede decidir cómo manejar el fallo, ya sea reiniciando el actor, deteniéndolo, o escalando el fallo a un supervisor superior.\n",
    "\n",
    "Enrutamiento y balanceo de carga\n",
    "\n",
    "El patrón de enrutamiento permite distribuir mensajes entre un conjunto de actores según ciertas reglas. Esto es útil para balancear la carga y mejorar la eficiencia. Los enrutadores pueden distribuir mensajes de manera aleatoria, basada en el contenido del mensaje, o utilizando otras estrategias de enrutamiento definidas.\n",
    "\n",
    "Agregación de resultados\n",
    "\n",
    "En sistemas distribuidos, es común que múltiples actores realicen tareas en paralelo y luego agreguen sus resultados. El patrón de agregación de resultados involucra un actor coordinador que recopila resultados parciales de otros actores y los combina para producir un resultado final.\n",
    "\n",
    "Patrones de comunicación\n",
    "\n",
    "Existen varios patrones de comunicación utilizados en el Actor Model:\n",
    "\n",
    "* Solicitar-responder (Request-Response): Un patrón donde un actor envía una solicitud y espera una respuesta.\n",
    "* Mensajería de fuego y olvido (Fire-and-Forget): Un patrón donde un actor envía un mensaje sin esperar una respuesta.\n",
    "* Difusión (Broadcast): Un patrón donde un actor envía un mensaje a múltiples destinatarios.\n",
    "* Patrón de Pipeline: Un patrón donde los mensajes fluyen a través de una serie de actores, cada uno realizando una etapa del procesamiento.\n",
    "\n",
    "**Implementaciones y herramientas**\n",
    "\n",
    "Akka\n",
    "\n",
    "Akka es un toolkit y runtime basado en el Actor Model para construir aplicaciones concurrentes, distribuidas y resilientes. Akka proporciona una API robusta para manejar actores, supervisores, enrutadores y muchas otras funcionalidades avanzadas.\n",
    "\n",
    "Erlang/OTP\n",
    "\n",
    "Erlang es un lenguaje de programación diseñado para sistemas concurrentes y distribuidos, utilizando el Actor Model como su fundamento. OTP (Open Telecom Platform) es un conjunto de bibliotecas y herramientas para desarrollar aplicaciones Erlang robustas y escalables.\n",
    "\n",
    "Microsoft Orleans\n",
    "\n",
    "Orleans es un framework para construir aplicaciones distribuidas en .NET. Implementa el Actor Model con mejoras para la escalabilidad y simplicidad, permitiendo a los desarrolladores enfocarse en la lógica de negocio sin preocuparse por los detalles de la concurrencia y la distribución.\n",
    "\n",
    "Ray\n",
    "\n",
    "Ray es un framework en Python para aplicaciones distribuidas y de inteligencia artificial. Implementa el Actor Model para manejar la concurrencia y la paralelización, facilitando el desarrollo de aplicaciones distribuidas de alto rendimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf8624",
   "metadata": {},
   "source": [
    "### Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d86929",
   "metadata": {},
   "source": [
    "Aunque no hay una biblioteca estándar de Actor Model en C, podemos utilizar [libactor](https://www.google.com/search?client=ubuntu-sn&channel=fs&q=libactor), una biblioteca ligera para implementar el Actor Model. Aquí se muestra un ejemplo avanzado utilizando libactor para ilustrar la supervisión y la agregación de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebae92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <actor/actor.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "typedef struct {\n",
    "    int a;\n",
    "    int b;\n",
    "} AddMessage;\n",
    "\n",
    "void adder_behavior(actor_t *self, void *message) {\n",
    "    AddMessage *msg = (AddMessage *)message;\n",
    "    int result = msg->a + msg->b;\n",
    "    printf(\"Adder Actor: %d + %d = %d\\n\", msg->a, msg->b, result);\n",
    "}\n",
    "\n",
    "void supervisor_behavior(actor_t *self, void *message) {\n",
    "    printf(\"Supervisor Actor: Creating child actors\\n\");\n",
    "    actor_t *child1 = actor_create(adder_behavior);\n",
    "    actor_t *child2 = actor_create(adder_behavior);\n",
    "\n",
    "    AddMessage msg1 = {1, 2};\n",
    "    AddMessage msg2 = {3, 4};\n",
    "\n",
    "    actor_send(child1, &msg1);\n",
    "    actor_send(child2, &msg2);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    actor_system_t *actor_system = actor_system_create();\n",
    "\n",
    "    actor_t *supervisor = actor_create(supervisor_behavior);\n",
    "    actor_system_add_actor(actor_system, supervisor);\n",
    "\n",
    "    actor_system_run(actor_system);\n",
    "    actor_system_destroy(actor_system);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb8835",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Supervisión: El actor supervisor crea dos actores hijos y les envía mensajes para realizar una suma.\n",
    "* Agregación de resultados: Aunque en este ejemplo no se muestra la agregación explícita de resultados, se ilustra la creación y coordinación de múltiples actores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48787a",
   "metadata": {},
   "source": [
    "En Python, usaremos [pykka](https://pypi.org/project/pykka/1.2.1/), una biblioteca que implementa el Actor Model. Aquí mostramos un ejemplo avanzado utilizando pykka para ilustrar la supervisión, el balanceo de carga y la agregación de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykka\n",
    "import time\n",
    "\n",
    "class AdderActor(pykka.ThreadingActor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []\n",
    "\n",
    "    def on_receive(self, message):\n",
    "        if message.get('command') == 'add':\n",
    "            a = message.get('a')\n",
    "            b = message.get('b')\n",
    "            result = a + b\n",
    "            self.results.append(result)\n",
    "            print(f\"Adder Actor: {a} + {b} = {result}\")\n",
    "            return result\n",
    "        elif message.get('command') == 'get_results':\n",
    "            return self.results\n",
    "\n",
    "class SupervisorActor(pykka.ThreadingActor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.children = []\n",
    "\n",
    "    def on_start(self):\n",
    "        print(\"Supervisor Actor: Creating child actors\")\n",
    "        self.children.append(AdderActor.start().proxy())\n",
    "        self.children.append(AdderActor.start().proxy())\n",
    "\n",
    "    def on_receive(self, message):\n",
    "        if message.get('command') == 'add':\n",
    "            futures = [child.tell({'command': 'add', 'a': message.get('a'), 'b': message.get('b')}) for child in self.children]\n",
    "            return futures\n",
    "\n",
    "    def on_stop(self):\n",
    "        for child in self.children:\n",
    "            child.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    supervisor = SupervisorActor.start().proxy()\n",
    "    \n",
    "    # Enviar tareas a los actores hijos\n",
    "    futures = supervisor.tell({'command': 'add', 'a': 1, 'b': 2})\n",
    "    futures = supervisor.tell({'command': 'add', 'a': 3, 'b': 4})\n",
    "\n",
    "    time.sleep(1)  # Esperar a que los actores terminen de procesar\n",
    "\n",
    "    # Obtener resultados\n",
    "    results = [future.get() for future in futures]\n",
    "    print(f\"Results: {results}\")\n",
    "\n",
    "    pykka.ActorRegistry.stop_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9613ddd",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Supervisión: El supervisorActor crea dos AdderActor al iniciarse y les envía mensajes para realizar operaciones de suma.\n",
    "* Balanceo de carga: El supervisor distribuye las tareas de suma entre los actores hijos.\n",
    "* Agregación de resultados: Los resultados de las operaciones de suma se recopilan y se pueden procesar más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce10bcda",
   "metadata": {},
   "source": [
    "Ejemplo con enrutadores para balanceo de carga en Pykka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykka\n",
    "import random\n",
    "import time\n",
    "\n",
    "class WorkerActor(pykka.ThreadingActor):\n",
    "    def on_receive(self, message):\n",
    "        if message.get('command') == 'process':\n",
    "            data = message.get('data')\n",
    "            result = data * 2\n",
    "            print(f\"Worker Actor {self.actor_urn[-4:]}: Processing {data} -> {result}\")\n",
    "            return result\n",
    "\n",
    "class RouterActor(pykka.ThreadingActor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.workers = [WorkerActor.start().proxy() for _ in range(3)]\n",
    "\n",
    "    def on_receive(self, message):\n",
    "        if message.get('command') == 'route':\n",
    "            worker = random.choice(self.workers)\n",
    "            future = worker.ask({'command': 'process', 'data': message.get('data')}, timeout=2)\n",
    "            return future\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    router = RouterActor.start().proxy()\n",
    "\n",
    "    # Enviar tareas al enrutador\n",
    "    for i in range(5):\n",
    "        future = router.ask({'command': 'route', 'data': i}, timeout=5)\n",
    "        result = future.get()\n",
    "        print(f\"Main: Received result {result}\")\n",
    "\n",
    "    pykka.ActorRegistry.stop_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f32c13",
   "metadata": {},
   "source": [
    "Explicación\n",
    "\n",
    "* Enrutamiento: El RouterActor distribuye tareas entre un conjunto de WorkerActor de manera aleatoria.\n",
    "* Balanceo de carga: Distribuir las tareas ayuda a balancear la carga entre múltiples actores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925111ce",
   "metadata": {},
   "source": [
    "Ejemplo con patrón de Pipeline en Pykka.\n",
    "\n",
    "Definición de actores para un pipeline de procesamiento de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48be381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykka\n",
    "import time\n",
    "\n",
    "class ProducerActor(pykka.ThreadingActor):\n",
    "    def on_receive(self, message):\n",
    "        if message.get('command') == 'produce':\n",
    "            for i in range(message.get('count')):\n",
    "                time.sleep(1)  # Simula la producción de datos\n",
    "                print(f\"Producer Actor: Producing {i}\")\n",
    "                self.actor_ref.tell({'command': 'process', 'data': i})\n",
    "\n",
    "class ProcessorActor(pykka.ThreadingActor):\n",
    "    def on_receive(self, message):\n",
    "        if message.get('command') == 'process':\n",
    "            data = message.get('data')\n",
    "            processed_data = data * 2\n",
    "            print(f\"Processor Actor: Processing {data} -> {processed_data}\")\n",
    "            self.actor_ref.tell({'command': 'consume', 'data': processed_data})\n",
    "\n",
    "class ConsumerActor(pykka.ThreadingActor):\n",
    "    def on_receive(self, message):\n",
    "        if message.get('command') == 'consume':\n",
    "            data = message.get('data')\n",
    "            print(f\"Consumer Actor: Consuming {data}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    consumer = ConsumerActor.start().proxy()\n",
    "    processor = ProcessorActor.start().proxy()\n",
    "    producer = ProducerActor.start().proxy()\n",
    "\n",
    "    producer.tell({'command': 'produce', 'count': 5})\n",
    "\n",
    "    time.sleep(6)  # Esperar a que los actores terminen de procesar\n",
    "\n",
    "    pykka.ActorRegistry.stop_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733eb3a8",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "**Ejercicio 1:** Simulación de un sistema de dinámica de fluidos usando MPI\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar una aplicación distribuida que simule la dinámica de fluidos utilizando el método de los volúmenes finitos. Los nodos deben comunicarse utilizando MPI para actualizar las fronteras de sus subdominios.\n",
    "\n",
    "Descripción del ejercicio:\n",
    "\n",
    "1. Divide el dominio del fluido en una malla 2D rectangular distribuida entre varios nodos.\n",
    "2. Cada nodo es responsable de calcular la evolución del fluido en su subdominio utilizando el método de los volúmenes finitos.\n",
    "3. Implementa la comunicación entre nodos para actualizar las celdas en las fronteras de los subdominios. Use MPI_Send y MPI_Recv para transferir datos de frontera.\n",
    "4. Integra comunicaciones no bloqueantes (MPI_Isend y MPI_Irecv) para mejorar la eficiencia de la simulación.\n",
    "5. Realiza un análisis de rendimiento comparando tiempos de ejecución con diferentes números de nodos y tamaños de subdominios.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Inicialización del dominio y partición del subdominio entre nodos.\n",
    "* Implementación del método de los volúmenes finitos para la evolución del fluido.\n",
    "* Comunicación eficiente entre nodos para la actualización de fronteras.\n",
    "* Uso de técnicas de optimización para reducir el overhead de comunicación.\n",
    "* Análisis y visualización de los resultados de la simulación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c165e93",
   "metadata": {},
   "source": [
    "**Ejercicio 2:**  Implementación de un Servicio distribuido de análisis de datos\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar un servicio distribuido que permita la ejecución remota de procedimientos para el análisis de grandes conjuntos de datos utilizando RPC.\n",
    "\n",
    "Descripción del ejercicio:\n",
    "\n",
    "1. Diseña un servicio de análisis de datos que exponga varios procedimientos remotos como operaciones de agregación, filtrado y transformación de datos.\n",
    "2. Implementa la comunicación RPC entre el cliente y el servidor, asegurando la serialización y deserialización correcta de los datos.\n",
    "3. Implementa mecanismos de autenticación para asegurar que solo clientes autorizados puedan invocar procedimientos remotos.\n",
    "4. Incluye manejo de errores robusto para gestionar fallos de red y errores durante la ejecución de los procedimientos remotos.\n",
    "5. Optimiza la transmisión de datos mediante compresión y técnicas de batching para reducir la latencia de comunicación.\n",
    "6. Realiza pruebas de rendimiento y escalabilidad con diferentes volúmenes de datos y número de clientes concurrentes.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Diseño y exposición de la API de procedimientos remotos.\n",
    "* Implementación de la lógica de negocio para operaciones de análisis de datos.\n",
    "* Configuración de seguridad y autenticación en el servicio RPC.\n",
    "* Estrategias de manejo de errores y reintentos.\n",
    "* Técnicas de optimización de comunicación y pruebas de escalabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415bb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e48d3d",
   "metadata": {},
   "source": [
    "**Ejercicio 3:** Sistema de gestión de biblioteca distribuido con RMI\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar un sistema distribuido de gestión de biblioteca que permita la invocación remota de métodos para realizar operaciones de préstamo y devolución de libros.\n",
    "\n",
    "Descripción del ejercicio:\n",
    "\n",
    "1. Diseña una interfaz remota que defina los métodos para buscar libros, realizar préstamos, devolver libros y consultar el estado de los préstamos.\n",
    "2. Implementa los métodos remotos en el servidor RMI, asegurando la persistencia de los datos de la biblioteca.\n",
    "3. Registra los objetos remotos en el registro RMI para permitir a los clientes localizar y acceder a ellos.\n",
    "4. Implementa un cliente que pueda invocar métodos remotos para realizar operaciones de gestión de la biblioteca.\n",
    "5. Asegura el sistema implementando autenticación y autorización para verificar que solo usuarios autorizados pueden realizar ciertas operaciones.\n",
    "6. Implementa  manejo de errores para gestionar situaciones como libros no disponibles, errores de red y problemas de concurrencia.\n",
    "7. Realiza pruebas de rendimiento y escalabilidad con múltiples clientes concurrentes.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Diseño de la interfaz remota y métodos de gestión de biblioteca.\n",
    "* Implementación de la lógica de negocio en el servidor RMI.\n",
    "* Registro y localización de objetos remotos.\n",
    "* Seguridad mediante autenticación y autorización.\n",
    "* Estrategias de manejo de errores y concurrencia.\n",
    "* Pruebas de rendimiento y análisis de escalabilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10432eb2",
   "metadata": {},
   "source": [
    "**Ejercicio 4:** Sistema de procesamiento de órdenes de compra basado en Actores\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar un sistema distribuido de procesamiento de órdenes de compra utilizando el Actor Model para manejar la concurrencia y la distribución de tareas.\n",
    "\n",
    "Descripción del ejercicio:\n",
    "\n",
    "1. Implementa un actor para manejar las órdenes de compra, que reciba las órdenes, las procese y envíe confirmaciones.\n",
    "2. Crea actores adicionales para realizar tareas específicas como validación de pagos, actualización de inventarios y envío de notificaciones.\n",
    "3. Diseña un actor supervisor que maneje la creación y monitoreo de actores, implementando estrategias de reinicio en caso de fallos.\n",
    "4. Implementa un enrutador de mensajes para distribuir las órdenes de compra entre múltiples actores de procesamiento, asegurando el balanceo de carga.\n",
    "5. Integra un mecanismo de agregación de resultados donde los actores recopilen y combinen resultados parciales antes de enviarlos al cliente.\n",
    "6. Asegura la comunicación entre actores mediante autenticación y encriptación de mensajes.\n",
    "7. Realiza pruebas de rendimiento y escalabilidad con diferentes volúmenes de órdenes y número de actores concurrentes.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Diseño e implementación de actores para manejar diferentes etapas del procesamiento de órdenes.\n",
    "* Estrategias de supervisión y tolerancia a fallos.\n",
    "* Enrutamiento de mensajes y balanceo de carga entre actores.\n",
    "* Agregación de resultados y comunicación segura.\n",
    "* Pruebas de rendimiento y escalabilidad del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb766f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f047",
   "metadata": {},
   "source": [
    "**Ejercicio 5:** Análisis de Big Data usando MPI\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar una aplicación distribuida que realice el análisis de un conjunto de datos masivo utilizando operaciones de reducción y difusión con MPI.\n",
    "\n",
    "Descripción del Ejercicio:\n",
    "\n",
    "1. Divide un conjunto de datos masivo en fragmentos y distribuya estos fragmentos entre varios nodos.\n",
    "2. Cada nodo debe realizar operaciones locales de filtrado y transformación en su fragmento de datos.\n",
    "3. Implementa una operación de reducción (MPI_Reduce) para calcular estadísticas globales como la suma, el promedio y la desviación estándar de los datos.\n",
    "4. Utiliza MPI_Bcast para distribuir los resultados globales a todos los nodos.\n",
    "5. Implementa técnicas de comunicación no bloqueante (MPI_Isend y MPI_Irecv) para optimizar el intercambio de datos entre nodos.\n",
    "6. Analiza el rendimiento de la aplicación con diferentes tamaños de datos y números de nodos, y proponga mejoras.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Dividir y distribuir conjuntos de datos masivos.\n",
    "* Filtrado y transformación de datos en paralelo.\n",
    "* Operaciones de reducción y difusión.\n",
    "* Comunicación no bloqueante y optimización.\n",
    "* Análisis de rendimiento y propuestas de mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b98534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e41d4",
   "metadata": {},
   "source": [
    "**Ejercicio 6:** Sistema distribuido de predicción de series temporales\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar un sistema distribuido que prediga series temporales utilizando modelos de aprendizaje automático, con métodos invocados remotamente mediante RMI.\n",
    "\n",
    "Descripción del ejercicio:\n",
    "\n",
    "1. Diseña una interfaz remota que permita la carga de datos, el entrenamiento de modelos, y la predicción de nuevas observaciones.\n",
    "2. Implementa los métodos remotos en el servidor RMI, asegurando la persistencia de los modelos entrenados.\n",
    "3. Utiliza bibliotecas de aprendizaje automático para entrenar modelos de predicción de series temporales en el servidor.\n",
    "4. Implementa mecanismos de autenticación y autorización para proteger los métodos remotos.\n",
    "5. Maneja errores y excepciones para asegurar la robustez del sistema.\n",
    "6. Realiza pruebas con diferentes conjuntos de datos y modelos para evaluar la precisión y el rendimiento del sistema.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Diseño de la interfaz remota para predicción de series temporales.\n",
    "* Implementación de modelos de aprendizaje automático.\n",
    "* Persistencia de modelos entrenados.\n",
    "* Seguridad mediante autenticación y autorización.\n",
    "* Manejo de errores y excepciones.\n",
    "* Evaluación de precisión y rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a605d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1563726",
   "metadata": {},
   "source": [
    "**Ejercicio 7:** Sistema de gestión de eventos en tiempo real basado en Actores\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar un sistema de gestión de eventos en tiempo real utilizando el Actor Model para manejar la concurrencia y la comunicación asíncrona.\n",
    "\n",
    "Descripción del ejercicio:\n",
    "\n",
    "1. Implementa actores que representen diferentes tipos de eventos (por ejemplo, eventos de usuario, eventos del sistema).\n",
    "2. Desarrolla un actor de enrutamiento que distribuya los eventos entrantes a los actores correspondientes según su tipo.\n",
    "3. Crea actores que procesen eventos específicos y realicen acciones como la actualización de bases de datos, envío de notificaciones, o ejecución de scripts.\n",
    "4. Implementa un actor supervisor que gestione la creación y monitoreo de actores, incluyendo la reconfiguración dinámica en caso de aumento de carga.\n",
    "5. Utiliza técnicas de streaming para manejar flujos continuos de eventos en tiempo real.\n",
    "6. Asegura la comunicación entre actores mediante autenticación y encriptación de mensajes.\n",
    "7. Realiza pruebas de rendimiento y escalabilidad con diferentes volúmenes de eventos y actores concurrentes.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Diseño e implementación de actores para manejar diferentes tipos de eventos.\n",
    "* Enrutamiento y distribución de eventos.\n",
    "* Procesamiento de eventos y ejecución de acciones.\n",
    "* Supervisión y reconfiguración dinámica.\n",
    "* Manejo de flujos continuos de eventos (streaming).\n",
    "* Comunicación segura entre actores.\n",
    "* Pruebas de rendimiento y escalabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c926457",
   "metadata": {},
   "source": [
    "**Ejercicio 8** : Sistema distribuido de procesamiento de imágenes usando RPC\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "Desarrollar un sistema distribuido que realice procesamiento de imágenes utilizando RPC para invocar procedimientos remotos.\n",
    "\n",
    "Descripción del ejercicio:\n",
    "\n",
    "1. Diseña una API RPC que permita la ejecución remota de operaciones de procesamiento de imágenes como filtrado, transformación y análisis.\n",
    "2. Implementa la lógica de procesamiento de imágenes en el servidor RPC.\n",
    "3. Desarrolla un cliente que distribuya las tareas de procesamiento de imágenes entre múltiples nodos utilizando llamadas RPC.\n",
    "4. Implementa mecanismos de autenticación y autorización para asegurar que solo clientes autorizados puedan invocar los procedimientos.\n",
    "5. Asegura la consistencia y coherencia de los datos utilizando técnicas de sincronización.\n",
    "6. Realiza pruebas de rendimiento y escalabilidad con diferentes tamaños de imágenes y números de clientes concurrentes.\n",
    "\n",
    "Puntos clave a desarrollar:\n",
    "\n",
    "* Diseño e implementación de la API RPC.\n",
    "* Lógica de procesamiento de imágenes en un entorno distribuido.\n",
    "* Distribución de tareas y balanceo de carga.\n",
    "* Seguridad y autenticación.\n",
    "* Sincronización de datos.\n",
    "* Pruebas de rendimiento y escalabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5afc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
